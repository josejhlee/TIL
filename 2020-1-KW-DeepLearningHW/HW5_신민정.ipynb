{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "coursera": {
      "course_slug": "neural-networks-deep-learning",
      "graded_item_id": "XaIWT",
      "launcher_item_id": "zAgPl"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    },
    "colab": {
      "name": "HW5.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9OA0f9oxYGYb",
        "colab_type": "text"
      },
      "source": [
        "# HW#5 Convolutional Neural Network\n",
        "\n",
        "안녕하세요, 광운대학교 로봇학부의 오정현 교수입니다. 본 자료는 딥러닝 실습 수업을 위해 제작된 것입니다.\n",
        "\n",
        "파이썬 문법\n",
        "- 점프투파이썬(https://wikidocs.net/book/1) 참고\n",
        "\n",
        "이번 과제는 Convolutional Neural Network를 이용하여 Classification을 해보는 것입니다.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9KBzwzd7Bub",
        "colab_type": "text"
      },
      "source": [
        "#1. CNN Classification\n",
        "지난 주에는 Multi-layer Neural Network를 이용하여 이미지를 분류하였습니다. CNN은 이미지 처리에 있어서 일반적인 Neural Network보다 높은 성능을 나타냅니다. \n",
        "\n",
        "지난 예제 (https://www.tensorflow.org/tutorials/keras/classification?hl=ko)에서 구현하였던 것처럼 fashion_mnist 분류기를 CNN으로 설계하여 보세요. \n",
        "CNN 예제 (https://www.tensorflow.org/tutorials/images/cnn)를 참고하셔도 됩니다.\n",
        "\n",
        "다양한 layer 개수, node 개수 등 모델의 parameter를 바꿔서 보다 높은 분류 성능이 나오도록 네트워크를 바꿔보세요. \n",
        "\n",
        "기존 NN에 비하여 성능이 높게 나오나요?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzrHl0W72gZQ",
        "colab_type": "text"
      },
      "source": [
        "# **Data Loader & Preprocessing**\n",
        "EDA는 생략(HW4참조)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TmfiqmK11Aq3",
        "outputId": "509048ba-1672-4b90-d9f6-519bbbbac46e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "import pandas as pd # Import Pandas for data manipulation using dataframes\n",
        "import numpy as np # Import Numpy for data statistical analysis \n",
        "import matplotlib.pyplot as plt # Import matplotlib for data visualisation\n",
        "import seaborn as sns\n",
        "import random\n",
        "\n",
        "import tensorflow as tf\n",
        "%matplotlib inline\n",
        "sns.set_style(\"whitegrid\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "av16oMt8Hw8x",
        "colab_type": "code",
        "outputId": "53a75417-481b-4a2e-f7d8-368e988ce98f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.2.0-rc4'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQLAorOG18lI",
        "colab_type": "code",
        "outputId": "200ab17a-9625-48f2-d5bc-d9dd889ae857",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        }
      },
      "source": [
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "# data loader\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "X_train = X_train.reshape((60000, 28, 28, 1))\n",
        "X_test = X_test.reshape((10000, 28, 28, 1))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHjm1xfl2Q9S",
        "colab_type": "code",
        "outputId": "fa4654b9-8dfa-48bc-9f0a-78f98275b6e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "X_train.shape, y_train.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 28, 28, 1), (60000,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1t0PIvX2uOH",
        "colab_type": "code",
        "outputId": "ab963b41-a594-4ba9-c66a-b5213763745a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "X_test.shape, y_test.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((10000, 28, 28, 1), (10000,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsysCoYI3DDM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HsLkxuP2yAw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pixel값을 normalization하여 0~1로 하기위해 scaling\n",
        "X_train = X_train / 255.0\n",
        "\n",
        "X_test = X_test / 255.0\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_hJUxvg9LBD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 512\n",
        "learning_rate = 0.01\n",
        "epochs = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnfG4NqJ3HqI",
        "colab_type": "code",
        "outputId": "66b8af11-ea23-43d8-d0b7-f0a08a8cdb9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4-2wyG38-Mc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "\n",
        "reduceLR = ReduceLROnPlateau( \n",
        "    monitor='val_accuracy',  # 모니터 기준 설정 val_loss? val_acc?\n",
        "    factor=0.5,          # callback 호출시 학습률을 1/2로 줄인다\n",
        "    patience=15,         # epoch 10 동안 개선되지 않으면 callback이 호출\n",
        ")\n",
        "\n",
        "filename = './mymodel.h5'.format(epochs, batch_size)\n",
        "checkpoint = ModelCheckpoint(filename,             # file명을 지정\n",
        "                             monitor='val_accuracy',   # val_accuracy 값이 개선되었을때 호출\n",
        "                             verbose=1,            # 로그를 출력\n",
        "                             save_best_only=True,  # best 값만 저장\n",
        "                             mode='auto'           # auto는 알아서 best를 찾는다. min/max\n",
        "                            )\n",
        "\n",
        "earlystopping = EarlyStopping(monitor='val_accuracy',  # 모니터 기준 설정 (val acc) \n",
        "                              patience=15,         # 10회 Epoch동안 개선되지 않는다면 종료\n",
        "                             )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEjXVZYfC-6Y",
        "colab_type": "text"
      },
      "source": [
        "## **model_1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hK5XgqY3T1N",
        "colab_type": "code",
        "outputId": "239c7cdd-a6a5-4bab-c8bf-abab31ad8d88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        }
      },
      "source": [
        "model_1 = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "\n",
        "  tf.keras.layers.Conv2D(64, (3,3), \n",
        "                         activation ='relu'),\n",
        "\n",
        "  tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(64, activation = \"relu\"),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "\n",
        "])\n",
        "\n",
        "model_1.compile(optimizer=\"Adam\" ,loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "model_1.summary()\n",
        "                            "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 24, 24, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 22, 22, 128)       73856     \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 61952)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                3964992   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 4,058,314\n",
            "Trainable params: 4,058,314\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3osHzoxA5ZOs",
        "colab_type": "code",
        "outputId": "b1355ac0-27bf-4e81-8fb3-aae04f9776c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history_1 = model_1.fit(X_train, y_train, \n",
        "                        batch_size=batch_size,\n",
        "                        epochs=epochs,\n",
        "                        verbose = 2,\n",
        "                        validation_split = 0.2,\n",
        "                        callbacks=[checkpoint, earlystopping,reduceLR])\n",
        "                        "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.84925, saving model to ./mymodel.h5\n",
            "94/94 - 7s - loss: 0.5969 - accuracy: 0.7882 - val_loss: 0.4127 - val_accuracy: 0.8493 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.84925 to 0.88483, saving model to ./mymodel.h5\n",
            "94/94 - 6s - loss: 0.3363 - accuracy: 0.8798 - val_loss: 0.3197 - val_accuracy: 0.8848 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.88483 to 0.89892, saving model to ./mymodel.h5\n",
            "94/94 - 6s - loss: 0.2752 - accuracy: 0.9007 - val_loss: 0.2770 - val_accuracy: 0.8989 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.89892 to 0.90500, saving model to ./mymodel.h5\n",
            "94/94 - 6s - loss: 0.2364 - accuracy: 0.9139 - val_loss: 0.2635 - val_accuracy: 0.9050 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.90500 to 0.91183, saving model to ./mymodel.h5\n",
            "94/94 - 6s - loss: 0.2001 - accuracy: 0.9273 - val_loss: 0.2462 - val_accuracy: 0.9118 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.91183\n",
            "94/94 - 6s - loss: 0.1711 - accuracy: 0.9371 - val_loss: 0.2544 - val_accuracy: 0.9104 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.91183 to 0.91533, saving model to ./mymodel.h5\n",
            "94/94 - 6s - loss: 0.1428 - accuracy: 0.9481 - val_loss: 0.2467 - val_accuracy: 0.9153 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.91533 to 0.91783, saving model to ./mymodel.h5\n",
            "94/94 - 6s - loss: 0.1206 - accuracy: 0.9557 - val_loss: 0.2462 - val_accuracy: 0.9178 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.91783\n",
            "94/94 - 6s - loss: 0.0997 - accuracy: 0.9635 - val_loss: 0.2626 - val_accuracy: 0.9169 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.91783\n",
            "94/94 - 6s - loss: 0.0811 - accuracy: 0.9704 - val_loss: 0.2643 - val_accuracy: 0.9175 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.91783\n",
            "94/94 - 6s - loss: 0.0618 - accuracy: 0.9778 - val_loss: 0.3081 - val_accuracy: 0.9148 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.91783\n",
            "94/94 - 6s - loss: 0.0449 - accuracy: 0.9849 - val_loss: 0.3239 - val_accuracy: 0.9156 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.91783\n",
            "94/94 - 6s - loss: 0.0337 - accuracy: 0.9889 - val_loss: 0.3676 - val_accuracy: 0.9132 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.91783\n",
            "94/94 - 6s - loss: 0.0259 - accuracy: 0.9919 - val_loss: 0.3849 - val_accuracy: 0.9154 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.91783\n",
            "94/94 - 6s - loss: 0.0193 - accuracy: 0.9939 - val_loss: 0.4249 - val_accuracy: 0.9137 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.91783\n",
            "94/94 - 6s - loss: 0.0163 - accuracy: 0.9947 - val_loss: 0.4454 - val_accuracy: 0.9133 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.91783\n",
            "94/94 - 6s - loss: 0.0195 - accuracy: 0.9938 - val_loss: 0.4344 - val_accuracy: 0.9128 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.91783\n",
            "94/94 - 6s - loss: 0.0197 - accuracy: 0.9941 - val_loss: 0.4454 - val_accuracy: 0.9142 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.91783\n",
            "94/94 - 6s - loss: 0.0107 - accuracy: 0.9969 - val_loss: 0.5027 - val_accuracy: 0.9124 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.91783\n",
            "94/94 - 6s - loss: 0.0080 - accuracy: 0.9980 - val_loss: 0.5022 - val_accuracy: 0.9162 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.91783\n",
            "94/94 - 6s - loss: 0.0071 - accuracy: 0.9979 - val_loss: 0.6099 - val_accuracy: 0.9025 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.91783\n",
            "94/94 - 6s - loss: 0.0136 - accuracy: 0.9954 - val_loss: 0.5208 - val_accuracy: 0.9147 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.91783\n",
            "94/94 - 6s - loss: 0.0125 - accuracy: 0.9961 - val_loss: 0.5280 - val_accuracy: 0.9103 - lr: 0.0010\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0erRyPhgCh-",
        "colab_type": "code",
        "outputId": "30e0b757-93fc-49c8-9e3c-1ebac1a2a489",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 754
        }
      },
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "plot_model(model_1, to_file = 'model_1.png', show_shapes = True, show_layer_names = True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRO4iztoAW3i",
        "colab_type": "code",
        "outputId": "8d4b60d9-b232-484e-c68e-ae59d96d0f41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history_1.history['accuracy'])\n",
        "plt.plot(history_1.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history_1.history['loss'])\n",
        "plt.plot(history_1.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MBBIRVtDOia",
        "colab_type": "code",
        "outputId": "96af7267-0d42-4c9b-b09f-164b06d0fc69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "test_loss_1, test_acc_1 = model_1.evaluate(X_test,  y_test, verbose=2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 - 1s - loss: 0.5412 - accuracy: 0.9103\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLGkDhQZD9EI",
        "colab_type": "code",
        "outputId": "1f0206dc-3b65-43ef-e1a4-dd8aae9453ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(test_acc_1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9103000164031982\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpilH-WvD-xk",
        "colab_type": "text"
      },
      "source": [
        "# **Model_2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhEtxv9r8MVy",
        "colab_type": "code",
        "outputId": "a2cd17a0-5b9c-4d1b-850e-c7c0a6801fc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 778
        }
      },
      "source": [
        "model_2 = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv2D(32, (3,3), input_shape=(28, 28, 1),\n",
        "                         activation ='relu'),\n",
        "  tf.keras.layers.BatchNormalization(),    \n",
        "  tf.keras.layers.MaxPooling2D(pool_size=(2,2)), \n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "\n",
        "\n",
        "  tf.keras.layers.Conv2D(64, (3,3), \n",
        "                         activation ='relu'),\n",
        "  tf.keras.layers.BatchNormalization(),    \n",
        "  tf.keras.layers.MaxPooling2D(pool_size=(2,2)), \n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "\n",
        "\n",
        "\n",
        "  tf.keras.layers.Conv2D(128, (3,3), \n",
        "                         activation ='relu'),\n",
        "  tf.keras.layers.BatchNormalization(),    \n",
        "  tf.keras.layers.MaxPooling2D(pool_size=(2,2)), \n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "\n",
        "\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(64, activation = \"relu\"),\n",
        "  tf.keras.layers.BatchNormalization(),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "\n",
        "])\n",
        "\n",
        "model_2.compile(optimizer=\"Adam\" ,loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "model_2.summary()\n",
        "                            "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_3 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 26, 26, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 11, 11, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 11, 11, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 3, 3, 128)         73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 3, 3, 128)         512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 1, 1, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 1, 1, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 64)                256       \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 102,730\n",
            "Trainable params: 102,154\n",
            "Non-trainable params: 576\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkQCahUa_kuo",
        "colab_type": "code",
        "outputId": "1f79dcae-2bc4-49b0-a370-062dad747a6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "plot_model(model_2, to_file = 'model_2.png', show_shapes = True, show_layer_names = True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lc011YYC_m5v",
        "colab_type": "code",
        "outputId": "e651564c-8346-42f7-8b50-18e94543292f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history_2 = model_2.fit(X_train, y_train, \n",
        "                        batch_size=batch_size,\n",
        "                        epochs=epochs,\n",
        "                        verbose = 2,\n",
        "                        validation_split = 0.2,\n",
        "                        callbacks=[checkpoint, earlystopping,reduceLR])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.91783\n",
            "94/94 - 3s - loss: 0.8675 - accuracy: 0.7013 - val_loss: 2.2710 - val_accuracy: 0.0957 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.5437 - accuracy: 0.8061 - val_loss: 2.0572 - val_accuracy: 0.1856 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.4702 - accuracy: 0.8307 - val_loss: 1.6023 - val_accuracy: 0.4728 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.4253 - accuracy: 0.8454 - val_loss: 1.1717 - val_accuracy: 0.5754 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.3997 - accuracy: 0.8553 - val_loss: 0.6666 - val_accuracy: 0.7638 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.3784 - accuracy: 0.8635 - val_loss: 0.4671 - val_accuracy: 0.8351 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.3579 - accuracy: 0.8694 - val_loss: 0.3374 - val_accuracy: 0.8804 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.3483 - accuracy: 0.8745 - val_loss: 0.3479 - val_accuracy: 0.8660 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.3330 - accuracy: 0.8789 - val_loss: 0.3142 - val_accuracy: 0.8823 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.3259 - accuracy: 0.8816 - val_loss: 0.3022 - val_accuracy: 0.8864 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.3148 - accuracy: 0.8841 - val_loss: 0.3123 - val_accuracy: 0.8851 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.3068 - accuracy: 0.8894 - val_loss: 0.2878 - val_accuracy: 0.8953 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.3003 - accuracy: 0.8898 - val_loss: 0.3081 - val_accuracy: 0.8861 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.2957 - accuracy: 0.8921 - val_loss: 0.2880 - val_accuracy: 0.8932 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.2898 - accuracy: 0.8953 - val_loss: 0.2805 - val_accuracy: 0.8967 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.2788 - accuracy: 0.8984 - val_loss: 0.3000 - val_accuracy: 0.8882 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.2753 - accuracy: 0.8993 - val_loss: 0.3103 - val_accuracy: 0.8872 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.2716 - accuracy: 0.8997 - val_loss: 0.2712 - val_accuracy: 0.9011 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.2645 - accuracy: 0.9035 - val_loss: 0.2734 - val_accuracy: 0.8995 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.2632 - accuracy: 0.9031 - val_loss: 0.2696 - val_accuracy: 0.9039 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.2576 - accuracy: 0.9052 - val_loss: 0.2662 - val_accuracy: 0.9026 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.2535 - accuracy: 0.9061 - val_loss: 0.2758 - val_accuracy: 0.8979 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.2481 - accuracy: 0.9085 - val_loss: 0.2789 - val_accuracy: 0.8970 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.2428 - accuracy: 0.9115 - val_loss: 0.2834 - val_accuracy: 0.8960 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.2441 - accuracy: 0.9097 - val_loss: 0.2913 - val_accuracy: 0.8921 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.2408 - accuracy: 0.9104 - val_loss: 0.2676 - val_accuracy: 0.9043 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.2372 - accuracy: 0.9124 - val_loss: 0.2605 - val_accuracy: 0.9069 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.2299 - accuracy: 0.9159 - val_loss: 0.2550 - val_accuracy: 0.9067 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.2284 - accuracy: 0.9156 - val_loss: 0.2707 - val_accuracy: 0.9009 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.2276 - accuracy: 0.9154 - val_loss: 0.2816 - val_accuracy: 0.9012 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.2240 - accuracy: 0.9180 - val_loss: 0.2678 - val_accuracy: 0.9049 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.2220 - accuracy: 0.9177 - val_loss: 0.2769 - val_accuracy: 0.9021 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.2213 - accuracy: 0.9176 - val_loss: 0.2728 - val_accuracy: 0.9035 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.2172 - accuracy: 0.9196 - val_loss: 0.2817 - val_accuracy: 0.8995 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.2167 - accuracy: 0.9197 - val_loss: 0.2648 - val_accuracy: 0.9052 - lr: 0.0010\n",
            "Epoch 36/100\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.2147 - accuracy: 0.9210 - val_loss: 0.2885 - val_accuracy: 0.9001 - lr: 0.0010\n",
            "Epoch 37/100\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.2119 - accuracy: 0.9221 - val_loss: 0.2940 - val_accuracy: 0.8937 - lr: 0.0010\n",
            "Epoch 38/100\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.2084 - accuracy: 0.9231 - val_loss: 0.2601 - val_accuracy: 0.9081 - lr: 0.0010\n",
            "Epoch 39/100\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.2074 - accuracy: 0.9236 - val_loss: 0.2754 - val_accuracy: 0.9028 - lr: 0.0010\n",
            "Epoch 40/100\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.2052 - accuracy: 0.9244 - val_loss: 0.2593 - val_accuracy: 0.9077 - lr: 0.0010\n",
            "Epoch 41/100\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.2034 - accuracy: 0.9228 - val_loss: 0.2515 - val_accuracy: 0.9089 - lr: 0.0010\n",
            "Epoch 42/100\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.2032 - accuracy: 0.9241 - val_loss: 0.2786 - val_accuracy: 0.9021 - lr: 0.0010\n",
            "Epoch 43/100\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.2037 - accuracy: 0.9244 - val_loss: 0.2761 - val_accuracy: 0.9010 - lr: 0.0010\n",
            "Epoch 44/100\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.2004 - accuracy: 0.9260 - val_loss: 0.2689 - val_accuracy: 0.9055 - lr: 0.0010\n",
            "Epoch 45/100\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.1988 - accuracy: 0.9260 - val_loss: 0.2620 - val_accuracy: 0.9068 - lr: 0.0010\n",
            "Epoch 46/100\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.1929 - accuracy: 0.9271 - val_loss: 0.2626 - val_accuracy: 0.9073 - lr: 0.0010\n",
            "Epoch 47/100\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.1902 - accuracy: 0.9293 - val_loss: 0.2595 - val_accuracy: 0.9079 - lr: 0.0010\n",
            "Epoch 48/100\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.1932 - accuracy: 0.9280 - val_loss: 0.2581 - val_accuracy: 0.9106 - lr: 0.0010\n",
            "Epoch 49/100\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.1921 - accuracy: 0.9287 - val_loss: 0.3251 - val_accuracy: 0.8882 - lr: 0.0010\n",
            "Epoch 50/100\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.1882 - accuracy: 0.9297 - val_loss: 0.2611 - val_accuracy: 0.9100 - lr: 0.0010\n",
            "Epoch 51/100\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.1889 - accuracy: 0.9302 - val_loss: 0.2587 - val_accuracy: 0.9097 - lr: 0.0010\n",
            "Epoch 52/100\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.1867 - accuracy: 0.9300 - val_loss: 0.2650 - val_accuracy: 0.9103 - lr: 0.0010\n",
            "Epoch 53/100\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.1825 - accuracy: 0.9321 - val_loss: 0.2834 - val_accuracy: 0.9027 - lr: 0.0010\n",
            "Epoch 54/100\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.1854 - accuracy: 0.9311 - val_loss: 0.3045 - val_accuracy: 0.8952 - lr: 0.0010\n",
            "Epoch 55/100\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.1851 - accuracy: 0.9322 - val_loss: 0.2991 - val_accuracy: 0.8967 - lr: 0.0010\n",
            "Epoch 56/100\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.1849 - accuracy: 0.9304 - val_loss: 0.2751 - val_accuracy: 0.9052 - lr: 0.0010\n",
            "Epoch 57/100\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.1856 - accuracy: 0.9305 - val_loss: 0.2529 - val_accuracy: 0.9113 - lr: 0.0010\n",
            "Epoch 58/100\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.1769 - accuracy: 0.9317 - val_loss: 0.2556 - val_accuracy: 0.9133 - lr: 0.0010\n",
            "Epoch 59/100\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.1786 - accuracy: 0.9326 - val_loss: 0.2603 - val_accuracy: 0.9091 - lr: 0.0010\n",
            "Epoch 60/100\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.1741 - accuracy: 0.9356 - val_loss: 0.2780 - val_accuracy: 0.9055 - lr: 0.0010\n",
            "Epoch 61/100\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.1786 - accuracy: 0.9333 - val_loss: 0.2660 - val_accuracy: 0.9087 - lr: 0.0010\n",
            "Epoch 62/100\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.1733 - accuracy: 0.9348 - val_loss: 0.2670 - val_accuracy: 0.9107 - lr: 0.0010\n",
            "Epoch 63/100\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.1723 - accuracy: 0.9353 - val_loss: 0.2691 - val_accuracy: 0.9079 - lr: 0.0010\n",
            "Epoch 64/100\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.1743 - accuracy: 0.9348 - val_loss: 0.2736 - val_accuracy: 0.9044 - lr: 0.0010\n",
            "Epoch 65/100\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.1700 - accuracy: 0.9367 - val_loss: 0.2745 - val_accuracy: 0.9086 - lr: 0.0010\n",
            "Epoch 66/100\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.1734 - accuracy: 0.9347 - val_loss: 0.2788 - val_accuracy: 0.9059 - lr: 0.0010\n",
            "Epoch 67/100\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.1731 - accuracy: 0.9342 - val_loss: 0.2649 - val_accuracy: 0.9107 - lr: 0.0010\n",
            "Epoch 68/100\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.1692 - accuracy: 0.9380 - val_loss: 0.2591 - val_accuracy: 0.9142 - lr: 0.0010\n",
            "Epoch 69/100\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.1684 - accuracy: 0.9374 - val_loss: 0.2861 - val_accuracy: 0.9039 - lr: 0.0010\n",
            "Epoch 70/100\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.1669 - accuracy: 0.9383 - val_loss: 0.2645 - val_accuracy: 0.9112 - lr: 0.0010\n",
            "Epoch 71/100\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.1695 - accuracy: 0.9370 - val_loss: 0.2972 - val_accuracy: 0.8989 - lr: 0.0010\n",
            "Epoch 72/100\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.1692 - accuracy: 0.9371 - val_loss: 0.2782 - val_accuracy: 0.9064 - lr: 0.0010\n",
            "Epoch 73/100\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.1659 - accuracy: 0.9386 - val_loss: 0.2609 - val_accuracy: 0.9118 - lr: 0.0010\n",
            "Epoch 74/100\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.1645 - accuracy: 0.9387 - val_loss: 0.2802 - val_accuracy: 0.9045 - lr: 0.0010\n",
            "Epoch 75/100\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.1635 - accuracy: 0.9390 - val_loss: 0.2668 - val_accuracy: 0.9119 - lr: 0.0010\n",
            "Epoch 76/100\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.1658 - accuracy: 0.9383 - val_loss: 0.2680 - val_accuracy: 0.9115 - lr: 0.0010\n",
            "Epoch 77/100\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.1653 - accuracy: 0.9392 - val_loss: 0.2715 - val_accuracy: 0.9102 - lr: 0.0010\n",
            "Epoch 78/100\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.1635 - accuracy: 0.9387 - val_loss: 0.2807 - val_accuracy: 0.9076 - lr: 0.0010\n",
            "Epoch 79/100\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.1604 - accuracy: 0.9393 - val_loss: 0.2995 - val_accuracy: 0.9019 - lr: 0.0010\n",
            "Epoch 80/100\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.1621 - accuracy: 0.9398 - val_loss: 0.2628 - val_accuracy: 0.9142 - lr: 0.0010\n",
            "Epoch 81/100\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.1599 - accuracy: 0.9399 - val_loss: 0.2585 - val_accuracy: 0.9127 - lr: 0.0010\n",
            "Epoch 82/100\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.1589 - accuracy: 0.9398 - val_loss: 0.2768 - val_accuracy: 0.9081 - lr: 0.0010\n",
            "Epoch 83/100\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.1600 - accuracy: 0.9401 - val_loss: 0.2600 - val_accuracy: 0.9147 - lr: 0.0010\n",
            "Epoch 84/100\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.1576 - accuracy: 0.9408 - val_loss: 0.2861 - val_accuracy: 0.9065 - lr: 0.0010\n",
            "Epoch 85/100\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.1536 - accuracy: 0.9430 - val_loss: 0.2723 - val_accuracy: 0.9103 - lr: 0.0010\n",
            "Epoch 86/100\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.1552 - accuracy: 0.9426 - val_loss: 0.2741 - val_accuracy: 0.9075 - lr: 0.0010\n",
            "Epoch 87/100\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.1568 - accuracy: 0.9410 - val_loss: 0.3019 - val_accuracy: 0.8989 - lr: 0.0010\n",
            "Epoch 88/100\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.1555 - accuracy: 0.9411 - val_loss: 0.2663 - val_accuracy: 0.9103 - lr: 0.0010\n",
            "Epoch 89/100\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.1562 - accuracy: 0.9421 - val_loss: 0.2687 - val_accuracy: 0.9126 - lr: 0.0010\n",
            "Epoch 90/100\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.1540 - accuracy: 0.9422 - val_loss: 0.2621 - val_accuracy: 0.9123 - lr: 0.0010\n",
            "Epoch 91/100\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.1557 - accuracy: 0.9412 - val_loss: 0.2730 - val_accuracy: 0.9102 - lr: 0.0010\n",
            "Epoch 92/100\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.1516 - accuracy: 0.9438 - val_loss: 0.2694 - val_accuracy: 0.9100 - lr: 0.0010\n",
            "Epoch 93/100\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.1491 - accuracy: 0.9446 - val_loss: 0.2668 - val_accuracy: 0.9111 - lr: 0.0010\n",
            "Epoch 94/100\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.1520 - accuracy: 0.9430 - val_loss: 0.2799 - val_accuracy: 0.9113 - lr: 0.0010\n",
            "Epoch 95/100\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.1522 - accuracy: 0.9437 - val_loss: 0.5473 - val_accuracy: 0.8548 - lr: 0.0010\n",
            "Epoch 96/100\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.1523 - accuracy: 0.9431 - val_loss: 0.2791 - val_accuracy: 0.9078 - lr: 0.0010\n",
            "Epoch 97/100\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.1502 - accuracy: 0.9436 - val_loss: 0.2720 - val_accuracy: 0.9124 - lr: 0.0010\n",
            "Epoch 98/100\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.91783\n",
            "94/94 - 2s - loss: 0.1478 - accuracy: 0.9448 - val_loss: 0.2740 - val_accuracy: 0.9132 - lr: 0.0010\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VM1xDpeXH56w",
        "colab_type": "code",
        "outputId": "59bdc50e-1a9c-4c07-8992-11982aef8658",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        }
      },
      "source": [
        "\n",
        "plt.plot(history_2.history['accuracy'])\n",
        "plt.plot(history_2.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history_2.history['loss'])\n",
        "plt.plot(history_2.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctvGTTLEEeo_",
        "colab_type": "code",
        "outputId": "8db94d59-54d6-49f2-8ec3-8ccfad529de6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "test_loss_2, test_acc_2 = model_2.evaluate(X_test,  y_test, verbose=2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 - 1s - loss: 0.2793 - accuracy: 0.9118\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DI96Xp8b_1aQ",
        "colab_type": "code",
        "outputId": "786a9679-a5c4-4859-ef2f-93781045703c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "test_acc_2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9118000268936157"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpEP5rV7Jnvg",
        "colab_type": "text"
      },
      "source": [
        "# **Model-GridsearchCV**\n",
        "Batch normalization, activation function, Dropout, optimizer,등 하이퍼파라미터 튜닝을 위해 gridsearch를 사용합니다.\n",
        "model_2와 같은 층 구조를 사용하고, 하이퍼파라미터만 조정합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hcauf-6OJnVM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "import numpy\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "def create_model(_optimizer, _lr, _batch_norm, _activation, _dropout):\n",
        "\t\n",
        "\tmodel = tf.keras.models.Sequential([\n",
        "\t\ttf.keras.layers.Conv2D(32, (3,3), input_shape=(28, 28, 1),\n",
        "\t\t\t\t\tactivation =_activation),\n",
        "\t\ttf.keras.layers.BatchNormalization() if _batch_norm else '',    \n",
        "\t\ttf.keras.layers.MaxPooling2D(pool_size=(2,2)), \n",
        "\t\ttf.keras.layers.Dropout(_dropout),\n",
        "\t\t\n",
        "\t\t\n",
        "\t\ttf.keras.layers.Conv2D(64, (3,3), \n",
        "\t\t\t\t\tactivation =_activation),\n",
        "\t\ttf.keras.layers.BatchNormalization() if _batch_norm else '',    \n",
        "\t\ttf.keras.layers.MaxPooling2D(pool_size=(2,2)), \n",
        "\t\ttf.keras.layers.Dropout(_dropout),\n",
        "\t\t\n",
        "\t\t\n",
        "\t\t\n",
        "\t\ttf.keras.layers.Conv2D(128, (3,3), \n",
        "\t\t\t\t\tactivation =_activation),\n",
        "\t\ttf.keras.layers.BatchNormalization() if _batch_norm else '',    \n",
        "\t\ttf.keras.layers.MaxPooling2D(pool_size=(2,2)), \n",
        "\t\ttf.keras.layers.Dropout(_dropout),\n",
        "\t\t\n",
        "\t\t\n",
        "\t\t\n",
        "\t\ttf.keras.layers.Flatten(),\n",
        "\t\ttf.keras.layers.Dense(64, activation = _activation),\n",
        "\t\ttf.keras.layers.BatchNormalization() if _batch_norm else '',\n",
        "\t\ttf.keras.layers.Dropout(_dropout),\n",
        "\t\ttf.keras.layers.Dense(10, activation='softmax')])\n",
        "\t\n",
        "\toptimizer = getattr(tf.keras.optimizers, _optimizer)(learning_rate=_lr)\n",
        "\t\n",
        "\tmodel.compile(loss='sparse_categorical_crossentropy',\n",
        "\t\t\toptimizer=optimizer,\n",
        "\t\t\tmetrics=['accuracy'])\n",
        "\treturn model\n",
        "# KerasClassifier로 모델 생성기 설정\n",
        "model = KerasClassifier(build_fn=create_model, verbose=3)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtPB2hNFEjgV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Grid 설정\n",
        "param_grid = {\n",
        "    'batch_size': [512, 1024],\n",
        "    'epochs': [100],\n",
        "    '_optimizer': ['RMSprop','Adam'], \n",
        "    '_lr': [1e-3, 2e-3, 1e-2], \n",
        "    '_batch_norm': [1, 0], \n",
        "    '_activation': ['relu','selu','swish'],\n",
        "    '_dropout': [0.2, 0.4], \n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzXYOv4ZMtE0",
        "colab_type": "code",
        "outputId": "675db416-8537-4983-bfaa-129d28cd40aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        }
      },
      "source": [
        "param_grid"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'_activation': ['relu', 'selu', 'swish'],\n",
              " '_batch_norm': [1, 0],\n",
              " '_dropout': [0.2, 0.4],\n",
              " '_lr': [0.001, 0.002, 0.01],\n",
              " '_optimizer': ['RMSprop', 'Adam'],\n",
              " 'batch_size': [512, 1024],\n",
              " 'epochs': [100]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OcYrhiRMxKQ",
        "colab_type": "code",
        "outputId": "67401132-bc91-48c6-f11a-570aeace41a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3)\n",
        "grid_result = grid.fit(X_train, y_train, \n",
        "                        batch_size=batch_size,\n",
        "                        epochs=epochs,\n",
        "                        verbose = 2,\n",
        "                        validation_split = 0.2,\n",
        "                        callbacks=[checkpoint, earlystopping,reduceLR])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43m스트리밍 출력 내용이 길어서 마지막 5000줄이 삭제되었습니다.\u001b[0m\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 1.1456 - accuracy: 0.5963 - val_loss: 2.3495 - val_accuracy: 0.0980 - lr: 0.0020\n",
            "Epoch 2/100\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.7239 - accuracy: 0.7360 - val_loss: 2.1545 - val_accuracy: 0.1889 - lr: 0.0020\n",
            "Epoch 3/100\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.6238 - accuracy: 0.7748 - val_loss: 2.0259 - val_accuracy: 0.2887 - lr: 0.0020\n",
            "Epoch 4/100\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.5617 - accuracy: 0.8001 - val_loss: 1.7831 - val_accuracy: 0.4126 - lr: 0.0020\n",
            "Epoch 5/100\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.5202 - accuracy: 0.8144 - val_loss: 1.4434 - val_accuracy: 0.4689 - lr: 0.0020\n",
            "Epoch 6/100\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4928 - accuracy: 0.8238 - val_loss: 0.9526 - val_accuracy: 0.6135 - lr: 0.0020\n",
            "Epoch 7/100\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4703 - accuracy: 0.8327 - val_loss: 0.7002 - val_accuracy: 0.7189 - lr: 0.0020\n",
            "Epoch 8/100\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4594 - accuracy: 0.8351 - val_loss: 0.6664 - val_accuracy: 0.7206 - lr: 0.0020\n",
            "Epoch 9/100\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4439 - accuracy: 0.8418 - val_loss: 0.4127 - val_accuracy: 0.8406 - lr: 0.0020\n",
            "Epoch 10/100\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4361 - accuracy: 0.8427 - val_loss: 0.3890 - val_accuracy: 0.8518 - lr: 0.0020\n",
            "Epoch 11/100\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4249 - accuracy: 0.8469 - val_loss: 0.3783 - val_accuracy: 0.8599 - lr: 0.0020\n",
            "Epoch 12/100\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4126 - accuracy: 0.8495 - val_loss: 0.3685 - val_accuracy: 0.8608 - lr: 0.0020\n",
            "Epoch 13/100\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4052 - accuracy: 0.8535 - val_loss: 0.3566 - val_accuracy: 0.8668 - lr: 0.0020\n",
            "Epoch 14/100\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4000 - accuracy: 0.8558 - val_loss: 0.3391 - val_accuracy: 0.8751 - lr: 0.0020\n",
            "Epoch 15/100\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3885 - accuracy: 0.8611 - val_loss: 0.3533 - val_accuracy: 0.8649 - lr: 0.0020\n",
            "Epoch 16/100\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3914 - accuracy: 0.8577 - val_loss: 0.3942 - val_accuracy: 0.8510 - lr: 0.0020\n",
            "Epoch 17/100\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3828 - accuracy: 0.8619 - val_loss: 0.3555 - val_accuracy: 0.8670 - lr: 0.0020\n",
            "Epoch 18/100\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3803 - accuracy: 0.8627 - val_loss: 0.3483 - val_accuracy: 0.8694 - lr: 0.0020\n",
            "Epoch 19/100\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3748 - accuracy: 0.8660 - val_loss: 0.3305 - val_accuracy: 0.8750 - lr: 0.0020\n",
            "Epoch 20/100\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3651 - accuracy: 0.8674 - val_loss: 0.3372 - val_accuracy: 0.8658 - lr: 0.0020\n",
            "Epoch 21/100\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3669 - accuracy: 0.8698 - val_loss: 0.3455 - val_accuracy: 0.8698 - lr: 0.0020\n",
            "Epoch 22/100\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3608 - accuracy: 0.8691 - val_loss: 0.3173 - val_accuracy: 0.8826 - lr: 0.0020\n",
            "Epoch 23/100\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3656 - accuracy: 0.8692 - val_loss: 0.3149 - val_accuracy: 0.8805 - lr: 0.0020\n",
            "Epoch 24/100\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3541 - accuracy: 0.8741 - val_loss: 0.3215 - val_accuracy: 0.8763 - lr: 0.0020\n",
            "Epoch 25/100\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3538 - accuracy: 0.8714 - val_loss: 0.3570 - val_accuracy: 0.8681 - lr: 0.0020\n",
            "Epoch 26/100\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3529 - accuracy: 0.8721 - val_loss: 0.3214 - val_accuracy: 0.8734 - lr: 0.0020\n",
            "Epoch 27/100\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3494 - accuracy: 0.8748 - val_loss: 0.3114 - val_accuracy: 0.8817 - lr: 0.0020\n",
            "Epoch 28/100\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3465 - accuracy: 0.8736 - val_loss: 0.2970 - val_accuracy: 0.8894 - lr: 0.0020\n",
            "Epoch 29/100\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3468 - accuracy: 0.8744 - val_loss: 0.4159 - val_accuracy: 0.8439 - lr: 0.0020\n",
            "Epoch 30/100\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3455 - accuracy: 0.8753 - val_loss: 0.3083 - val_accuracy: 0.8860 - lr: 0.0020\n",
            "Epoch 31/100\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3367 - accuracy: 0.8770 - val_loss: 0.3277 - val_accuracy: 0.8756 - lr: 0.0020\n",
            "Epoch 32/100\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3397 - accuracy: 0.8762 - val_loss: 0.3094 - val_accuracy: 0.8865 - lr: 0.0020\n",
            "Epoch 33/100\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3386 - accuracy: 0.8783 - val_loss: 0.3074 - val_accuracy: 0.8799 - lr: 0.0020\n",
            "Epoch 34/100\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3361 - accuracy: 0.8792 - val_loss: 0.2959 - val_accuracy: 0.8889 - lr: 0.0020\n",
            "Epoch 35/100\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3307 - accuracy: 0.8809 - val_loss: 0.3090 - val_accuracy: 0.8855 - lr: 0.0020\n",
            "Epoch 36/100\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3286 - accuracy: 0.8820 - val_loss: 0.3092 - val_accuracy: 0.8839 - lr: 0.0020\n",
            "Epoch 37/100\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3252 - accuracy: 0.8823 - val_loss: 0.2873 - val_accuracy: 0.8930 - lr: 0.0020\n",
            "Epoch 38/100\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3312 - accuracy: 0.8789 - val_loss: 0.3154 - val_accuracy: 0.8815 - lr: 0.0020\n",
            "Epoch 39/100\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3307 - accuracy: 0.8782 - val_loss: 0.3203 - val_accuracy: 0.8775 - lr: 0.0020\n",
            "Epoch 40/100\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3257 - accuracy: 0.8830 - val_loss: 0.3039 - val_accuracy: 0.8859 - lr: 0.0020\n",
            "Epoch 41/100\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3209 - accuracy: 0.8832 - val_loss: 0.2883 - val_accuracy: 0.8917 - lr: 0.0020\n",
            "Epoch 42/100\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3236 - accuracy: 0.8816 - val_loss: 0.2969 - val_accuracy: 0.8890 - lr: 0.0020\n",
            "Epoch 43/100\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3237 - accuracy: 0.8817 - val_loss: 0.3135 - val_accuracy: 0.8808 - lr: 0.0020\n",
            "Epoch 44/100\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3193 - accuracy: 0.8840 - val_loss: 0.2902 - val_accuracy: 0.8910 - lr: 0.0020\n",
            "Epoch 45/100\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3184 - accuracy: 0.8845 - val_loss: 0.2976 - val_accuracy: 0.8919 - lr: 0.0020\n",
            "Epoch 46/100\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3140 - accuracy: 0.8875 - val_loss: 0.2818 - val_accuracy: 0.8969 - lr: 0.0020\n",
            "Epoch 47/100\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3141 - accuracy: 0.8845 - val_loss: 0.2884 - val_accuracy: 0.8935 - lr: 0.0020\n",
            "Epoch 48/100\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3136 - accuracy: 0.8855 - val_loss: 0.2983 - val_accuracy: 0.8876 - lr: 0.0020\n",
            "Epoch 49/100\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3100 - accuracy: 0.8869 - val_loss: 0.3102 - val_accuracy: 0.8819 - lr: 0.0020\n",
            "Epoch 50/100\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3105 - accuracy: 0.8876 - val_loss: 0.2911 - val_accuracy: 0.8904 - lr: 0.0020\n",
            "Epoch 51/100\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3075 - accuracy: 0.8893 - val_loss: 0.3119 - val_accuracy: 0.8838 - lr: 0.0020\n",
            "Epoch 52/100\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3085 - accuracy: 0.8883 - val_loss: 0.3339 - val_accuracy: 0.8740 - lr: 0.0020\n",
            "Epoch 53/100\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3144 - accuracy: 0.8863 - val_loss: 0.3006 - val_accuracy: 0.8882 - lr: 0.0020\n",
            "Epoch 54/100\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3072 - accuracy: 0.8877 - val_loss: 0.3104 - val_accuracy: 0.8852 - lr: 0.0020\n",
            "Epoch 55/100\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3073 - accuracy: 0.8895 - val_loss: 0.2834 - val_accuracy: 0.8925 - lr: 0.0020\n",
            "Epoch 56/100\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3007 - accuracy: 0.8900 - val_loss: 0.2849 - val_accuracy: 0.8972 - lr: 0.0020\n",
            "Epoch 57/100\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3076 - accuracy: 0.8885 - val_loss: 0.2780 - val_accuracy: 0.8963 - lr: 0.0020\n",
            "Epoch 58/100\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3029 - accuracy: 0.8906 - val_loss: 0.3076 - val_accuracy: 0.8866 - lr: 0.0020\n",
            "Epoch 59/100\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3044 - accuracy: 0.8887 - val_loss: 0.2865 - val_accuracy: 0.8942 - lr: 0.0020\n",
            "Epoch 60/100\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3014 - accuracy: 0.8918 - val_loss: 0.2758 - val_accuracy: 0.8972 - lr: 0.0020\n",
            "Epoch 61/100\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2995 - accuracy: 0.8894 - val_loss: 0.2748 - val_accuracy: 0.8978 - lr: 0.0020\n",
            "Epoch 62/100\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3027 - accuracy: 0.8892 - val_loss: 0.2889 - val_accuracy: 0.8895 - lr: 0.0020\n",
            "Epoch 63/100\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3010 - accuracy: 0.8908 - val_loss: 0.3429 - val_accuracy: 0.8658 - lr: 0.0020\n",
            "Epoch 64/100\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2973 - accuracy: 0.8918 - val_loss: 0.2834 - val_accuracy: 0.8950 - lr: 0.0020\n",
            "Epoch 65/100\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2976 - accuracy: 0.8926 - val_loss: 0.2697 - val_accuracy: 0.9003 - lr: 0.0020\n",
            "Epoch 66/100\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2974 - accuracy: 0.8935 - val_loss: 0.3132 - val_accuracy: 0.8831 - lr: 0.0020\n",
            "Epoch 67/100\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2994 - accuracy: 0.8914 - val_loss: 0.2701 - val_accuracy: 0.8997 - lr: 0.0020\n",
            "Epoch 68/100\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2977 - accuracy: 0.8932 - val_loss: 0.2834 - val_accuracy: 0.8949 - lr: 0.0020\n",
            "Epoch 69/100\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2952 - accuracy: 0.8916 - val_loss: 0.2877 - val_accuracy: 0.8931 - lr: 0.0020\n",
            "Epoch 70/100\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2993 - accuracy: 0.8920 - val_loss: 0.2694 - val_accuracy: 0.9018 - lr: 0.0020\n",
            "Epoch 71/100\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2943 - accuracy: 0.8929 - val_loss: 0.2847 - val_accuracy: 0.8945 - lr: 0.0020\n",
            "Epoch 72/100\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2944 - accuracy: 0.8934 - val_loss: 0.2740 - val_accuracy: 0.8970 - lr: 0.0020\n",
            "Epoch 73/100\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2922 - accuracy: 0.8938 - val_loss: 0.3130 - val_accuracy: 0.8825 - lr: 0.0020\n",
            "Epoch 74/100\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2928 - accuracy: 0.8958 - val_loss: 0.2759 - val_accuracy: 0.8967 - lr: 0.0020\n",
            "Epoch 75/100\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2944 - accuracy: 0.8963 - val_loss: 0.2742 - val_accuracy: 0.8984 - lr: 0.0020\n",
            "Epoch 76/100\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2923 - accuracy: 0.8940 - val_loss: 0.2753 - val_accuracy: 0.8990 - lr: 0.0020\n",
            "Epoch 77/100\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2913 - accuracy: 0.8934 - val_loss: 0.2880 - val_accuracy: 0.8940 - lr: 0.0020\n",
            "Epoch 78/100\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2883 - accuracy: 0.8966 - val_loss: 0.2757 - val_accuracy: 0.8992 - lr: 0.0020\n",
            "Epoch 79/100\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2891 - accuracy: 0.8948 - val_loss: 0.2935 - val_accuracy: 0.8911 - lr: 0.0020\n",
            "Epoch 80/100\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2935 - accuracy: 0.8928 - val_loss: 0.2761 - val_accuracy: 0.8985 - lr: 0.0020\n",
            "Epoch 81/100\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2938 - accuracy: 0.8924 - val_loss: 0.2936 - val_accuracy: 0.8880 - lr: 0.0020\n",
            "Epoch 82/100\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2890 - accuracy: 0.8943 - val_loss: 0.2857 - val_accuracy: 0.8934 - lr: 0.0020\n",
            "Epoch 83/100\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2874 - accuracy: 0.8958 - val_loss: 0.2702 - val_accuracy: 0.9015 - lr: 0.0020\n",
            "Epoch 84/100\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2914 - accuracy: 0.8956 - val_loss: 0.3173 - val_accuracy: 0.8794 - lr: 0.0020\n",
            "Epoch 85/100\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2875 - accuracy: 0.8960 - val_loss: 0.2713 - val_accuracy: 0.9001 - lr: 0.0020\n",
            "Epoch 1/100\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 1.1987 - accuracy: 0.5816 - val_loss: 2.2631 - val_accuracy: 0.0988 - lr: 0.0020\n",
            "Epoch 2/100\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.7284 - accuracy: 0.7326 - val_loss: 2.2030 - val_accuracy: 0.2975 - lr: 0.0020\n",
            "Epoch 3/100\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.6254 - accuracy: 0.7747 - val_loss: 1.8105 - val_accuracy: 0.4599 - lr: 0.0020\n",
            "Epoch 4/100\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.5766 - accuracy: 0.7947 - val_loss: 1.5673 - val_accuracy: 0.4784 - lr: 0.0020\n",
            "Epoch 5/100\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.5405 - accuracy: 0.8075 - val_loss: 1.2749 - val_accuracy: 0.5030 - lr: 0.0020\n",
            "Epoch 6/100\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.5042 - accuracy: 0.8187 - val_loss: 0.9916 - val_accuracy: 0.5875 - lr: 0.0020\n",
            "Epoch 7/100\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4935 - accuracy: 0.8231 - val_loss: 0.6580 - val_accuracy: 0.7411 - lr: 0.0020\n",
            "Epoch 8/100\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4647 - accuracy: 0.8328 - val_loss: 0.5721 - val_accuracy: 0.7878 - lr: 0.0020\n",
            "Epoch 9/100\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4600 - accuracy: 0.8345 - val_loss: 0.4668 - val_accuracy: 0.8200 - lr: 0.0020\n",
            "Epoch 10/100\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4439 - accuracy: 0.8432 - val_loss: 0.4802 - val_accuracy: 0.8130 - lr: 0.0020\n",
            "Epoch 11/100\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4393 - accuracy: 0.8429 - val_loss: 0.3631 - val_accuracy: 0.8670 - lr: 0.0020\n",
            "Epoch 12/100\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4304 - accuracy: 0.8452 - val_loss: 0.3375 - val_accuracy: 0.8767 - lr: 0.0020\n",
            "Epoch 13/100\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4202 - accuracy: 0.8492 - val_loss: 0.3610 - val_accuracy: 0.8651 - lr: 0.0020\n",
            "Epoch 14/100\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4081 - accuracy: 0.8512 - val_loss: 0.3811 - val_accuracy: 0.8559 - lr: 0.0020\n",
            "Epoch 15/100\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4048 - accuracy: 0.8550 - val_loss: 0.3470 - val_accuracy: 0.8714 - lr: 0.0020\n",
            "Epoch 16/100\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3982 - accuracy: 0.8584 - val_loss: 0.3580 - val_accuracy: 0.8661 - lr: 0.0020\n",
            "Epoch 17/100\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3938 - accuracy: 0.8569 - val_loss: 0.3171 - val_accuracy: 0.8850 - lr: 0.0020\n",
            "Epoch 18/100\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3861 - accuracy: 0.8598 - val_loss: 0.3243 - val_accuracy: 0.8831 - lr: 0.0020\n",
            "Epoch 19/100\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3860 - accuracy: 0.8599 - val_loss: 0.3147 - val_accuracy: 0.8831 - lr: 0.0020\n",
            "Epoch 20/100\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3840 - accuracy: 0.8601 - val_loss: 0.3522 - val_accuracy: 0.8746 - lr: 0.0020\n",
            "Epoch 21/100\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3813 - accuracy: 0.8620 - val_loss: 0.3178 - val_accuracy: 0.8836 - lr: 0.0020\n",
            "Epoch 22/100\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3734 - accuracy: 0.8662 - val_loss: 0.3237 - val_accuracy: 0.8790 - lr: 0.0020\n",
            "Epoch 23/100\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3694 - accuracy: 0.8663 - val_loss: 0.3121 - val_accuracy: 0.8899 - lr: 0.0020\n",
            "Epoch 24/100\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3679 - accuracy: 0.8673 - val_loss: 0.3101 - val_accuracy: 0.8835 - lr: 0.0020\n",
            "Epoch 25/100\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3615 - accuracy: 0.8706 - val_loss: 0.3278 - val_accuracy: 0.8780 - lr: 0.0020\n",
            "Epoch 26/100\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3584 - accuracy: 0.8703 - val_loss: 0.3214 - val_accuracy: 0.8795 - lr: 0.0020\n",
            "Epoch 27/100\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3537 - accuracy: 0.8706 - val_loss: 0.3516 - val_accuracy: 0.8677 - lr: 0.0020\n",
            "Epoch 28/100\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3558 - accuracy: 0.8723 - val_loss: 0.2990 - val_accuracy: 0.8870 - lr: 0.0020\n",
            "Epoch 29/100\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3497 - accuracy: 0.8727 - val_loss: 0.2866 - val_accuracy: 0.8928 - lr: 0.0020\n",
            "Epoch 30/100\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3492 - accuracy: 0.8750 - val_loss: 0.2954 - val_accuracy: 0.8911 - lr: 0.0020\n",
            "Epoch 31/100\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3468 - accuracy: 0.8753 - val_loss: 0.2934 - val_accuracy: 0.8930 - lr: 0.0020\n",
            "Epoch 32/100\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3447 - accuracy: 0.8763 - val_loss: 0.2892 - val_accuracy: 0.8938 - lr: 0.0020\n",
            "Epoch 33/100\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3450 - accuracy: 0.8750 - val_loss: 0.2888 - val_accuracy: 0.8980 - lr: 0.0020\n",
            "Epoch 34/100\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3464 - accuracy: 0.8755 - val_loss: 0.2847 - val_accuracy: 0.8959 - lr: 0.0020\n",
            "Epoch 35/100\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3373 - accuracy: 0.8785 - val_loss: 0.3348 - val_accuracy: 0.8751 - lr: 0.0020\n",
            "Epoch 36/100\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3380 - accuracy: 0.8775 - val_loss: 0.2989 - val_accuracy: 0.8889 - lr: 0.0020\n",
            "Epoch 37/100\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3372 - accuracy: 0.8780 - val_loss: 0.2811 - val_accuracy: 0.8974 - lr: 0.0020\n",
            "Epoch 38/100\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3327 - accuracy: 0.8788 - val_loss: 0.2812 - val_accuracy: 0.8959 - lr: 0.0020\n",
            "Epoch 39/100\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3290 - accuracy: 0.8811 - val_loss: 0.2804 - val_accuracy: 0.8980 - lr: 0.0020\n",
            "Epoch 40/100\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3240 - accuracy: 0.8848 - val_loss: 0.3129 - val_accuracy: 0.8839 - lr: 0.0020\n",
            "Epoch 41/100\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3246 - accuracy: 0.8824 - val_loss: 0.3028 - val_accuracy: 0.8884 - lr: 0.0020\n",
            "Epoch 42/100\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3288 - accuracy: 0.8812 - val_loss: 0.3103 - val_accuracy: 0.8835 - lr: 0.0020\n",
            "Epoch 43/100\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3294 - accuracy: 0.8816 - val_loss: 0.2858 - val_accuracy: 0.8972 - lr: 0.0020\n",
            "Epoch 44/100\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3256 - accuracy: 0.8830 - val_loss: 0.3539 - val_accuracy: 0.8633 - lr: 0.0020\n",
            "Epoch 45/100\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3239 - accuracy: 0.8843 - val_loss: 0.2791 - val_accuracy: 0.8955 - lr: 0.0020\n",
            "Epoch 46/100\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3209 - accuracy: 0.8853 - val_loss: 0.2707 - val_accuracy: 0.9028 - lr: 0.0020\n",
            "Epoch 47/100\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3184 - accuracy: 0.8854 - val_loss: 0.2801 - val_accuracy: 0.8959 - lr: 0.0020\n",
            "Epoch 48/100\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3216 - accuracy: 0.8827 - val_loss: 0.3013 - val_accuracy: 0.8921 - lr: 0.0020\n",
            "Epoch 49/100\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3232 - accuracy: 0.8818 - val_loss: 0.3528 - val_accuracy: 0.8669 - lr: 0.0020\n",
            "Epoch 50/100\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3282 - accuracy: 0.8814 - val_loss: 0.2841 - val_accuracy: 0.8985 - lr: 0.0020\n",
            "Epoch 51/100\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3156 - accuracy: 0.8867 - val_loss: 0.2791 - val_accuracy: 0.8944 - lr: 0.0020\n",
            "Epoch 52/100\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3177 - accuracy: 0.8842 - val_loss: 0.2713 - val_accuracy: 0.8997 - lr: 0.0020\n",
            "Epoch 53/100\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3148 - accuracy: 0.8870 - val_loss: 0.2853 - val_accuracy: 0.8932 - lr: 0.0020\n",
            "Epoch 54/100\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3122 - accuracy: 0.8850 - val_loss: 0.2781 - val_accuracy: 0.8994 - lr: 0.0020\n",
            "Epoch 55/100\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3128 - accuracy: 0.8863 - val_loss: 0.2778 - val_accuracy: 0.8996 - lr: 0.0020\n",
            "Epoch 56/100\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3095 - accuracy: 0.8862 - val_loss: 0.2757 - val_accuracy: 0.9010 - lr: 0.0020\n",
            "Epoch 57/100\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3087 - accuracy: 0.8878 - val_loss: 0.2705 - val_accuracy: 0.9016 - lr: 0.0020\n",
            "Epoch 58/100\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3053 - accuracy: 0.8895 - val_loss: 0.2750 - val_accuracy: 0.8982 - lr: 0.0020\n",
            "Epoch 59/100\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3040 - accuracy: 0.8910 - val_loss: 0.2902 - val_accuracy: 0.8946 - lr: 0.0020\n",
            "Epoch 60/100\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3107 - accuracy: 0.8868 - val_loss: 0.2871 - val_accuracy: 0.8944 - lr: 0.0020\n",
            "Epoch 61/100\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3068 - accuracy: 0.8892 - val_loss: 0.2748 - val_accuracy: 0.8995 - lr: 0.0020\n",
            "Epoch 1/100\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 1.1502 - accuracy: 0.5988 - val_loss: 2.4442 - val_accuracy: 0.0980 - lr: 0.0020\n",
            "Epoch 2/100\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.7311 - accuracy: 0.7335 - val_loss: 2.3903 - val_accuracy: 0.0980 - lr: 0.0020\n",
            "Epoch 3/100\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.6390 - accuracy: 0.7675 - val_loss: 1.9765 - val_accuracy: 0.1985 - lr: 0.0020\n",
            "Epoch 4/100\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.5786 - accuracy: 0.7917 - val_loss: 1.5226 - val_accuracy: 0.3442 - lr: 0.0020\n",
            "Epoch 5/100\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.5407 - accuracy: 0.8064 - val_loss: 1.2302 - val_accuracy: 0.4780 - lr: 0.0020\n",
            "Epoch 6/100\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.5137 - accuracy: 0.8185 - val_loss: 0.8335 - val_accuracy: 0.6678 - lr: 0.0020\n",
            "Epoch 7/100\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4951 - accuracy: 0.8240 - val_loss: 0.7792 - val_accuracy: 0.6977 - lr: 0.0020\n",
            "Epoch 8/100\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4761 - accuracy: 0.8324 - val_loss: 0.5743 - val_accuracy: 0.7845 - lr: 0.0020\n",
            "Epoch 9/100\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4631 - accuracy: 0.8365 - val_loss: 0.4688 - val_accuracy: 0.8160 - lr: 0.0020\n",
            "Epoch 10/100\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4469 - accuracy: 0.8407 - val_loss: 0.3895 - val_accuracy: 0.8541 - lr: 0.0020\n",
            "Epoch 11/100\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4394 - accuracy: 0.8417 - val_loss: 0.4078 - val_accuracy: 0.8451 - lr: 0.0020\n",
            "Epoch 12/100\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4295 - accuracy: 0.8454 - val_loss: 0.4253 - val_accuracy: 0.8341 - lr: 0.0020\n",
            "Epoch 13/100\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4186 - accuracy: 0.8499 - val_loss: 0.3644 - val_accuracy: 0.8621 - lr: 0.0020\n",
            "Epoch 14/100\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4114 - accuracy: 0.8526 - val_loss: 0.4107 - val_accuracy: 0.8374 - lr: 0.0020\n",
            "Epoch 15/100\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4146 - accuracy: 0.8522 - val_loss: 0.3393 - val_accuracy: 0.8733 - lr: 0.0020\n",
            "Epoch 16/100\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4019 - accuracy: 0.8562 - val_loss: 0.3336 - val_accuracy: 0.8775 - lr: 0.0020\n",
            "Epoch 17/100\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3952 - accuracy: 0.8590 - val_loss: 0.3530 - val_accuracy: 0.8683 - lr: 0.0020\n",
            "Epoch 18/100\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3949 - accuracy: 0.8617 - val_loss: 0.3254 - val_accuracy: 0.8790 - lr: 0.0020\n",
            "Epoch 19/100\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3957 - accuracy: 0.8574 - val_loss: 0.3253 - val_accuracy: 0.8808 - lr: 0.0020\n",
            "Epoch 20/100\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3908 - accuracy: 0.8603 - val_loss: 0.3383 - val_accuracy: 0.8733 - lr: 0.0020\n",
            "Epoch 21/100\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3821 - accuracy: 0.8618 - val_loss: 0.3573 - val_accuracy: 0.8669 - lr: 0.0020\n",
            "Epoch 22/100\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3760 - accuracy: 0.8650 - val_loss: 0.3238 - val_accuracy: 0.8804 - lr: 0.0020\n",
            "Epoch 23/100\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3712 - accuracy: 0.8660 - val_loss: 0.3065 - val_accuracy: 0.8852 - lr: 0.0020\n",
            "Epoch 24/100\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3672 - accuracy: 0.8674 - val_loss: 0.3099 - val_accuracy: 0.8854 - lr: 0.0020\n",
            "Epoch 25/100\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3656 - accuracy: 0.8702 - val_loss: 0.3079 - val_accuracy: 0.8861 - lr: 0.0020\n",
            "Epoch 26/100\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3645 - accuracy: 0.8698 - val_loss: 0.3190 - val_accuracy: 0.8823 - lr: 0.0020\n",
            "Epoch 27/100\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3574 - accuracy: 0.8710 - val_loss: 0.3092 - val_accuracy: 0.8844 - lr: 0.0020\n",
            "Epoch 28/100\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3579 - accuracy: 0.8705 - val_loss: 0.3229 - val_accuracy: 0.8802 - lr: 0.0020\n",
            "Epoch 29/100\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3512 - accuracy: 0.8736 - val_loss: 0.3154 - val_accuracy: 0.8852 - lr: 0.0020\n",
            "Epoch 30/100\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3543 - accuracy: 0.8719 - val_loss: 0.3392 - val_accuracy: 0.8668 - lr: 0.0020\n",
            "Epoch 31/100\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3513 - accuracy: 0.8757 - val_loss: 0.3174 - val_accuracy: 0.8809 - lr: 0.0020\n",
            "Epoch 32/100\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3440 - accuracy: 0.8748 - val_loss: 0.3002 - val_accuracy: 0.8870 - lr: 0.0020\n",
            "Epoch 33/100\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3493 - accuracy: 0.8724 - val_loss: 0.3140 - val_accuracy: 0.8835 - lr: 0.0020\n",
            "Epoch 34/100\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3417 - accuracy: 0.8768 - val_loss: 0.3173 - val_accuracy: 0.8825 - lr: 0.0020\n",
            "Epoch 35/100\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3384 - accuracy: 0.8776 - val_loss: 0.3059 - val_accuracy: 0.8856 - lr: 0.0020\n",
            "Epoch 36/100\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3346 - accuracy: 0.8799 - val_loss: 0.3336 - val_accuracy: 0.8746 - lr: 0.0020\n",
            "Epoch 37/100\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3333 - accuracy: 0.8777 - val_loss: 0.3005 - val_accuracy: 0.8871 - lr: 0.0020\n",
            "Epoch 38/100\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3391 - accuracy: 0.8767 - val_loss: 0.3446 - val_accuracy: 0.8725 - lr: 0.0020\n",
            "Epoch 39/100\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3376 - accuracy: 0.8788 - val_loss: 0.3059 - val_accuracy: 0.8838 - lr: 0.0020\n",
            "Epoch 40/100\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3321 - accuracy: 0.8796 - val_loss: 0.3115 - val_accuracy: 0.8840 - lr: 0.0020\n",
            "Epoch 41/100\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3307 - accuracy: 0.8818 - val_loss: 0.3080 - val_accuracy: 0.8857 - lr: 0.0020\n",
            "Epoch 42/100\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3328 - accuracy: 0.8816 - val_loss: 0.3044 - val_accuracy: 0.8894 - lr: 0.0020\n",
            "Epoch 43/100\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3260 - accuracy: 0.8815 - val_loss: 0.2948 - val_accuracy: 0.8882 - lr: 0.0020\n",
            "Epoch 44/100\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3278 - accuracy: 0.8842 - val_loss: 0.3282 - val_accuracy: 0.8709 - lr: 0.0020\n",
            "Epoch 45/100\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3282 - accuracy: 0.8819 - val_loss: 0.2924 - val_accuracy: 0.8904 - lr: 0.0020\n",
            "Epoch 46/100\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3267 - accuracy: 0.8821 - val_loss: 0.2875 - val_accuracy: 0.8928 - lr: 0.0020\n",
            "Epoch 47/100\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3194 - accuracy: 0.8852 - val_loss: 0.2919 - val_accuracy: 0.8910 - lr: 0.0020\n",
            "Epoch 48/100\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3218 - accuracy: 0.8836 - val_loss: 0.2864 - val_accuracy: 0.8929 - lr: 0.0020\n",
            "Epoch 49/100\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3172 - accuracy: 0.8857 - val_loss: 0.2940 - val_accuracy: 0.8888 - lr: 0.0020\n",
            "Epoch 50/100\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3184 - accuracy: 0.8823 - val_loss: 0.3005 - val_accuracy: 0.8854 - lr: 0.0020\n",
            "Epoch 51/100\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3143 - accuracy: 0.8865 - val_loss: 0.3192 - val_accuracy: 0.8770 - lr: 0.0020\n",
            "Epoch 52/100\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3147 - accuracy: 0.8847 - val_loss: 0.2819 - val_accuracy: 0.8938 - lr: 0.0020\n",
            "Epoch 53/100\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3108 - accuracy: 0.8881 - val_loss: 0.2863 - val_accuracy: 0.8915 - lr: 0.0020\n",
            "Epoch 54/100\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3170 - accuracy: 0.8846 - val_loss: 0.2845 - val_accuracy: 0.8942 - lr: 0.0020\n",
            "Epoch 55/100\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3137 - accuracy: 0.8851 - val_loss: 0.2876 - val_accuracy: 0.8919 - lr: 0.0020\n",
            "Epoch 56/100\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3087 - accuracy: 0.8871 - val_loss: 0.3091 - val_accuracy: 0.8854 - lr: 0.0020\n",
            "Epoch 57/100\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3091 - accuracy: 0.8885 - val_loss: 0.3457 - val_accuracy: 0.8677 - lr: 0.0020\n",
            "Epoch 58/100\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3120 - accuracy: 0.8882 - val_loss: 0.2936 - val_accuracy: 0.8929 - lr: 0.0020\n",
            "Epoch 59/100\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3097 - accuracy: 0.8889 - val_loss: 0.2815 - val_accuracy: 0.8940 - lr: 0.0020\n",
            "Epoch 60/100\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3126 - accuracy: 0.8857 - val_loss: 0.2719 - val_accuracy: 0.8974 - lr: 0.0020\n",
            "Epoch 61/100\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3086 - accuracy: 0.8896 - val_loss: 0.2950 - val_accuracy: 0.8920 - lr: 0.0020\n",
            "Epoch 62/100\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3049 - accuracy: 0.8893 - val_loss: 0.2835 - val_accuracy: 0.8957 - lr: 0.0020\n",
            "Epoch 63/100\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3120 - accuracy: 0.8882 - val_loss: 0.2839 - val_accuracy: 0.8910 - lr: 0.0020\n",
            "Epoch 64/100\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3025 - accuracy: 0.8913 - val_loss: 0.2783 - val_accuracy: 0.8954 - lr: 0.0020\n",
            "Epoch 65/100\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3037 - accuracy: 0.8885 - val_loss: 0.2733 - val_accuracy: 0.8961 - lr: 0.0020\n",
            "Epoch 66/100\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3044 - accuracy: 0.8892 - val_loss: 0.3015 - val_accuracy: 0.8876 - lr: 0.0020\n",
            "Epoch 67/100\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3014 - accuracy: 0.8898 - val_loss: 0.2908 - val_accuracy: 0.8941 - lr: 0.0020\n",
            "Epoch 68/100\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2983 - accuracy: 0.8926 - val_loss: 0.2800 - val_accuracy: 0.8956 - lr: 0.0020\n",
            "Epoch 69/100\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3018 - accuracy: 0.8906 - val_loss: 0.2774 - val_accuracy: 0.8995 - lr: 0.0020\n",
            "Epoch 70/100\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3026 - accuracy: 0.8903 - val_loss: 0.2827 - val_accuracy: 0.8966 - lr: 0.0020\n",
            "Epoch 71/100\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3009 - accuracy: 0.8906 - val_loss: 0.2865 - val_accuracy: 0.8931 - lr: 0.0020\n",
            "Epoch 72/100\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2959 - accuracy: 0.8933 - val_loss: 0.3122 - val_accuracy: 0.8844 - lr: 0.0020\n",
            "Epoch 73/100\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2952 - accuracy: 0.8934 - val_loss: 0.3053 - val_accuracy: 0.8851 - lr: 0.0020\n",
            "Epoch 74/100\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2974 - accuracy: 0.8922 - val_loss: 0.2898 - val_accuracy: 0.8926 - lr: 0.0020\n",
            "Epoch 75/100\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2987 - accuracy: 0.8917 - val_loss: 0.2732 - val_accuracy: 0.9006 - lr: 0.0020\n",
            "Epoch 76/100\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3024 - accuracy: 0.8894 - val_loss: 0.2854 - val_accuracy: 0.8949 - lr: 0.0020\n",
            "Epoch 77/100\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2992 - accuracy: 0.8919 - val_loss: 0.2764 - val_accuracy: 0.8979 - lr: 0.0020\n",
            "Epoch 78/100\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2944 - accuracy: 0.8943 - val_loss: 0.2701 - val_accuracy: 0.8995 - lr: 0.0020\n",
            "Epoch 79/100\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2960 - accuracy: 0.8931 - val_loss: 0.2773 - val_accuracy: 0.8969 - lr: 0.0020\n",
            "Epoch 80/100\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2987 - accuracy: 0.8904 - val_loss: 0.2989 - val_accuracy: 0.8878 - lr: 0.0020\n",
            "Epoch 81/100\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2886 - accuracy: 0.8945 - val_loss: 0.2725 - val_accuracy: 0.8992 - lr: 0.0020\n",
            "Epoch 82/100\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2968 - accuracy: 0.8932 - val_loss: 0.2816 - val_accuracy: 0.8961 - lr: 0.0020\n",
            "Epoch 83/100\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2900 - accuracy: 0.8930 - val_loss: 0.2689 - val_accuracy: 0.8996 - lr: 0.0020\n",
            "Epoch 84/100\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2930 - accuracy: 0.8951 - val_loss: 0.2835 - val_accuracy: 0.8965 - lr: 0.0020\n",
            "Epoch 85/100\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2957 - accuracy: 0.8939 - val_loss: 0.2746 - val_accuracy: 0.8989 - lr: 0.0020\n",
            "Epoch 86/100\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2905 - accuracy: 0.8948 - val_loss: 0.2745 - val_accuracy: 0.8972 - lr: 0.0020\n",
            "Epoch 87/100\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2890 - accuracy: 0.8932 - val_loss: 0.2922 - val_accuracy: 0.8916 - lr: 0.0020\n",
            "Epoch 88/100\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2902 - accuracy: 0.8941 - val_loss: 0.3410 - val_accuracy: 0.8720 - lr: 0.0020\n",
            "Epoch 89/100\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2937 - accuracy: 0.8935 - val_loss: 0.2802 - val_accuracy: 0.8959 - lr: 0.0020\n",
            "Epoch 90/100\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2841 - accuracy: 0.8987 - val_loss: 0.2678 - val_accuracy: 0.9019 - lr: 0.0020\n",
            "Epoch 91/100\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2955 - accuracy: 0.8942 - val_loss: 0.2945 - val_accuracy: 0.8886 - lr: 0.0020\n",
            "Epoch 92/100\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2822 - accuracy: 0.8969 - val_loss: 0.2747 - val_accuracy: 0.9013 - lr: 0.0020\n",
            "Epoch 93/100\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2885 - accuracy: 0.8955 - val_loss: 0.2728 - val_accuracy: 0.8988 - lr: 0.0020\n",
            "Epoch 94/100\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2930 - accuracy: 0.8949 - val_loss: 0.2715 - val_accuracy: 0.8997 - lr: 0.0020\n",
            "Epoch 95/100\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2840 - accuracy: 0.8975 - val_loss: 0.2862 - val_accuracy: 0.8940 - lr: 0.0020\n",
            "Epoch 96/100\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2793 - accuracy: 0.8979 - val_loss: 0.2815 - val_accuracy: 0.8969 - lr: 0.0020\n",
            "Epoch 97/100\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2846 - accuracy: 0.8961 - val_loss: 0.2786 - val_accuracy: 0.8959 - lr: 0.0020\n",
            "Epoch 98/100\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2860 - accuracy: 0.8963 - val_loss: 0.2906 - val_accuracy: 0.8911 - lr: 0.0020\n",
            "Epoch 99/100\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2816 - accuracy: 0.8972 - val_loss: 0.3138 - val_accuracy: 0.8823 - lr: 0.0020\n",
            "Epoch 100/100\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2857 - accuracy: 0.8959 - val_loss: 0.2679 - val_accuracy: 0.9014 - lr: 0.0020\n",
            "Epoch 1/100\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 1.1674 - accuracy: 0.5970 - val_loss: 2.3546 - val_accuracy: 0.0980 - lr: 0.0020\n",
            "Epoch 2/100\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.7374 - accuracy: 0.7271 - val_loss: 2.2933 - val_accuracy: 0.2640 - lr: 0.0020\n",
            "Epoch 3/100\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.6435 - accuracy: 0.7629 - val_loss: 2.0336 - val_accuracy: 0.3715 - lr: 0.0020\n",
            "Epoch 4/100\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.5854 - accuracy: 0.7883 - val_loss: 1.7215 - val_accuracy: 0.4423 - lr: 0.0020\n",
            "Epoch 5/100\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.5474 - accuracy: 0.8014 - val_loss: 1.2099 - val_accuracy: 0.5860 - lr: 0.0020\n",
            "Epoch 6/100\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.5145 - accuracy: 0.8152 - val_loss: 1.0296 - val_accuracy: 0.6229 - lr: 0.0020\n",
            "Epoch 7/100\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4943 - accuracy: 0.8224 - val_loss: 0.8404 - val_accuracy: 0.7309 - lr: 0.0020\n",
            "Epoch 8/100\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4737 - accuracy: 0.8310 - val_loss: 0.5080 - val_accuracy: 0.8266 - lr: 0.0020\n",
            "Epoch 9/100\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4613 - accuracy: 0.8345 - val_loss: 0.4418 - val_accuracy: 0.8420 - lr: 0.0020\n",
            "Epoch 10/100\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4454 - accuracy: 0.8441 - val_loss: 0.3748 - val_accuracy: 0.8643 - lr: 0.0020\n",
            "Epoch 11/100\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4331 - accuracy: 0.8465 - val_loss: 0.3518 - val_accuracy: 0.8710 - lr: 0.0020\n",
            "Epoch 12/100\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4241 - accuracy: 0.8482 - val_loss: 0.3600 - val_accuracy: 0.8668 - lr: 0.0020\n",
            "Epoch 13/100\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4160 - accuracy: 0.8499 - val_loss: 0.3565 - val_accuracy: 0.8665 - lr: 0.0020\n",
            "Epoch 14/100\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4119 - accuracy: 0.8525 - val_loss: 0.3406 - val_accuracy: 0.8730 - lr: 0.0020\n",
            "Epoch 15/100\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4064 - accuracy: 0.8542 - val_loss: 0.3381 - val_accuracy: 0.8719 - lr: 0.0020\n",
            "Epoch 16/100\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3964 - accuracy: 0.8557 - val_loss: 0.3890 - val_accuracy: 0.8479 - lr: 0.0020\n",
            "Epoch 17/100\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3911 - accuracy: 0.8594 - val_loss: 0.3453 - val_accuracy: 0.8661 - lr: 0.0020\n",
            "Epoch 18/100\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3869 - accuracy: 0.8586 - val_loss: 0.3303 - val_accuracy: 0.8761 - lr: 0.0020\n",
            "Epoch 19/100\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3838 - accuracy: 0.8621 - val_loss: 0.3169 - val_accuracy: 0.8839 - lr: 0.0020\n",
            "Epoch 20/100\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3838 - accuracy: 0.8621 - val_loss: 0.3235 - val_accuracy: 0.8808 - lr: 0.0020\n",
            "Epoch 21/100\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3781 - accuracy: 0.8626 - val_loss: 0.3288 - val_accuracy: 0.8798 - lr: 0.0020\n",
            "Epoch 22/100\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3692 - accuracy: 0.8686 - val_loss: 0.3298 - val_accuracy: 0.8771 - lr: 0.0020\n",
            "Epoch 23/100\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3686 - accuracy: 0.8678 - val_loss: 0.3410 - val_accuracy: 0.8696 - lr: 0.0020\n",
            "Epoch 24/100\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3579 - accuracy: 0.8713 - val_loss: 0.3380 - val_accuracy: 0.8737 - lr: 0.0020\n",
            "Epoch 25/100\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3574 - accuracy: 0.8702 - val_loss: 0.3653 - val_accuracy: 0.8554 - lr: 0.0020\n",
            "Epoch 26/100\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3584 - accuracy: 0.8699 - val_loss: 0.3450 - val_accuracy: 0.8715 - lr: 0.0020\n",
            "Epoch 27/100\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3549 - accuracy: 0.8734 - val_loss: 0.3284 - val_accuracy: 0.8780 - lr: 0.0020\n",
            "Epoch 28/100\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3512 - accuracy: 0.8741 - val_loss: 0.3126 - val_accuracy: 0.8838 - lr: 0.0020\n",
            "Epoch 29/100\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3498 - accuracy: 0.8745 - val_loss: 0.3529 - val_accuracy: 0.8609 - lr: 0.0020\n",
            "Epoch 30/100\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3497 - accuracy: 0.8742 - val_loss: 0.3382 - val_accuracy: 0.8751 - lr: 0.0020\n",
            "Epoch 31/100\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3485 - accuracy: 0.8742 - val_loss: 0.2925 - val_accuracy: 0.8924 - lr: 0.0020\n",
            "Epoch 32/100\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3478 - accuracy: 0.8742 - val_loss: 0.3124 - val_accuracy: 0.8832 - lr: 0.0020\n",
            "Epoch 33/100\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3472 - accuracy: 0.8736 - val_loss: 0.2945 - val_accuracy: 0.8903 - lr: 0.0020\n",
            "Epoch 34/100\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3384 - accuracy: 0.8788 - val_loss: 0.3216 - val_accuracy: 0.8765 - lr: 0.0020\n",
            "Epoch 35/100\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3422 - accuracy: 0.8735 - val_loss: 0.3284 - val_accuracy: 0.8795 - lr: 0.0020\n",
            "Epoch 36/100\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3368 - accuracy: 0.8767 - val_loss: 0.2958 - val_accuracy: 0.8905 - lr: 0.0020\n",
            "Epoch 37/100\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3400 - accuracy: 0.8773 - val_loss: 0.3534 - val_accuracy: 0.8635 - lr: 0.0020\n",
            "Epoch 38/100\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3341 - accuracy: 0.8789 - val_loss: 0.2887 - val_accuracy: 0.8932 - lr: 0.0020\n",
            "Epoch 39/100\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3319 - accuracy: 0.8812 - val_loss: 0.3253 - val_accuracy: 0.8750 - lr: 0.0020\n",
            "Epoch 40/100\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3318 - accuracy: 0.8809 - val_loss: 0.2846 - val_accuracy: 0.8960 - lr: 0.0020\n",
            "Epoch 41/100\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3334 - accuracy: 0.8785 - val_loss: 0.2872 - val_accuracy: 0.8930 - lr: 0.0020\n",
            "Epoch 42/100\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3267 - accuracy: 0.8819 - val_loss: 0.2872 - val_accuracy: 0.8961 - lr: 0.0020\n",
            "Epoch 43/100\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3245 - accuracy: 0.8854 - val_loss: 0.3968 - val_accuracy: 0.8543 - lr: 0.0020\n",
            "Epoch 44/100\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3256 - accuracy: 0.8821 - val_loss: 0.2864 - val_accuracy: 0.8941 - lr: 0.0020\n",
            "Epoch 45/100\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3212 - accuracy: 0.8827 - val_loss: 0.2921 - val_accuracy: 0.8934 - lr: 0.0020\n",
            "Epoch 46/100\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3232 - accuracy: 0.8818 - val_loss: 0.3271 - val_accuracy: 0.8730 - lr: 0.0020\n",
            "Epoch 47/100\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3206 - accuracy: 0.8845 - val_loss: 0.2864 - val_accuracy: 0.8960 - lr: 0.0020\n",
            "Epoch 48/100\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3234 - accuracy: 0.8834 - val_loss: 0.3186 - val_accuracy: 0.8811 - lr: 0.0020\n",
            "Epoch 49/100\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3143 - accuracy: 0.8857 - val_loss: 0.3650 - val_accuracy: 0.8558 - lr: 0.0020\n",
            "Epoch 50/100\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3190 - accuracy: 0.8836 - val_loss: 0.3028 - val_accuracy: 0.8866 - lr: 0.0020\n",
            "Epoch 51/100\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3202 - accuracy: 0.8834 - val_loss: 0.2983 - val_accuracy: 0.8894 - lr: 0.0020\n",
            "Epoch 52/100\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3142 - accuracy: 0.8850 - val_loss: 0.2863 - val_accuracy: 0.8985 - lr: 0.0020\n",
            "Epoch 53/100\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3163 - accuracy: 0.8867 - val_loss: 0.3049 - val_accuracy: 0.8873 - lr: 0.0020\n",
            "Epoch 54/100\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3146 - accuracy: 0.8861 - val_loss: 0.2841 - val_accuracy: 0.8990 - lr: 0.0020\n",
            "Epoch 55/100\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3133 - accuracy: 0.8866 - val_loss: 0.3250 - val_accuracy: 0.8770 - lr: 0.0020\n",
            "Epoch 56/100\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3133 - accuracy: 0.8860 - val_loss: 0.3179 - val_accuracy: 0.8830 - lr: 0.0020\n",
            "Epoch 57/100\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3121 - accuracy: 0.8859 - val_loss: 0.3411 - val_accuracy: 0.8691 - lr: 0.0020\n",
            "Epoch 58/100\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3126 - accuracy: 0.8867 - val_loss: 0.3115 - val_accuracy: 0.8824 - lr: 0.0020\n",
            "Epoch 59/100\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3109 - accuracy: 0.8870 - val_loss: 0.2961 - val_accuracy: 0.8895 - lr: 0.0020\n",
            "Epoch 60/100\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3110 - accuracy: 0.8873 - val_loss: 0.2857 - val_accuracy: 0.8941 - lr: 0.0020\n",
            "Epoch 61/100\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3134 - accuracy: 0.8863 - val_loss: 0.2943 - val_accuracy: 0.8924 - lr: 0.0020\n",
            "Epoch 62/100\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3047 - accuracy: 0.8908 - val_loss: 0.2964 - val_accuracy: 0.8903 - lr: 0.0020\n",
            "Epoch 63/100\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3057 - accuracy: 0.8891 - val_loss: 0.2861 - val_accuracy: 0.8946 - lr: 0.0020\n",
            "Epoch 64/100\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3082 - accuracy: 0.8888 - val_loss: 0.3017 - val_accuracy: 0.8880 - lr: 0.0020\n",
            "Epoch 65/100\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3097 - accuracy: 0.8885 - val_loss: 0.3371 - val_accuracy: 0.8720 - lr: 0.0020\n",
            "Epoch 66/100\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3059 - accuracy: 0.8888 - val_loss: 0.2802 - val_accuracy: 0.8978 - lr: 0.0020\n",
            "Epoch 67/100\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3095 - accuracy: 0.8885 - val_loss: 0.3372 - val_accuracy: 0.8676 - lr: 0.0020\n",
            "Epoch 68/100\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3067 - accuracy: 0.8885 - val_loss: 0.3021 - val_accuracy: 0.8878 - lr: 0.0020\n",
            "Epoch 69/100\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3026 - accuracy: 0.8908 - val_loss: 0.3032 - val_accuracy: 0.8880 - lr: 0.0020\n",
            "Epoch 1/100\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 1.1746 - accuracy: 0.5908 - val_loss: 2.3633 - val_accuracy: 0.1551 - lr: 0.0020\n",
            "Epoch 2/100\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.7322 - accuracy: 0.7304 - val_loss: 2.5596 - val_accuracy: 0.1035 - lr: 0.0020\n",
            "Epoch 3/100\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.6373 - accuracy: 0.7672 - val_loss: 3.1738 - val_accuracy: 0.1040 - lr: 0.0020\n",
            "Epoch 4/100\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.5829 - accuracy: 0.7883 - val_loss: 2.7856 - val_accuracy: 0.1459 - lr: 0.0020\n",
            "Epoch 5/100\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.5449 - accuracy: 0.8046 - val_loss: 2.5374 - val_accuracy: 0.1845 - lr: 0.0020\n",
            "Epoch 6/100\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.5138 - accuracy: 0.8167 - val_loss: 1.2989 - val_accuracy: 0.4779 - lr: 0.0020\n",
            "Epoch 7/100\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4930 - accuracy: 0.8243 - val_loss: 0.7605 - val_accuracy: 0.7150 - lr: 0.0020\n",
            "Epoch 8/100\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4821 - accuracy: 0.8267 - val_loss: 0.5302 - val_accuracy: 0.8199 - lr: 0.0020\n",
            "Epoch 9/100\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4666 - accuracy: 0.8334 - val_loss: 0.4982 - val_accuracy: 0.8171 - lr: 0.0020\n",
            "Epoch 10/100\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4515 - accuracy: 0.8389 - val_loss: 0.3717 - val_accuracy: 0.8662 - lr: 0.0020\n",
            "Epoch 11/100\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4477 - accuracy: 0.8390 - val_loss: 0.3830 - val_accuracy: 0.8627 - lr: 0.0020\n",
            "Epoch 12/100\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4300 - accuracy: 0.8455 - val_loss: 0.3800 - val_accuracy: 0.8587 - lr: 0.0020\n",
            "Epoch 13/100\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4217 - accuracy: 0.8496 - val_loss: 0.4260 - val_accuracy: 0.8344 - lr: 0.0020\n",
            "Epoch 14/100\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4126 - accuracy: 0.8512 - val_loss: 0.3401 - val_accuracy: 0.8749 - lr: 0.0020\n",
            "Epoch 15/100\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4140 - accuracy: 0.8512 - val_loss: 0.3254 - val_accuracy: 0.8840 - lr: 0.0020\n",
            "Epoch 16/100\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4062 - accuracy: 0.8544 - val_loss: 0.3432 - val_accuracy: 0.8716 - lr: 0.0020\n",
            "Epoch 17/100\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4035 - accuracy: 0.8571 - val_loss: 0.3146 - val_accuracy: 0.8846 - lr: 0.0020\n",
            "Epoch 18/100\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3891 - accuracy: 0.8590 - val_loss: 0.3746 - val_accuracy: 0.8556 - lr: 0.0020\n",
            "Epoch 19/100\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3830 - accuracy: 0.8617 - val_loss: 0.3156 - val_accuracy: 0.8856 - lr: 0.0020\n",
            "Epoch 20/100\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3847 - accuracy: 0.8634 - val_loss: 0.3562 - val_accuracy: 0.8677 - lr: 0.0020\n",
            "Epoch 21/100\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3742 - accuracy: 0.8649 - val_loss: 0.3200 - val_accuracy: 0.8799 - lr: 0.0020\n",
            "Epoch 22/100\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3695 - accuracy: 0.8659 - val_loss: 0.3203 - val_accuracy: 0.8795 - lr: 0.0020\n",
            "Epoch 23/100\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3771 - accuracy: 0.8637 - val_loss: 0.3166 - val_accuracy: 0.8836 - lr: 0.0020\n",
            "Epoch 24/100\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3759 - accuracy: 0.8654 - val_loss: 0.3005 - val_accuracy: 0.8885 - lr: 0.0020\n",
            "Epoch 25/100\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3681 - accuracy: 0.8662 - val_loss: 0.3208 - val_accuracy: 0.8758 - lr: 0.0020\n",
            "Epoch 26/100\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3578 - accuracy: 0.8707 - val_loss: 0.3095 - val_accuracy: 0.8849 - lr: 0.0020\n",
            "Epoch 27/100\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3593 - accuracy: 0.8710 - val_loss: 0.3055 - val_accuracy: 0.8852 - lr: 0.0020\n",
            "Epoch 28/100\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3599 - accuracy: 0.8726 - val_loss: 0.3433 - val_accuracy: 0.8694 - lr: 0.0020\n",
            "Epoch 29/100\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3524 - accuracy: 0.8726 - val_loss: 0.3173 - val_accuracy: 0.8801 - lr: 0.0020\n",
            "Epoch 30/100\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3496 - accuracy: 0.8740 - val_loss: 0.2911 - val_accuracy: 0.8947 - lr: 0.0020\n",
            "Epoch 31/100\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3491 - accuracy: 0.8744 - val_loss: 0.3247 - val_accuracy: 0.8799 - lr: 0.0020\n",
            "Epoch 32/100\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3488 - accuracy: 0.8744 - val_loss: 0.3159 - val_accuracy: 0.8849 - lr: 0.0020\n",
            "Epoch 33/100\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3457 - accuracy: 0.8728 - val_loss: 0.3581 - val_accuracy: 0.8673 - lr: 0.0020\n",
            "Epoch 34/100\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3407 - accuracy: 0.8774 - val_loss: 0.2897 - val_accuracy: 0.8954 - lr: 0.0020\n",
            "Epoch 35/100\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3450 - accuracy: 0.8773 - val_loss: 0.2841 - val_accuracy: 0.8949 - lr: 0.0020\n",
            "Epoch 36/100\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3406 - accuracy: 0.8775 - val_loss: 0.2862 - val_accuracy: 0.8963 - lr: 0.0020\n",
            "Epoch 37/100\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3455 - accuracy: 0.8754 - val_loss: 0.2922 - val_accuracy: 0.8898 - lr: 0.0020\n",
            "Epoch 38/100\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3347 - accuracy: 0.8813 - val_loss: 0.3029 - val_accuracy: 0.8859 - lr: 0.0020\n",
            "Epoch 39/100\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3299 - accuracy: 0.8803 - val_loss: 0.3634 - val_accuracy: 0.8622 - lr: 0.0020\n",
            "Epoch 40/100\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3316 - accuracy: 0.8814 - val_loss: 0.2866 - val_accuracy: 0.8955 - lr: 0.0020\n",
            "Epoch 41/100\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3281 - accuracy: 0.8832 - val_loss: 0.3054 - val_accuracy: 0.8876 - lr: 0.0020\n",
            "Epoch 42/100\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3333 - accuracy: 0.8778 - val_loss: 0.2825 - val_accuracy: 0.8944 - lr: 0.0020\n",
            "Epoch 43/100\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3261 - accuracy: 0.8815 - val_loss: 0.3083 - val_accuracy: 0.8880 - lr: 0.0020\n",
            "Epoch 44/100\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3232 - accuracy: 0.8830 - val_loss: 0.2844 - val_accuracy: 0.8960 - lr: 0.0020\n",
            "Epoch 45/100\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3255 - accuracy: 0.8838 - val_loss: 0.2779 - val_accuracy: 0.8990 - lr: 0.0020\n",
            "Epoch 46/100\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3241 - accuracy: 0.8819 - val_loss: 0.3201 - val_accuracy: 0.8824 - lr: 0.0020\n",
            "Epoch 47/100\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3201 - accuracy: 0.8827 - val_loss: 0.2770 - val_accuracy: 0.8996 - lr: 0.0020\n",
            "Epoch 48/100\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3242 - accuracy: 0.8828 - val_loss: 0.2713 - val_accuracy: 0.9013 - lr: 0.0020\n",
            "Epoch 49/100\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3183 - accuracy: 0.8839 - val_loss: 0.2785 - val_accuracy: 0.8965 - lr: 0.0020\n",
            "Epoch 50/100\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3225 - accuracy: 0.8829 - val_loss: 0.2885 - val_accuracy: 0.8923 - lr: 0.0020\n",
            "Epoch 51/100\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3157 - accuracy: 0.8865 - val_loss: 0.2784 - val_accuracy: 0.8941 - lr: 0.0020\n",
            "Epoch 52/100\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3136 - accuracy: 0.8857 - val_loss: 0.2871 - val_accuracy: 0.8931 - lr: 0.0020\n",
            "Epoch 53/100\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3144 - accuracy: 0.8873 - val_loss: 0.2725 - val_accuracy: 0.9005 - lr: 0.0020\n",
            "Epoch 54/100\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3180 - accuracy: 0.8864 - val_loss: 0.2968 - val_accuracy: 0.8900 - lr: 0.0020\n",
            "Epoch 55/100\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3193 - accuracy: 0.8834 - val_loss: 0.2824 - val_accuracy: 0.8982 - lr: 0.0020\n",
            "Epoch 56/100\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3110 - accuracy: 0.8871 - val_loss: 0.2728 - val_accuracy: 0.9010 - lr: 0.0020\n",
            "Epoch 57/100\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3160 - accuracy: 0.8857 - val_loss: 0.2841 - val_accuracy: 0.9000 - lr: 0.0020\n",
            "Epoch 58/100\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3116 - accuracy: 0.8867 - val_loss: 0.2667 - val_accuracy: 0.9043 - lr: 0.0020\n",
            "Epoch 59/100\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3125 - accuracy: 0.8865 - val_loss: 0.2824 - val_accuracy: 0.8964 - lr: 0.0020\n",
            "Epoch 60/100\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3094 - accuracy: 0.8887 - val_loss: 0.2858 - val_accuracy: 0.8940 - lr: 0.0020\n",
            "Epoch 61/100\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3097 - accuracy: 0.8886 - val_loss: 0.2818 - val_accuracy: 0.8944 - lr: 0.0020\n",
            "Epoch 62/100\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3066 - accuracy: 0.8888 - val_loss: 0.2934 - val_accuracy: 0.8891 - lr: 0.0020\n",
            "Epoch 63/100\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3030 - accuracy: 0.8902 - val_loss: 0.2689 - val_accuracy: 0.9009 - lr: 0.0020\n",
            "Epoch 64/100\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3048 - accuracy: 0.8887 - val_loss: 0.2678 - val_accuracy: 0.9015 - lr: 0.0020\n",
            "Epoch 65/100\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3034 - accuracy: 0.8877 - val_loss: 0.2773 - val_accuracy: 0.9004 - lr: 0.0020\n",
            "Epoch 66/100\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3113 - accuracy: 0.8858 - val_loss: 0.2820 - val_accuracy: 0.8954 - lr: 0.0020\n",
            "Epoch 67/100\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2982 - accuracy: 0.8920 - val_loss: 0.2649 - val_accuracy: 0.9035 - lr: 0.0020\n",
            "Epoch 68/100\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3059 - accuracy: 0.8894 - val_loss: 0.2650 - val_accuracy: 0.9069 - lr: 0.0020\n",
            "Epoch 69/100\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2975 - accuracy: 0.8912 - val_loss: 0.3056 - val_accuracy: 0.8899 - lr: 0.0020\n",
            "Epoch 70/100\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3074 - accuracy: 0.8880 - val_loss: 0.3192 - val_accuracy: 0.8836 - lr: 0.0020\n",
            "Epoch 71/100\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2985 - accuracy: 0.8907 - val_loss: 0.2692 - val_accuracy: 0.9050 - lr: 0.0020\n",
            "Epoch 72/100\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3040 - accuracy: 0.8901 - val_loss: 0.2871 - val_accuracy: 0.8955 - lr: 0.0020\n",
            "Epoch 73/100\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2964 - accuracy: 0.8931 - val_loss: 0.3056 - val_accuracy: 0.8928 - lr: 0.0020\n",
            "Epoch 74/100\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2969 - accuracy: 0.8929 - val_loss: 0.2675 - val_accuracy: 0.9021 - lr: 0.0020\n",
            "Epoch 75/100\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2934 - accuracy: 0.8927 - val_loss: 0.2572 - val_accuracy: 0.9078 - lr: 0.0020\n",
            "Epoch 76/100\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2949 - accuracy: 0.8925 - val_loss: 0.2701 - val_accuracy: 0.9030 - lr: 0.0020\n",
            "Epoch 77/100\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2972 - accuracy: 0.8906 - val_loss: 0.2696 - val_accuracy: 0.9025 - lr: 0.0020\n",
            "Epoch 78/100\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2963 - accuracy: 0.8918 - val_loss: 0.2740 - val_accuracy: 0.9014 - lr: 0.0020\n",
            "Epoch 79/100\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2948 - accuracy: 0.8931 - val_loss: 0.2601 - val_accuracy: 0.9051 - lr: 0.0020\n",
            "Epoch 80/100\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2949 - accuracy: 0.8931 - val_loss: 0.2672 - val_accuracy: 0.9055 - lr: 0.0020\n",
            "Epoch 81/100\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2972 - accuracy: 0.8949 - val_loss: 0.2829 - val_accuracy: 0.8955 - lr: 0.0020\n",
            "Epoch 82/100\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2989 - accuracy: 0.8915 - val_loss: 0.2572 - val_accuracy: 0.9062 - lr: 0.0020\n",
            "Epoch 83/100\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2909 - accuracy: 0.8943 - val_loss: 0.2627 - val_accuracy: 0.9056 - lr: 0.0020\n",
            "Epoch 84/100\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3005 - accuracy: 0.8913 - val_loss: 0.2622 - val_accuracy: 0.9062 - lr: 0.0020\n",
            "Epoch 85/100\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2900 - accuracy: 0.8952 - val_loss: 0.3128 - val_accuracy: 0.8905 - lr: 0.0020\n",
            "Epoch 86/100\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2966 - accuracy: 0.8918 - val_loss: 0.3457 - val_accuracy: 0.8648 - lr: 0.0020\n",
            "Epoch 87/100\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2942 - accuracy: 0.8925 - val_loss: 0.2616 - val_accuracy: 0.9026 - lr: 0.0020\n",
            "Epoch 88/100\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2927 - accuracy: 0.8946 - val_loss: 0.2814 - val_accuracy: 0.8989 - lr: 0.0020\n",
            "Epoch 89/100\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2898 - accuracy: 0.8952 - val_loss: 0.3200 - val_accuracy: 0.8844 - lr: 0.0020\n",
            "Epoch 90/100\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2900 - accuracy: 0.8935 - val_loss: 0.2763 - val_accuracy: 0.8959 - lr: 0.0020\n",
            "Epoch 1/100\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.9031 - accuracy: 0.6792 - val_loss: 1.9259 - val_accuracy: 0.2405 - lr: 0.0100\n",
            "Epoch 2/100\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.6119 - accuracy: 0.7770 - val_loss: 1.9543 - val_accuracy: 0.2240 - lr: 0.0100\n",
            "Epoch 3/100\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.5370 - accuracy: 0.8069 - val_loss: 1.2883 - val_accuracy: 0.4851 - lr: 0.0100\n",
            "Epoch 4/100\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.5032 - accuracy: 0.8189 - val_loss: 1.1009 - val_accuracy: 0.5820 - lr: 0.0100\n",
            "Epoch 5/100\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4743 - accuracy: 0.8277 - val_loss: 0.6293 - val_accuracy: 0.7972 - lr: 0.0100\n",
            "Epoch 6/100\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4598 - accuracy: 0.8353 - val_loss: 0.6462 - val_accuracy: 0.7270 - lr: 0.0100\n",
            "Epoch 7/100\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4466 - accuracy: 0.8401 - val_loss: 0.6330 - val_accuracy: 0.7199 - lr: 0.0100\n",
            "Epoch 8/100\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4305 - accuracy: 0.8442 - val_loss: 0.4928 - val_accuracy: 0.7981 - lr: 0.0100\n",
            "Epoch 9/100\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4244 - accuracy: 0.8480 - val_loss: 0.4055 - val_accuracy: 0.8401 - lr: 0.0100\n",
            "Epoch 10/100\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4132 - accuracy: 0.8503 - val_loss: 0.4659 - val_accuracy: 0.8279 - lr: 0.0100\n",
            "Epoch 11/100\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4099 - accuracy: 0.8529 - val_loss: 0.4157 - val_accuracy: 0.8504 - lr: 0.0100\n",
            "Epoch 12/100\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3967 - accuracy: 0.8557 - val_loss: 0.3792 - val_accuracy: 0.8533 - lr: 0.0100\n",
            "Epoch 13/100\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3973 - accuracy: 0.8568 - val_loss: 0.3998 - val_accuracy: 0.8525 - lr: 0.0100\n",
            "Epoch 14/100\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3910 - accuracy: 0.8581 - val_loss: 0.3655 - val_accuracy: 0.8656 - lr: 0.0100\n",
            "Epoch 15/100\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3907 - accuracy: 0.8595 - val_loss: 0.3794 - val_accuracy: 0.8528 - lr: 0.0100\n",
            "Epoch 16/100\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3813 - accuracy: 0.8623 - val_loss: 0.3368 - val_accuracy: 0.8733 - lr: 0.0100\n",
            "Epoch 17/100\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3768 - accuracy: 0.8659 - val_loss: 0.3647 - val_accuracy: 0.8676 - lr: 0.0100\n",
            "Epoch 18/100\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3731 - accuracy: 0.8641 - val_loss: 0.3846 - val_accuracy: 0.8474 - lr: 0.0100\n",
            "Epoch 19/100\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3712 - accuracy: 0.8654 - val_loss: 0.3293 - val_accuracy: 0.8780 - lr: 0.0100\n",
            "Epoch 20/100\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3675 - accuracy: 0.8667 - val_loss: 0.3553 - val_accuracy: 0.8652 - lr: 0.0100\n",
            "Epoch 21/100\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3657 - accuracy: 0.8667 - val_loss: 0.3332 - val_accuracy: 0.8783 - lr: 0.0100\n",
            "Epoch 22/100\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3580 - accuracy: 0.8704 - val_loss: 0.3603 - val_accuracy: 0.8690 - lr: 0.0100\n",
            "Epoch 23/100\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3596 - accuracy: 0.8686 - val_loss: 0.3406 - val_accuracy: 0.8733 - lr: 0.0100\n",
            "Epoch 24/100\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3596 - accuracy: 0.8707 - val_loss: 0.5279 - val_accuracy: 0.8116 - lr: 0.0100\n",
            "Epoch 25/100\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3564 - accuracy: 0.8715 - val_loss: 0.3907 - val_accuracy: 0.8599 - lr: 0.0100\n",
            "Epoch 26/100\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3535 - accuracy: 0.8727 - val_loss: 0.3499 - val_accuracy: 0.8736 - lr: 0.0100\n",
            "Epoch 27/100\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3518 - accuracy: 0.8743 - val_loss: 0.3369 - val_accuracy: 0.8763 - lr: 0.0100\n",
            "Epoch 28/100\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3513 - accuracy: 0.8726 - val_loss: 0.3885 - val_accuracy: 0.8594 - lr: 0.0100\n",
            "Epoch 29/100\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3419 - accuracy: 0.8777 - val_loss: 0.3035 - val_accuracy: 0.8884 - lr: 0.0100\n",
            "Epoch 30/100\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3433 - accuracy: 0.8764 - val_loss: 0.3666 - val_accuracy: 0.8656 - lr: 0.0100\n",
            "Epoch 31/100\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3451 - accuracy: 0.8765 - val_loss: 0.3554 - val_accuracy: 0.8665 - lr: 0.0100\n",
            "Epoch 32/100\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3396 - accuracy: 0.8764 - val_loss: 0.3066 - val_accuracy: 0.8839 - lr: 0.0100\n",
            "Epoch 33/100\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3405 - accuracy: 0.8769 - val_loss: 0.3221 - val_accuracy: 0.8866 - lr: 0.0100\n",
            "Epoch 34/100\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3363 - accuracy: 0.8788 - val_loss: 0.3160 - val_accuracy: 0.8808 - lr: 0.0100\n",
            "Epoch 35/100\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3368 - accuracy: 0.8780 - val_loss: 0.3127 - val_accuracy: 0.8816 - lr: 0.0100\n",
            "Epoch 36/100\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3356 - accuracy: 0.8794 - val_loss: 0.2916 - val_accuracy: 0.8935 - lr: 0.0100\n",
            "Epoch 37/100\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3339 - accuracy: 0.8793 - val_loss: 0.3037 - val_accuracy: 0.8881 - lr: 0.0100\n",
            "Epoch 38/100\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3331 - accuracy: 0.8796 - val_loss: 0.3365 - val_accuracy: 0.8755 - lr: 0.0100\n",
            "Epoch 39/100\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3331 - accuracy: 0.8821 - val_loss: 0.3147 - val_accuracy: 0.8841 - lr: 0.0100\n",
            "Epoch 40/100\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3303 - accuracy: 0.8811 - val_loss: 0.3217 - val_accuracy: 0.8796 - lr: 0.0100\n",
            "Epoch 41/100\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3314 - accuracy: 0.8788 - val_loss: 0.3380 - val_accuracy: 0.8737 - lr: 0.0100\n",
            "Epoch 42/100\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3269 - accuracy: 0.8817 - val_loss: 0.3244 - val_accuracy: 0.8760 - lr: 0.0100\n",
            "Epoch 43/100\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3246 - accuracy: 0.8836 - val_loss: 0.3388 - val_accuracy: 0.8690 - lr: 0.0100\n",
            "Epoch 44/100\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3271 - accuracy: 0.8834 - val_loss: 0.3986 - val_accuracy: 0.8536 - lr: 0.0100\n",
            "Epoch 45/100\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3262 - accuracy: 0.8814 - val_loss: 0.3033 - val_accuracy: 0.8856 - lr: 0.0100\n",
            "Epoch 46/100\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3237 - accuracy: 0.8845 - val_loss: 0.3923 - val_accuracy: 0.8478 - lr: 0.0100\n",
            "Epoch 47/100\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3260 - accuracy: 0.8822 - val_loss: 0.3157 - val_accuracy: 0.8815 - lr: 0.0100\n",
            "Epoch 48/100\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3179 - accuracy: 0.8853 - val_loss: 0.3020 - val_accuracy: 0.8899 - lr: 0.0100\n",
            "Epoch 49/100\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3193 - accuracy: 0.8855 - val_loss: 0.3822 - val_accuracy: 0.8549 - lr: 0.0100\n",
            "Epoch 50/100\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3202 - accuracy: 0.8844 - val_loss: 0.4124 - val_accuracy: 0.8341 - lr: 0.0100\n",
            "Epoch 51/100\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3264 - accuracy: 0.8835 - val_loss: 0.3035 - val_accuracy: 0.8903 - lr: 0.0100\n",
            "Epoch 1/100\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.8989 - accuracy: 0.6795 - val_loss: 1.7731 - val_accuracy: 0.3144 - lr: 0.0100\n",
            "Epoch 2/100\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.6194 - accuracy: 0.7767 - val_loss: 1.7085 - val_accuracy: 0.3943 - lr: 0.0100\n",
            "Epoch 3/100\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.5488 - accuracy: 0.7993 - val_loss: 2.5470 - val_accuracy: 0.2887 - lr: 0.0100\n",
            "Epoch 4/100\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.5084 - accuracy: 0.8133 - val_loss: 1.6067 - val_accuracy: 0.4350 - lr: 0.0100\n",
            "Epoch 5/100\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4780 - accuracy: 0.8257 - val_loss: 1.3510 - val_accuracy: 0.5421 - lr: 0.0100\n",
            "Epoch 6/100\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4680 - accuracy: 0.8279 - val_loss: 0.7054 - val_accuracy: 0.7385 - lr: 0.0100\n",
            "Epoch 7/100\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4540 - accuracy: 0.8337 - val_loss: 0.7244 - val_accuracy: 0.7200 - lr: 0.0100\n",
            "Epoch 8/100\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4391 - accuracy: 0.8407 - val_loss: 0.6361 - val_accuracy: 0.7531 - lr: 0.0100\n",
            "Epoch 9/100\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4306 - accuracy: 0.8430 - val_loss: 0.5541 - val_accuracy: 0.7582 - lr: 0.0100\n",
            "Epoch 10/100\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4220 - accuracy: 0.8454 - val_loss: 0.3758 - val_accuracy: 0.8564 - lr: 0.0100\n",
            "Epoch 11/100\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4142 - accuracy: 0.8485 - val_loss: 0.4177 - val_accuracy: 0.8421 - lr: 0.0100\n",
            "Epoch 12/100\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4095 - accuracy: 0.8497 - val_loss: 0.4036 - val_accuracy: 0.8480 - lr: 0.0100\n",
            "Epoch 13/100\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4037 - accuracy: 0.8536 - val_loss: 0.4979 - val_accuracy: 0.8325 - lr: 0.0100\n",
            "Epoch 14/100\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4003 - accuracy: 0.8554 - val_loss: 0.3548 - val_accuracy: 0.8654 - lr: 0.0100\n",
            "Epoch 15/100\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3906 - accuracy: 0.8572 - val_loss: 0.4100 - val_accuracy: 0.8303 - lr: 0.0100\n",
            "Epoch 16/100\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3860 - accuracy: 0.8579 - val_loss: 0.4377 - val_accuracy: 0.8223 - lr: 0.0100\n",
            "Epoch 17/100\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3878 - accuracy: 0.8581 - val_loss: 0.3750 - val_accuracy: 0.8579 - lr: 0.0100\n",
            "Epoch 18/100\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3827 - accuracy: 0.8587 - val_loss: 0.3591 - val_accuracy: 0.8666 - lr: 0.0100\n",
            "Epoch 19/100\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3811 - accuracy: 0.8596 - val_loss: 0.3315 - val_accuracy: 0.8750 - lr: 0.0100\n",
            "Epoch 20/100\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3743 - accuracy: 0.8629 - val_loss: 0.3360 - val_accuracy: 0.8756 - lr: 0.0100\n",
            "Epoch 21/100\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3714 - accuracy: 0.8650 - val_loss: 0.3892 - val_accuracy: 0.8496 - lr: 0.0100\n",
            "Epoch 22/100\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3666 - accuracy: 0.8652 - val_loss: 0.3519 - val_accuracy: 0.8643 - lr: 0.0100\n",
            "Epoch 23/100\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3648 - accuracy: 0.8661 - val_loss: 0.4448 - val_accuracy: 0.8381 - lr: 0.0100\n",
            "Epoch 24/100\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3630 - accuracy: 0.8674 - val_loss: 0.4100 - val_accuracy: 0.8396 - lr: 0.0100\n",
            "Epoch 25/100\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3564 - accuracy: 0.8688 - val_loss: 0.3178 - val_accuracy: 0.8790 - lr: 0.0100\n",
            "Epoch 26/100\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3598 - accuracy: 0.8670 - val_loss: 0.3098 - val_accuracy: 0.8813 - lr: 0.0100\n",
            "Epoch 27/100\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3610 - accuracy: 0.8684 - val_loss: 0.3227 - val_accuracy: 0.8806 - lr: 0.0100\n",
            "Epoch 28/100\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3606 - accuracy: 0.8682 - val_loss: 0.3700 - val_accuracy: 0.8551 - lr: 0.0100\n",
            "Epoch 29/100\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3547 - accuracy: 0.8700 - val_loss: 0.3266 - val_accuracy: 0.8776 - lr: 0.0100\n",
            "Epoch 30/100\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3513 - accuracy: 0.8719 - val_loss: 0.3170 - val_accuracy: 0.8800 - lr: 0.0100\n",
            "Epoch 31/100\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3576 - accuracy: 0.8697 - val_loss: 0.5321 - val_accuracy: 0.8106 - lr: 0.0100\n",
            "Epoch 32/100\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3482 - accuracy: 0.8733 - val_loss: 0.3107 - val_accuracy: 0.8817 - lr: 0.0100\n",
            "Epoch 33/100\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3485 - accuracy: 0.8737 - val_loss: 0.3159 - val_accuracy: 0.8786 - lr: 0.0100\n",
            "Epoch 34/100\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3423 - accuracy: 0.8746 - val_loss: 0.2973 - val_accuracy: 0.8856 - lr: 0.0100\n",
            "Epoch 35/100\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3437 - accuracy: 0.8741 - val_loss: 0.3017 - val_accuracy: 0.8827 - lr: 0.0100\n",
            "Epoch 36/100\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3434 - accuracy: 0.8755 - val_loss: 0.3210 - val_accuracy: 0.8789 - lr: 0.0100\n",
            "Epoch 37/100\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3403 - accuracy: 0.8763 - val_loss: 0.3329 - val_accuracy: 0.8715 - lr: 0.0100\n",
            "Epoch 38/100\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3380 - accuracy: 0.8754 - val_loss: 0.4058 - val_accuracy: 0.8303 - lr: 0.0100\n",
            "Epoch 39/100\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3397 - accuracy: 0.8773 - val_loss: 0.3491 - val_accuracy: 0.8659 - lr: 0.0100\n",
            "Epoch 40/100\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3372 - accuracy: 0.8787 - val_loss: 0.3470 - val_accuracy: 0.8614 - lr: 0.0100\n",
            "Epoch 41/100\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3354 - accuracy: 0.8770 - val_loss: 0.3409 - val_accuracy: 0.8664 - lr: 0.0100\n",
            "Epoch 42/100\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3352 - accuracy: 0.8784 - val_loss: 0.2973 - val_accuracy: 0.8907 - lr: 0.0100\n",
            "Epoch 43/100\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3330 - accuracy: 0.8802 - val_loss: 0.4175 - val_accuracy: 0.8340 - lr: 0.0100\n",
            "Epoch 44/100\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3343 - accuracy: 0.8779 - val_loss: 0.3335 - val_accuracy: 0.8727 - lr: 0.0100\n",
            "Epoch 45/100\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3343 - accuracy: 0.8790 - val_loss: 0.3012 - val_accuracy: 0.8842 - lr: 0.0100\n",
            "Epoch 46/100\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3308 - accuracy: 0.8798 - val_loss: 0.3036 - val_accuracy: 0.8860 - lr: 0.0100\n",
            "Epoch 47/100\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3270 - accuracy: 0.8825 - val_loss: 0.3230 - val_accuracy: 0.8789 - lr: 0.0100\n",
            "Epoch 48/100\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3262 - accuracy: 0.8824 - val_loss: 0.3168 - val_accuracy: 0.8830 - lr: 0.0100\n",
            "Epoch 49/100\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3268 - accuracy: 0.8795 - val_loss: 0.2929 - val_accuracy: 0.8900 - lr: 0.0100\n",
            "Epoch 50/100\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3284 - accuracy: 0.8802 - val_loss: 0.3003 - val_accuracy: 0.8879 - lr: 0.0100\n",
            "Epoch 51/100\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3244 - accuracy: 0.8812 - val_loss: 0.3235 - val_accuracy: 0.8763 - lr: 0.0100\n",
            "Epoch 52/100\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3219 - accuracy: 0.8831 - val_loss: 0.3315 - val_accuracy: 0.8777 - lr: 0.0100\n",
            "Epoch 53/100\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3214 - accuracy: 0.8836 - val_loss: 0.3849 - val_accuracy: 0.8508 - lr: 0.0100\n",
            "Epoch 54/100\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3226 - accuracy: 0.8838 - val_loss: 0.2966 - val_accuracy: 0.8938 - lr: 0.0100\n",
            "Epoch 55/100\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3196 - accuracy: 0.8822 - val_loss: 0.4187 - val_accuracy: 0.8347 - lr: 0.0100\n",
            "Epoch 56/100\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3187 - accuracy: 0.8852 - val_loss: 0.2929 - val_accuracy: 0.8882 - lr: 0.0100\n",
            "Epoch 57/100\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3192 - accuracy: 0.8836 - val_loss: 0.3048 - val_accuracy: 0.8857 - lr: 0.0100\n",
            "Epoch 58/100\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3166 - accuracy: 0.8837 - val_loss: 0.2874 - val_accuracy: 0.8939 - lr: 0.0100\n",
            "Epoch 59/100\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3201 - accuracy: 0.8838 - val_loss: 0.2928 - val_accuracy: 0.8903 - lr: 0.0100\n",
            "Epoch 60/100\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3187 - accuracy: 0.8842 - val_loss: 0.3110 - val_accuracy: 0.8836 - lr: 0.0100\n",
            "Epoch 61/100\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3164 - accuracy: 0.8855 - val_loss: 0.3079 - val_accuracy: 0.8777 - lr: 0.0100\n",
            "Epoch 62/100\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3138 - accuracy: 0.8859 - val_loss: 0.2941 - val_accuracy: 0.8911 - lr: 0.0100\n",
            "Epoch 63/100\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3153 - accuracy: 0.8854 - val_loss: 0.2748 - val_accuracy: 0.8963 - lr: 0.0100\n",
            "Epoch 64/100\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3153 - accuracy: 0.8856 - val_loss: 0.2844 - val_accuracy: 0.8938 - lr: 0.0100\n",
            "Epoch 65/100\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3111 - accuracy: 0.8864 - val_loss: 0.3120 - val_accuracy: 0.8827 - lr: 0.0100\n",
            "Epoch 66/100\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3188 - accuracy: 0.8839 - val_loss: 0.3298 - val_accuracy: 0.8673 - lr: 0.0100\n",
            "Epoch 67/100\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3127 - accuracy: 0.8848 - val_loss: 0.3010 - val_accuracy: 0.8863 - lr: 0.0100\n",
            "Epoch 68/100\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3157 - accuracy: 0.8841 - val_loss: 0.2919 - val_accuracy: 0.8907 - lr: 0.0100\n",
            "Epoch 69/100\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3167 - accuracy: 0.8839 - val_loss: 0.2820 - val_accuracy: 0.8947 - lr: 0.0100\n",
            "Epoch 70/100\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3072 - accuracy: 0.8894 - val_loss: 0.2938 - val_accuracy: 0.8891 - lr: 0.0100\n",
            "Epoch 71/100\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3118 - accuracy: 0.8870 - val_loss: 0.3037 - val_accuracy: 0.8890 - lr: 0.0100\n",
            "Epoch 72/100\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3113 - accuracy: 0.8866 - val_loss: 0.2911 - val_accuracy: 0.8921 - lr: 0.0100\n",
            "Epoch 73/100\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3032 - accuracy: 0.8893 - val_loss: 0.3310 - val_accuracy: 0.8776 - lr: 0.0100\n",
            "Epoch 74/100\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3107 - accuracy: 0.8863 - val_loss: 0.2739 - val_accuracy: 0.9001 - lr: 0.0100\n",
            "Epoch 75/100\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3122 - accuracy: 0.8856 - val_loss: 0.2766 - val_accuracy: 0.8990 - lr: 0.0100\n",
            "Epoch 76/100\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3121 - accuracy: 0.8883 - val_loss: 0.3315 - val_accuracy: 0.8776 - lr: 0.0100\n",
            "Epoch 77/100\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3093 - accuracy: 0.8878 - val_loss: 0.2743 - val_accuracy: 0.8970 - lr: 0.0100\n",
            "Epoch 78/100\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3081 - accuracy: 0.8877 - val_loss: 0.3096 - val_accuracy: 0.8834 - lr: 0.0100\n",
            "Epoch 79/100\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3016 - accuracy: 0.8898 - val_loss: 0.3589 - val_accuracy: 0.8648 - lr: 0.0100\n",
            "Epoch 80/100\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3067 - accuracy: 0.8874 - val_loss: 0.3042 - val_accuracy: 0.8798 - lr: 0.0100\n",
            "Epoch 81/100\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3076 - accuracy: 0.8878 - val_loss: 0.3335 - val_accuracy: 0.8735 - lr: 0.0100\n",
            "Epoch 82/100\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3033 - accuracy: 0.8898 - val_loss: 0.2972 - val_accuracy: 0.8917 - lr: 0.0100\n",
            "Epoch 83/100\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3054 - accuracy: 0.8882 - val_loss: 0.2868 - val_accuracy: 0.8935 - lr: 0.0100\n",
            "Epoch 84/100\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3031 - accuracy: 0.8886 - val_loss: 0.2945 - val_accuracy: 0.8910 - lr: 0.0100\n",
            "Epoch 85/100\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3060 - accuracy: 0.8899 - val_loss: 0.2930 - val_accuracy: 0.8894 - lr: 0.0100\n",
            "Epoch 86/100\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3012 - accuracy: 0.8894 - val_loss: 0.2931 - val_accuracy: 0.8900 - lr: 0.0100\n",
            "Epoch 87/100\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3036 - accuracy: 0.8884 - val_loss: 0.2974 - val_accuracy: 0.8901 - lr: 0.0100\n",
            "Epoch 88/100\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3020 - accuracy: 0.8892 - val_loss: 0.3437 - val_accuracy: 0.8676 - lr: 0.0100\n",
            "Epoch 89/100\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2982 - accuracy: 0.8901 - val_loss: 0.2711 - val_accuracy: 0.8988 - lr: 0.0100\n",
            "Epoch 1/100\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.8972 - accuracy: 0.6763 - val_loss: 2.1958 - val_accuracy: 0.2404 - lr: 0.0100\n",
            "Epoch 2/100\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.6118 - accuracy: 0.7744 - val_loss: 1.7361 - val_accuracy: 0.2873 - lr: 0.0100\n",
            "Epoch 3/100\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.5449 - accuracy: 0.7989 - val_loss: 2.7649 - val_accuracy: 0.2286 - lr: 0.0100\n",
            "Epoch 4/100\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.5010 - accuracy: 0.8173 - val_loss: 1.5621 - val_accuracy: 0.4326 - lr: 0.0100\n",
            "Epoch 5/100\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4826 - accuracy: 0.8238 - val_loss: 1.0177 - val_accuracy: 0.6264 - lr: 0.0100\n",
            "Epoch 6/100\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4630 - accuracy: 0.8305 - val_loss: 0.6405 - val_accuracy: 0.7442 - lr: 0.0100\n",
            "Epoch 7/100\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4431 - accuracy: 0.8375 - val_loss: 0.4756 - val_accuracy: 0.8155 - lr: 0.0100\n",
            "Epoch 8/100\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4362 - accuracy: 0.8423 - val_loss: 0.3761 - val_accuracy: 0.8675 - lr: 0.0100\n",
            "Epoch 9/100\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4286 - accuracy: 0.8447 - val_loss: 0.4015 - val_accuracy: 0.8455 - lr: 0.0100\n",
            "Epoch 10/100\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4171 - accuracy: 0.8498 - val_loss: 0.4065 - val_accuracy: 0.8480 - lr: 0.0100\n",
            "Epoch 11/100\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4124 - accuracy: 0.8491 - val_loss: 0.4131 - val_accuracy: 0.8395 - lr: 0.0100\n",
            "Epoch 12/100\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4013 - accuracy: 0.8526 - val_loss: 0.3966 - val_accuracy: 0.8499 - lr: 0.0100\n",
            "Epoch 13/100\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4000 - accuracy: 0.8529 - val_loss: 0.3806 - val_accuracy: 0.8521 - lr: 0.0100\n",
            "Epoch 14/100\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3975 - accuracy: 0.8540 - val_loss: 0.3579 - val_accuracy: 0.8666 - lr: 0.0100\n",
            "Epoch 15/100\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3886 - accuracy: 0.8593 - val_loss: 0.3445 - val_accuracy: 0.8670 - lr: 0.0100\n",
            "Epoch 16/100\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3861 - accuracy: 0.8589 - val_loss: 0.3448 - val_accuracy: 0.8725 - lr: 0.0100\n",
            "Epoch 17/100\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3754 - accuracy: 0.8606 - val_loss: 0.3233 - val_accuracy: 0.8817 - lr: 0.0100\n",
            "Epoch 18/100\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3819 - accuracy: 0.8621 - val_loss: 0.3616 - val_accuracy: 0.8714 - lr: 0.0100\n",
            "Epoch 19/100\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3750 - accuracy: 0.8629 - val_loss: 0.3985 - val_accuracy: 0.8447 - lr: 0.0100\n",
            "Epoch 20/100\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3693 - accuracy: 0.8662 - val_loss: 0.3659 - val_accuracy: 0.8664 - lr: 0.0100\n",
            "Epoch 21/100\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3689 - accuracy: 0.8658 - val_loss: 0.5187 - val_accuracy: 0.8284 - lr: 0.0100\n",
            "Epoch 22/100\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3596 - accuracy: 0.8695 - val_loss: 0.3043 - val_accuracy: 0.8910 - lr: 0.0100\n",
            "Epoch 23/100\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3629 - accuracy: 0.8690 - val_loss: 0.3167 - val_accuracy: 0.8879 - lr: 0.0100\n",
            "Epoch 24/100\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3585 - accuracy: 0.8696 - val_loss: 0.2996 - val_accuracy: 0.8919 - lr: 0.0100\n",
            "Epoch 25/100\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3555 - accuracy: 0.8687 - val_loss: 0.3378 - val_accuracy: 0.8835 - lr: 0.0100\n",
            "Epoch 26/100\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3567 - accuracy: 0.8705 - val_loss: 0.3063 - val_accuracy: 0.8854 - lr: 0.0100\n",
            "Epoch 27/100\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3497 - accuracy: 0.8720 - val_loss: 0.3041 - val_accuracy: 0.8911 - lr: 0.0100\n",
            "Epoch 28/100\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3486 - accuracy: 0.8738 - val_loss: 0.3284 - val_accuracy: 0.8764 - lr: 0.0100\n",
            "Epoch 29/100\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3519 - accuracy: 0.8740 - val_loss: 0.3026 - val_accuracy: 0.8903 - lr: 0.0100\n",
            "Epoch 30/100\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3472 - accuracy: 0.8734 - val_loss: 0.3455 - val_accuracy: 0.8701 - lr: 0.0100\n",
            "Epoch 31/100\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3474 - accuracy: 0.8737 - val_loss: 0.3265 - val_accuracy: 0.8785 - lr: 0.0100\n",
            "Epoch 32/100\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3395 - accuracy: 0.8751 - val_loss: 0.3093 - val_accuracy: 0.8899 - lr: 0.0100\n",
            "Epoch 33/100\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3418 - accuracy: 0.8748 - val_loss: 0.3912 - val_accuracy: 0.8597 - lr: 0.0100\n",
            "Epoch 34/100\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3343 - accuracy: 0.8786 - val_loss: 0.3422 - val_accuracy: 0.8764 - lr: 0.0100\n",
            "Epoch 35/100\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3401 - accuracy: 0.8759 - val_loss: 0.2934 - val_accuracy: 0.8921 - lr: 0.0100\n",
            "Epoch 36/100\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3365 - accuracy: 0.8783 - val_loss: 0.3677 - val_accuracy: 0.8640 - lr: 0.0100\n",
            "Epoch 37/100\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3379 - accuracy: 0.8772 - val_loss: 0.3467 - val_accuracy: 0.8788 - lr: 0.0100\n",
            "Epoch 38/100\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3327 - accuracy: 0.8805 - val_loss: 0.3375 - val_accuracy: 0.8733 - lr: 0.0100\n",
            "Epoch 39/100\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3363 - accuracy: 0.8789 - val_loss: 0.2997 - val_accuracy: 0.8879 - lr: 0.0100\n",
            "Epoch 40/100\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3356 - accuracy: 0.8783 - val_loss: 0.2878 - val_accuracy: 0.8961 - lr: 0.0100\n",
            "Epoch 41/100\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3348 - accuracy: 0.8804 - val_loss: 0.3479 - val_accuracy: 0.8702 - lr: 0.0100\n",
            "Epoch 42/100\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3308 - accuracy: 0.8785 - val_loss: 0.3339 - val_accuracy: 0.8844 - lr: 0.0100\n",
            "Epoch 43/100\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3257 - accuracy: 0.8828 - val_loss: 0.3505 - val_accuracy: 0.8662 - lr: 0.0100\n",
            "Epoch 44/100\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3268 - accuracy: 0.8812 - val_loss: 0.2884 - val_accuracy: 0.8969 - lr: 0.0100\n",
            "Epoch 45/100\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3245 - accuracy: 0.8834 - val_loss: 0.3077 - val_accuracy: 0.8871 - lr: 0.0100\n",
            "Epoch 46/100\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3285 - accuracy: 0.8801 - val_loss: 0.3178 - val_accuracy: 0.8841 - lr: 0.0100\n",
            "Epoch 47/100\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3289 - accuracy: 0.8803 - val_loss: 0.3183 - val_accuracy: 0.8814 - lr: 0.0100\n",
            "Epoch 48/100\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3254 - accuracy: 0.8833 - val_loss: 0.3629 - val_accuracy: 0.8614 - lr: 0.0100\n",
            "Epoch 49/100\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3183 - accuracy: 0.8857 - val_loss: 0.2855 - val_accuracy: 0.8951 - lr: 0.0100\n",
            "Epoch 50/100\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3201 - accuracy: 0.8852 - val_loss: 0.3151 - val_accuracy: 0.8820 - lr: 0.0100\n",
            "Epoch 51/100\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3182 - accuracy: 0.8823 - val_loss: 0.4677 - val_accuracy: 0.8406 - lr: 0.0100\n",
            "Epoch 52/100\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3226 - accuracy: 0.8828 - val_loss: 0.2891 - val_accuracy: 0.8919 - lr: 0.0100\n",
            "Epoch 53/100\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3210 - accuracy: 0.8832 - val_loss: 0.2844 - val_accuracy: 0.9005 - lr: 0.0100\n",
            "Epoch 54/100\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3164 - accuracy: 0.8851 - val_loss: 0.2837 - val_accuracy: 0.8979 - lr: 0.0100\n",
            "Epoch 55/100\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3183 - accuracy: 0.8846 - val_loss: 0.3310 - val_accuracy: 0.8759 - lr: 0.0100\n",
            "Epoch 56/100\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3144 - accuracy: 0.8848 - val_loss: 0.2782 - val_accuracy: 0.8997 - lr: 0.0100\n",
            "Epoch 57/100\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3149 - accuracy: 0.8844 - val_loss: 0.3394 - val_accuracy: 0.8751 - lr: 0.0100\n",
            "Epoch 58/100\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3165 - accuracy: 0.8868 - val_loss: 0.2852 - val_accuracy: 0.9003 - lr: 0.0100\n",
            "Epoch 59/100\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3203 - accuracy: 0.8854 - val_loss: 0.2745 - val_accuracy: 0.9047 - lr: 0.0100\n",
            "Epoch 60/100\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3092 - accuracy: 0.8870 - val_loss: 0.2811 - val_accuracy: 0.9006 - lr: 0.0100\n",
            "Epoch 61/100\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3143 - accuracy: 0.8870 - val_loss: 0.2776 - val_accuracy: 0.8970 - lr: 0.0100\n",
            "Epoch 62/100\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3111 - accuracy: 0.8857 - val_loss: 0.2708 - val_accuracy: 0.9000 - lr: 0.0100\n",
            "Epoch 63/100\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3117 - accuracy: 0.8870 - val_loss: 0.2805 - val_accuracy: 0.8995 - lr: 0.0100\n",
            "Epoch 64/100\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3091 - accuracy: 0.8872 - val_loss: 0.2827 - val_accuracy: 0.8966 - lr: 0.0100\n",
            "Epoch 65/100\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3146 - accuracy: 0.8864 - val_loss: 0.3022 - val_accuracy: 0.8917 - lr: 0.0100\n",
            "Epoch 66/100\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3110 - accuracy: 0.8880 - val_loss: 0.2763 - val_accuracy: 0.8976 - lr: 0.0100\n",
            "Epoch 67/100\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3076 - accuracy: 0.8878 - val_loss: 0.2939 - val_accuracy: 0.8990 - lr: 0.0100\n",
            "Epoch 68/100\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3105 - accuracy: 0.8868 - val_loss: 0.2954 - val_accuracy: 0.8892 - lr: 0.0100\n",
            "Epoch 69/100\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3080 - accuracy: 0.8893 - val_loss: 0.2864 - val_accuracy: 0.8974 - lr: 0.0100\n",
            "Epoch 70/100\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3081 - accuracy: 0.8875 - val_loss: 0.2866 - val_accuracy: 0.8967 - lr: 0.0100\n",
            "Epoch 71/100\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3116 - accuracy: 0.8886 - val_loss: 0.2804 - val_accuracy: 0.8965 - lr: 0.0100\n",
            "Epoch 72/100\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3062 - accuracy: 0.8898 - val_loss: 0.3067 - val_accuracy: 0.8869 - lr: 0.0100\n",
            "Epoch 73/100\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3072 - accuracy: 0.8879 - val_loss: 0.3416 - val_accuracy: 0.8744 - lr: 0.0100\n",
            "Epoch 74/100\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3047 - accuracy: 0.8892 - val_loss: 0.2865 - val_accuracy: 0.8955 - lr: 0.0100\n",
            "Epoch 1/100\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.9119 - accuracy: 0.6728 - val_loss: 2.3433 - val_accuracy: 0.2485 - lr: 0.0100\n",
            "Epoch 2/100\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.6014 - accuracy: 0.7814 - val_loss: 1.9071 - val_accuracy: 0.3320 - lr: 0.0100\n",
            "Epoch 3/100\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.5418 - accuracy: 0.8049 - val_loss: 1.8103 - val_accuracy: 0.3750 - lr: 0.0100\n",
            "Epoch 4/100\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.5005 - accuracy: 0.8199 - val_loss: 1.3815 - val_accuracy: 0.5545 - lr: 0.0100\n",
            "Epoch 5/100\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4779 - accuracy: 0.8294 - val_loss: 1.0976 - val_accuracy: 0.5726 - lr: 0.0100\n",
            "Epoch 6/100\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4611 - accuracy: 0.8344 - val_loss: 0.7232 - val_accuracy: 0.7110 - lr: 0.0100\n",
            "Epoch 7/100\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4453 - accuracy: 0.8407 - val_loss: 0.6177 - val_accuracy: 0.7602 - lr: 0.0100\n",
            "Epoch 8/100\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4395 - accuracy: 0.8403 - val_loss: 0.4640 - val_accuracy: 0.8306 - lr: 0.0100\n",
            "Epoch 9/100\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4216 - accuracy: 0.8464 - val_loss: 0.4367 - val_accuracy: 0.8380 - lr: 0.0100\n",
            "Epoch 10/100\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4137 - accuracy: 0.8522 - val_loss: 0.4299 - val_accuracy: 0.8413 - lr: 0.0100\n",
            "Epoch 11/100\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4094 - accuracy: 0.8523 - val_loss: 0.4044 - val_accuracy: 0.8521 - lr: 0.0100\n",
            "Epoch 12/100\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4031 - accuracy: 0.8553 - val_loss: 0.5101 - val_accuracy: 0.7962 - lr: 0.0100\n",
            "Epoch 13/100\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3977 - accuracy: 0.8569 - val_loss: 0.3761 - val_accuracy: 0.8610 - lr: 0.0100\n",
            "Epoch 14/100\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3897 - accuracy: 0.8586 - val_loss: 0.3801 - val_accuracy: 0.8593 - lr: 0.0100\n",
            "Epoch 15/100\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3813 - accuracy: 0.8637 - val_loss: 0.3837 - val_accuracy: 0.8572 - lr: 0.0100\n",
            "Epoch 16/100\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3884 - accuracy: 0.8606 - val_loss: 0.3476 - val_accuracy: 0.8727 - lr: 0.0100\n",
            "Epoch 17/100\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3769 - accuracy: 0.8651 - val_loss: 0.4027 - val_accuracy: 0.8447 - lr: 0.0100\n",
            "Epoch 18/100\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3760 - accuracy: 0.8621 - val_loss: 0.3915 - val_accuracy: 0.8574 - lr: 0.0100\n",
            "Epoch 19/100\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3715 - accuracy: 0.8654 - val_loss: 0.3664 - val_accuracy: 0.8559 - lr: 0.0100\n",
            "Epoch 20/100\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3646 - accuracy: 0.8685 - val_loss: 0.3742 - val_accuracy: 0.8668 - lr: 0.0100\n",
            "Epoch 21/100\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3657 - accuracy: 0.8677 - val_loss: 0.4510 - val_accuracy: 0.8320 - lr: 0.0100\n",
            "Epoch 22/100\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3589 - accuracy: 0.8705 - val_loss: 0.5048 - val_accuracy: 0.8238 - lr: 0.0100\n",
            "Epoch 23/100\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3595 - accuracy: 0.8705 - val_loss: 0.3576 - val_accuracy: 0.8636 - lr: 0.0100\n",
            "Epoch 24/100\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3615 - accuracy: 0.8678 - val_loss: 0.3420 - val_accuracy: 0.8733 - lr: 0.0100\n",
            "Epoch 25/100\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3576 - accuracy: 0.8710 - val_loss: 0.3652 - val_accuracy: 0.8589 - lr: 0.0100\n",
            "Epoch 26/100\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3507 - accuracy: 0.8745 - val_loss: 0.3969 - val_accuracy: 0.8561 - lr: 0.0100\n",
            "Epoch 27/100\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3554 - accuracy: 0.8715 - val_loss: 0.3241 - val_accuracy: 0.8814 - lr: 0.0100\n",
            "Epoch 28/100\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3500 - accuracy: 0.8739 - val_loss: 0.3304 - val_accuracy: 0.8717 - lr: 0.0100\n",
            "Epoch 29/100\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3470 - accuracy: 0.8755 - val_loss: 0.3845 - val_accuracy: 0.8602 - lr: 0.0100\n",
            "Epoch 30/100\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3487 - accuracy: 0.8737 - val_loss: 0.3084 - val_accuracy: 0.8873 - lr: 0.0100\n",
            "Epoch 31/100\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3386 - accuracy: 0.8780 - val_loss: 0.3254 - val_accuracy: 0.8779 - lr: 0.0100\n",
            "Epoch 32/100\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3377 - accuracy: 0.8785 - val_loss: 0.3241 - val_accuracy: 0.8799 - lr: 0.0100\n",
            "Epoch 33/100\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3404 - accuracy: 0.8764 - val_loss: 0.3256 - val_accuracy: 0.8799 - lr: 0.0100\n",
            "Epoch 34/100\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3392 - accuracy: 0.8772 - val_loss: 0.3178 - val_accuracy: 0.8842 - lr: 0.0100\n",
            "Epoch 35/100\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3311 - accuracy: 0.8796 - val_loss: 0.4307 - val_accuracy: 0.8309 - lr: 0.0100\n",
            "Epoch 36/100\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3354 - accuracy: 0.8780 - val_loss: 0.3646 - val_accuracy: 0.8733 - lr: 0.0100\n",
            "Epoch 37/100\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3365 - accuracy: 0.8795 - val_loss: 0.3178 - val_accuracy: 0.8785 - lr: 0.0100\n",
            "Epoch 38/100\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3337 - accuracy: 0.8799 - val_loss: 0.3679 - val_accuracy: 0.8581 - lr: 0.0100\n",
            "Epoch 39/100\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3309 - accuracy: 0.8807 - val_loss: 0.3203 - val_accuracy: 0.8856 - lr: 0.0100\n",
            "Epoch 40/100\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3324 - accuracy: 0.8791 - val_loss: 0.4309 - val_accuracy: 0.8407 - lr: 0.0100\n",
            "Epoch 41/100\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3336 - accuracy: 0.8790 - val_loss: 0.2914 - val_accuracy: 0.8930 - lr: 0.0100\n",
            "Epoch 42/100\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3273 - accuracy: 0.8813 - val_loss: 0.3010 - val_accuracy: 0.8910 - lr: 0.0100\n",
            "Epoch 43/100\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3297 - accuracy: 0.8817 - val_loss: 0.3112 - val_accuracy: 0.8811 - lr: 0.0100\n",
            "Epoch 44/100\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3269 - accuracy: 0.8810 - val_loss: 0.3147 - val_accuracy: 0.8848 - lr: 0.0100\n",
            "Epoch 45/100\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3265 - accuracy: 0.8810 - val_loss: 0.3030 - val_accuracy: 0.8867 - lr: 0.0100\n",
            "Epoch 46/100\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3170 - accuracy: 0.8861 - val_loss: 0.3433 - val_accuracy: 0.8770 - lr: 0.0100\n",
            "Epoch 47/100\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3208 - accuracy: 0.8853 - val_loss: 0.3005 - val_accuracy: 0.8916 - lr: 0.0100\n",
            "Epoch 48/100\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3205 - accuracy: 0.8843 - val_loss: 0.2864 - val_accuracy: 0.8932 - lr: 0.0100\n",
            "Epoch 49/100\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3179 - accuracy: 0.8862 - val_loss: 0.3634 - val_accuracy: 0.8695 - lr: 0.0100\n",
            "Epoch 50/100\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3216 - accuracy: 0.8841 - val_loss: 0.3812 - val_accuracy: 0.8608 - lr: 0.0100\n",
            "Epoch 51/100\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3141 - accuracy: 0.8875 - val_loss: 0.2840 - val_accuracy: 0.8963 - lr: 0.0100\n",
            "Epoch 52/100\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3153 - accuracy: 0.8854 - val_loss: 0.3586 - val_accuracy: 0.8593 - lr: 0.0100\n",
            "Epoch 53/100\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3142 - accuracy: 0.8870 - val_loss: 0.3267 - val_accuracy: 0.8755 - lr: 0.0100\n",
            "Epoch 54/100\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3145 - accuracy: 0.8859 - val_loss: 0.2823 - val_accuracy: 0.8940 - lr: 0.0100\n",
            "Epoch 55/100\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3124 - accuracy: 0.8868 - val_loss: 0.2862 - val_accuracy: 0.8953 - lr: 0.0100\n",
            "Epoch 56/100\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3089 - accuracy: 0.8896 - val_loss: 0.3168 - val_accuracy: 0.8825 - lr: 0.0100\n",
            "Epoch 57/100\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3116 - accuracy: 0.8885 - val_loss: 0.3343 - val_accuracy: 0.8794 - lr: 0.0100\n",
            "Epoch 58/100\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3107 - accuracy: 0.8878 - val_loss: 0.2949 - val_accuracy: 0.8947 - lr: 0.0100\n",
            "Epoch 59/100\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3105 - accuracy: 0.8883 - val_loss: 0.4347 - val_accuracy: 0.8315 - lr: 0.0100\n",
            "Epoch 60/100\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3108 - accuracy: 0.8886 - val_loss: 0.3177 - val_accuracy: 0.8850 - lr: 0.0100\n",
            "Epoch 61/100\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3086 - accuracy: 0.8880 - val_loss: 0.2823 - val_accuracy: 0.8982 - lr: 0.0100\n",
            "Epoch 62/100\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3099 - accuracy: 0.8880 - val_loss: 0.3251 - val_accuracy: 0.8830 - lr: 0.0100\n",
            "Epoch 63/100\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3050 - accuracy: 0.8898 - val_loss: 0.3953 - val_accuracy: 0.8479 - lr: 0.0100\n",
            "Epoch 64/100\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3105 - accuracy: 0.8877 - val_loss: 0.2927 - val_accuracy: 0.8916 - lr: 0.0100\n",
            "Epoch 65/100\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3012 - accuracy: 0.8926 - val_loss: 0.3045 - val_accuracy: 0.8890 - lr: 0.0100\n",
            "Epoch 66/100\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3064 - accuracy: 0.8904 - val_loss: 0.2778 - val_accuracy: 0.9005 - lr: 0.0100\n",
            "Epoch 67/100\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3028 - accuracy: 0.8913 - val_loss: 0.3263 - val_accuracy: 0.8809 - lr: 0.0100\n",
            "Epoch 68/100\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3014 - accuracy: 0.8915 - val_loss: 0.2961 - val_accuracy: 0.8934 - lr: 0.0100\n",
            "Epoch 69/100\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2991 - accuracy: 0.8921 - val_loss: 0.3335 - val_accuracy: 0.8775 - lr: 0.0100\n",
            "Epoch 70/100\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2986 - accuracy: 0.8916 - val_loss: 0.2998 - val_accuracy: 0.8894 - lr: 0.0100\n",
            "Epoch 71/100\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2993 - accuracy: 0.8911 - val_loss: 0.2866 - val_accuracy: 0.8961 - lr: 0.0100\n",
            "Epoch 72/100\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3068 - accuracy: 0.8902 - val_loss: 0.3278 - val_accuracy: 0.8831 - lr: 0.0100\n",
            "Epoch 73/100\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2995 - accuracy: 0.8919 - val_loss: 0.4394 - val_accuracy: 0.8529 - lr: 0.0100\n",
            "Epoch 74/100\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2975 - accuracy: 0.8924 - val_loss: 0.3865 - val_accuracy: 0.8646 - lr: 0.0100\n",
            "Epoch 75/100\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2975 - accuracy: 0.8927 - val_loss: 0.2818 - val_accuracy: 0.8961 - lr: 0.0100\n",
            "Epoch 76/100\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2954 - accuracy: 0.8936 - val_loss: 0.3230 - val_accuracy: 0.8832 - lr: 0.0100\n",
            "Epoch 77/100\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3005 - accuracy: 0.8928 - val_loss: 0.2984 - val_accuracy: 0.8915 - lr: 0.0100\n",
            "Epoch 78/100\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2974 - accuracy: 0.8943 - val_loss: 0.4053 - val_accuracy: 0.8584 - lr: 0.0100\n",
            "Epoch 79/100\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2953 - accuracy: 0.8936 - val_loss: 0.2864 - val_accuracy: 0.8981 - lr: 0.0100\n",
            "Epoch 80/100\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2993 - accuracy: 0.8936 - val_loss: 0.3253 - val_accuracy: 0.8809 - lr: 0.0100\n",
            "Epoch 81/100\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2955 - accuracy: 0.8926 - val_loss: 0.2866 - val_accuracy: 0.8990 - lr: 0.0100\n",
            "Epoch 1/100\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.9071 - accuracy: 0.6741 - val_loss: 1.6376 - val_accuracy: 0.4830 - lr: 0.0100\n",
            "Epoch 2/100\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.6131 - accuracy: 0.7738 - val_loss: 1.9912 - val_accuracy: 0.2746 - lr: 0.0100\n",
            "Epoch 3/100\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.5407 - accuracy: 0.8027 - val_loss: 1.4168 - val_accuracy: 0.4308 - lr: 0.0100\n",
            "Epoch 4/100\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.5067 - accuracy: 0.8158 - val_loss: 1.0425 - val_accuracy: 0.6045 - lr: 0.0100\n",
            "Epoch 5/100\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4836 - accuracy: 0.8244 - val_loss: 0.6447 - val_accuracy: 0.7656 - lr: 0.0100\n",
            "Epoch 6/100\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4671 - accuracy: 0.8308 - val_loss: 0.5491 - val_accuracy: 0.7922 - lr: 0.0100\n",
            "Epoch 7/100\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4478 - accuracy: 0.8377 - val_loss: 0.4744 - val_accuracy: 0.8087 - lr: 0.0100\n",
            "Epoch 8/100\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4353 - accuracy: 0.8410 - val_loss: 0.4923 - val_accuracy: 0.8138 - lr: 0.0100\n",
            "Epoch 9/100\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4308 - accuracy: 0.8438 - val_loss: 0.5318 - val_accuracy: 0.7756 - lr: 0.0100\n",
            "Epoch 10/100\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4223 - accuracy: 0.8458 - val_loss: 0.3615 - val_accuracy: 0.8662 - lr: 0.0100\n",
            "Epoch 11/100\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4091 - accuracy: 0.8519 - val_loss: 0.4679 - val_accuracy: 0.8364 - lr: 0.0100\n",
            "Epoch 12/100\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4105 - accuracy: 0.8517 - val_loss: 0.5023 - val_accuracy: 0.8066 - lr: 0.0100\n",
            "Epoch 13/100\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3978 - accuracy: 0.8542 - val_loss: 0.4703 - val_accuracy: 0.8191 - lr: 0.0100\n",
            "Epoch 14/100\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3966 - accuracy: 0.8547 - val_loss: 0.3516 - val_accuracy: 0.8730 - lr: 0.0100\n",
            "Epoch 15/100\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3925 - accuracy: 0.8570 - val_loss: 0.3964 - val_accuracy: 0.8571 - lr: 0.0100\n",
            "Epoch 16/100\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3859 - accuracy: 0.8613 - val_loss: 0.3382 - val_accuracy: 0.8702 - lr: 0.0100\n",
            "Epoch 17/100\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3830 - accuracy: 0.8605 - val_loss: 0.3636 - val_accuracy: 0.8673 - lr: 0.0100\n",
            "Epoch 18/100\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3829 - accuracy: 0.8601 - val_loss: 0.3618 - val_accuracy: 0.8597 - lr: 0.0100\n",
            "Epoch 19/100\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3776 - accuracy: 0.8619 - val_loss: 0.4129 - val_accuracy: 0.8601 - lr: 0.0100\n",
            "Epoch 20/100\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3718 - accuracy: 0.8654 - val_loss: 0.3483 - val_accuracy: 0.8742 - lr: 0.0100\n",
            "Epoch 21/100\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3650 - accuracy: 0.8668 - val_loss: 0.4603 - val_accuracy: 0.8112 - lr: 0.0100\n",
            "Epoch 22/100\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3757 - accuracy: 0.8614 - val_loss: 0.3805 - val_accuracy: 0.8611 - lr: 0.0100\n",
            "Epoch 23/100\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3628 - accuracy: 0.8660 - val_loss: 0.3906 - val_accuracy: 0.8584 - lr: 0.0100\n",
            "Epoch 24/100\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3607 - accuracy: 0.8676 - val_loss: 0.3502 - val_accuracy: 0.8783 - lr: 0.0100\n",
            "Epoch 25/100\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3548 - accuracy: 0.8716 - val_loss: 0.4758 - val_accuracy: 0.8314 - lr: 0.0100\n",
            "Epoch 26/100\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3563 - accuracy: 0.8696 - val_loss: 0.3322 - val_accuracy: 0.8737 - lr: 0.0100\n",
            "Epoch 27/100\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3536 - accuracy: 0.8687 - val_loss: 0.3125 - val_accuracy: 0.8815 - lr: 0.0100\n",
            "Epoch 28/100\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3556 - accuracy: 0.8712 - val_loss: 0.3585 - val_accuracy: 0.8668 - lr: 0.0100\n",
            "Epoch 29/100\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3530 - accuracy: 0.8729 - val_loss: 0.3341 - val_accuracy: 0.8712 - lr: 0.0100\n",
            "Epoch 30/100\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3533 - accuracy: 0.8738 - val_loss: 0.3520 - val_accuracy: 0.8609 - lr: 0.0100\n",
            "Epoch 31/100\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3491 - accuracy: 0.8741 - val_loss: 0.3914 - val_accuracy: 0.8560 - lr: 0.0100\n",
            "Epoch 32/100\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3449 - accuracy: 0.8742 - val_loss: 0.4662 - val_accuracy: 0.8382 - lr: 0.0100\n",
            "Epoch 33/100\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3461 - accuracy: 0.8752 - val_loss: 0.3380 - val_accuracy: 0.8720 - lr: 0.0100\n",
            "Epoch 34/100\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3419 - accuracy: 0.8729 - val_loss: 0.3417 - val_accuracy: 0.8734 - lr: 0.0100\n",
            "Epoch 35/100\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3401 - accuracy: 0.8783 - val_loss: 0.4123 - val_accuracy: 0.8510 - lr: 0.0100\n",
            "Epoch 36/100\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3405 - accuracy: 0.8763 - val_loss: 0.3984 - val_accuracy: 0.8380 - lr: 0.0100\n",
            "Epoch 37/100\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3362 - accuracy: 0.8764 - val_loss: 0.3303 - val_accuracy: 0.8798 - lr: 0.0100\n",
            "Epoch 38/100\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3346 - accuracy: 0.8763 - val_loss: 0.3471 - val_accuracy: 0.8698 - lr: 0.0100\n",
            "Epoch 39/100\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3357 - accuracy: 0.8776 - val_loss: 0.3212 - val_accuracy: 0.8777 - lr: 0.0100\n",
            "Epoch 40/100\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3341 - accuracy: 0.8783 - val_loss: 0.4476 - val_accuracy: 0.8196 - lr: 0.0100\n",
            "Epoch 41/100\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3328 - accuracy: 0.8796 - val_loss: 0.3107 - val_accuracy: 0.8839 - lr: 0.0100\n",
            "Epoch 42/100\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3340 - accuracy: 0.8789 - val_loss: 0.3192 - val_accuracy: 0.8824 - lr: 0.0100\n",
            "Epoch 43/100\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3262 - accuracy: 0.8794 - val_loss: 0.3531 - val_accuracy: 0.8655 - lr: 0.0100\n",
            "Epoch 44/100\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3334 - accuracy: 0.8771 - val_loss: 0.2977 - val_accuracy: 0.8873 - lr: 0.0100\n",
            "Epoch 45/100\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3272 - accuracy: 0.8835 - val_loss: 0.3035 - val_accuracy: 0.8882 - lr: 0.0100\n",
            "Epoch 46/100\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3292 - accuracy: 0.8819 - val_loss: 0.3107 - val_accuracy: 0.8844 - lr: 0.0100\n",
            "Epoch 47/100\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3243 - accuracy: 0.8809 - val_loss: 0.3832 - val_accuracy: 0.8470 - lr: 0.0100\n",
            "Epoch 48/100\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3298 - accuracy: 0.8811 - val_loss: 0.3067 - val_accuracy: 0.8842 - lr: 0.0100\n",
            "Epoch 49/100\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3267 - accuracy: 0.8814 - val_loss: 0.3445 - val_accuracy: 0.8734 - lr: 0.0100\n",
            "Epoch 50/100\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3216 - accuracy: 0.8837 - val_loss: 0.3990 - val_accuracy: 0.8474 - lr: 0.0100\n",
            "Epoch 51/100\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3250 - accuracy: 0.8843 - val_loss: 0.4207 - val_accuracy: 0.8366 - lr: 0.0100\n",
            "Epoch 52/100\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3242 - accuracy: 0.8825 - val_loss: 0.3055 - val_accuracy: 0.8855 - lr: 0.0100\n",
            "Epoch 53/100\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3207 - accuracy: 0.8832 - val_loss: 0.3482 - val_accuracy: 0.8766 - lr: 0.0100\n",
            "Epoch 54/100\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3189 - accuracy: 0.8833 - val_loss: 0.2916 - val_accuracy: 0.8930 - lr: 0.0100\n",
            "Epoch 55/100\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3190 - accuracy: 0.8843 - val_loss: 0.2896 - val_accuracy: 0.8904 - lr: 0.0100\n",
            "Epoch 56/100\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3208 - accuracy: 0.8820 - val_loss: 0.3981 - val_accuracy: 0.8462 - lr: 0.0100\n",
            "Epoch 57/100\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3153 - accuracy: 0.8864 - val_loss: 0.3077 - val_accuracy: 0.8846 - lr: 0.0100\n",
            "Epoch 58/100\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3191 - accuracy: 0.8829 - val_loss: 0.2844 - val_accuracy: 0.8914 - lr: 0.0100\n",
            "Epoch 59/100\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3189 - accuracy: 0.8848 - val_loss: 0.2868 - val_accuracy: 0.8906 - lr: 0.0100\n",
            "Epoch 60/100\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3168 - accuracy: 0.8843 - val_loss: 0.4049 - val_accuracy: 0.8565 - lr: 0.0100\n",
            "Epoch 61/100\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3183 - accuracy: 0.8850 - val_loss: 0.3111 - val_accuracy: 0.8836 - lr: 0.0100\n",
            "Epoch 62/100\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3155 - accuracy: 0.8857 - val_loss: 0.3457 - val_accuracy: 0.8658 - lr: 0.0100\n",
            "Epoch 63/100\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3104 - accuracy: 0.8870 - val_loss: 0.3598 - val_accuracy: 0.8639 - lr: 0.0100\n",
            "Epoch 64/100\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3115 - accuracy: 0.8879 - val_loss: 0.2909 - val_accuracy: 0.8917 - lr: 0.0100\n",
            "Epoch 65/100\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3137 - accuracy: 0.8853 - val_loss: 0.3473 - val_accuracy: 0.8689 - lr: 0.0100\n",
            "Epoch 66/100\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3140 - accuracy: 0.8879 - val_loss: 0.2821 - val_accuracy: 0.8970 - lr: 0.0100\n",
            "Epoch 67/100\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3131 - accuracy: 0.8873 - val_loss: 0.2863 - val_accuracy: 0.8932 - lr: 0.0100\n",
            "Epoch 68/100\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3139 - accuracy: 0.8863 - val_loss: 0.3289 - val_accuracy: 0.8781 - lr: 0.0100\n",
            "Epoch 69/100\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3131 - accuracy: 0.8865 - val_loss: 0.2878 - val_accuracy: 0.8914 - lr: 0.0100\n",
            "Epoch 70/100\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3091 - accuracy: 0.8886 - val_loss: 0.3175 - val_accuracy: 0.8786 - lr: 0.0100\n",
            "Epoch 71/100\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3048 - accuracy: 0.8899 - val_loss: 0.3578 - val_accuracy: 0.8619 - lr: 0.0100\n",
            "Epoch 72/100\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3118 - accuracy: 0.8870 - val_loss: 0.2932 - val_accuracy: 0.8907 - lr: 0.0100\n",
            "Epoch 73/100\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3032 - accuracy: 0.8876 - val_loss: 0.2914 - val_accuracy: 0.8886 - lr: 0.0100\n",
            "Epoch 74/100\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3087 - accuracy: 0.8872 - val_loss: 0.3086 - val_accuracy: 0.8864 - lr: 0.0100\n",
            "Epoch 75/100\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3036 - accuracy: 0.8883 - val_loss: 0.3074 - val_accuracy: 0.8880 - lr: 0.0100\n",
            "Epoch 76/100\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3099 - accuracy: 0.8852 - val_loss: 0.2828 - val_accuracy: 0.8954 - lr: 0.0100\n",
            "Epoch 77/100\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3069 - accuracy: 0.8900 - val_loss: 0.3271 - val_accuracy: 0.8802 - lr: 0.0100\n",
            "Epoch 78/100\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3031 - accuracy: 0.8901 - val_loss: 0.3173 - val_accuracy: 0.8792 - lr: 0.0100\n",
            "Epoch 79/100\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3055 - accuracy: 0.8904 - val_loss: 0.2900 - val_accuracy: 0.8901 - lr: 0.0100\n",
            "Epoch 80/100\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3054 - accuracy: 0.8888 - val_loss: 0.3179 - val_accuracy: 0.8811 - lr: 0.0100\n",
            "Epoch 81/100\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3024 - accuracy: 0.8883 - val_loss: 0.4733 - val_accuracy: 0.8206 - lr: 0.0100\n",
            "Epoch 1/100\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.9034 - accuracy: 0.6736 - val_loss: 2.5137 - val_accuracy: 0.1629 - lr: 0.0100\n",
            "Epoch 2/100\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.6024 - accuracy: 0.7782 - val_loss: 1.5915 - val_accuracy: 0.4720 - lr: 0.0100\n",
            "Epoch 3/100\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.5437 - accuracy: 0.7998 - val_loss: 1.5093 - val_accuracy: 0.4293 - lr: 0.0100\n",
            "Epoch 4/100\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.5057 - accuracy: 0.8142 - val_loss: 1.1171 - val_accuracy: 0.5804 - lr: 0.0100\n",
            "Epoch 5/100\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4795 - accuracy: 0.8256 - val_loss: 1.1085 - val_accuracy: 0.5519 - lr: 0.0100\n",
            "Epoch 6/100\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4623 - accuracy: 0.8315 - val_loss: 0.7058 - val_accuracy: 0.7161 - lr: 0.0100\n",
            "Epoch 7/100\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4504 - accuracy: 0.8340 - val_loss: 0.4641 - val_accuracy: 0.8242 - lr: 0.0100\n",
            "Epoch 8/100\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4391 - accuracy: 0.8380 - val_loss: 0.4008 - val_accuracy: 0.8546 - lr: 0.0100\n",
            "Epoch 9/100\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4288 - accuracy: 0.8440 - val_loss: 0.4295 - val_accuracy: 0.8389 - lr: 0.0100\n",
            "Epoch 10/100\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4220 - accuracy: 0.8472 - val_loss: 0.3317 - val_accuracy: 0.8784 - lr: 0.0100\n",
            "Epoch 11/100\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4111 - accuracy: 0.8503 - val_loss: 0.4098 - val_accuracy: 0.8357 - lr: 0.0100\n",
            "Epoch 12/100\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4065 - accuracy: 0.8512 - val_loss: 0.4255 - val_accuracy: 0.8301 - lr: 0.0100\n",
            "Epoch 13/100\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4043 - accuracy: 0.8522 - val_loss: 0.3471 - val_accuracy: 0.8725 - lr: 0.0100\n",
            "Epoch 14/100\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3988 - accuracy: 0.8551 - val_loss: 0.3771 - val_accuracy: 0.8486 - lr: 0.0100\n",
            "Epoch 15/100\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3915 - accuracy: 0.8598 - val_loss: 0.3999 - val_accuracy: 0.8533 - lr: 0.0100\n",
            "Epoch 16/100\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3893 - accuracy: 0.8586 - val_loss: 0.3737 - val_accuracy: 0.8575 - lr: 0.0100\n",
            "Epoch 17/100\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3840 - accuracy: 0.8598 - val_loss: 0.3369 - val_accuracy: 0.8811 - lr: 0.0100\n",
            "Epoch 18/100\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3791 - accuracy: 0.8632 - val_loss: 0.3019 - val_accuracy: 0.8876 - lr: 0.0100\n",
            "Epoch 19/100\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3798 - accuracy: 0.8616 - val_loss: 0.3260 - val_accuracy: 0.8767 - lr: 0.0100\n",
            "Epoch 20/100\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3728 - accuracy: 0.8667 - val_loss: 0.3276 - val_accuracy: 0.8829 - lr: 0.0100\n",
            "Epoch 21/100\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3752 - accuracy: 0.8643 - val_loss: 0.3636 - val_accuracy: 0.8600 - lr: 0.0100\n",
            "Epoch 22/100\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3721 - accuracy: 0.8662 - val_loss: 0.3406 - val_accuracy: 0.8686 - lr: 0.0100\n",
            "Epoch 23/100\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3651 - accuracy: 0.8677 - val_loss: 0.3436 - val_accuracy: 0.8686 - lr: 0.0100\n",
            "Epoch 24/100\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3598 - accuracy: 0.8687 - val_loss: 0.3040 - val_accuracy: 0.8884 - lr: 0.0100\n",
            "Epoch 25/100\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3640 - accuracy: 0.8691 - val_loss: 0.3760 - val_accuracy: 0.8639 - lr: 0.0100\n",
            "Epoch 26/100\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3598 - accuracy: 0.8673 - val_loss: 0.3168 - val_accuracy: 0.8839 - lr: 0.0100\n",
            "Epoch 27/100\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3610 - accuracy: 0.8692 - val_loss: 0.3259 - val_accuracy: 0.8831 - lr: 0.0100\n",
            "Epoch 28/100\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3553 - accuracy: 0.8710 - val_loss: 0.3520 - val_accuracy: 0.8711 - lr: 0.0100\n",
            "Epoch 29/100\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3462 - accuracy: 0.8754 - val_loss: 0.3194 - val_accuracy: 0.8857 - lr: 0.0100\n",
            "Epoch 30/100\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3513 - accuracy: 0.8728 - val_loss: 0.3068 - val_accuracy: 0.8904 - lr: 0.0100\n",
            "Epoch 31/100\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3500 - accuracy: 0.8734 - val_loss: 0.3494 - val_accuracy: 0.8634 - lr: 0.0100\n",
            "Epoch 32/100\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3471 - accuracy: 0.8733 - val_loss: 0.3168 - val_accuracy: 0.8809 - lr: 0.0100\n",
            "Epoch 33/100\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3470 - accuracy: 0.8739 - val_loss: 0.2983 - val_accuracy: 0.8904 - lr: 0.0100\n",
            "Epoch 34/100\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3409 - accuracy: 0.8768 - val_loss: 0.3158 - val_accuracy: 0.8820 - lr: 0.0100\n",
            "Epoch 35/100\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3419 - accuracy: 0.8747 - val_loss: 0.3104 - val_accuracy: 0.8821 - lr: 0.0100\n",
            "Epoch 36/100\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3413 - accuracy: 0.8757 - val_loss: 0.2973 - val_accuracy: 0.8904 - lr: 0.0100\n",
            "Epoch 37/100\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3432 - accuracy: 0.8753 - val_loss: 0.2842 - val_accuracy: 0.8960 - lr: 0.0100\n",
            "Epoch 38/100\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3405 - accuracy: 0.8768 - val_loss: 0.2741 - val_accuracy: 0.8986 - lr: 0.0100\n",
            "Epoch 39/100\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3364 - accuracy: 0.8780 - val_loss: 0.3131 - val_accuracy: 0.8846 - lr: 0.0100\n",
            "Epoch 40/100\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3354 - accuracy: 0.8797 - val_loss: 0.3290 - val_accuracy: 0.8811 - lr: 0.0100\n",
            "Epoch 41/100\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3390 - accuracy: 0.8795 - val_loss: 0.2941 - val_accuracy: 0.8960 - lr: 0.0100\n",
            "Epoch 42/100\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3289 - accuracy: 0.8809 - val_loss: 0.2953 - val_accuracy: 0.8899 - lr: 0.0100\n",
            "Epoch 43/100\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3342 - accuracy: 0.8773 - val_loss: 0.4418 - val_accuracy: 0.8430 - lr: 0.0100\n",
            "Epoch 44/100\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3305 - accuracy: 0.8813 - val_loss: 0.3339 - val_accuracy: 0.8749 - lr: 0.0100\n",
            "Epoch 45/100\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3291 - accuracy: 0.8804 - val_loss: 0.3891 - val_accuracy: 0.8569 - lr: 0.0100\n",
            "Epoch 46/100\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3285 - accuracy: 0.8808 - val_loss: 0.2795 - val_accuracy: 0.8996 - lr: 0.0100\n",
            "Epoch 47/100\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3302 - accuracy: 0.8796 - val_loss: 0.2767 - val_accuracy: 0.8967 - lr: 0.0100\n",
            "Epoch 48/100\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3263 - accuracy: 0.8805 - val_loss: 0.2785 - val_accuracy: 0.9016 - lr: 0.0100\n",
            "Epoch 49/100\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3299 - accuracy: 0.8814 - val_loss: 0.2906 - val_accuracy: 0.8913 - lr: 0.0100\n",
            "Epoch 50/100\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3236 - accuracy: 0.8840 - val_loss: 0.3012 - val_accuracy: 0.8915 - lr: 0.0100\n",
            "Epoch 51/100\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3259 - accuracy: 0.8804 - val_loss: 0.2922 - val_accuracy: 0.8925 - lr: 0.0100\n",
            "Epoch 52/100\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3244 - accuracy: 0.8820 - val_loss: 0.2820 - val_accuracy: 0.8985 - lr: 0.0100\n",
            "Epoch 53/100\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3198 - accuracy: 0.8840 - val_loss: 0.3287 - val_accuracy: 0.8752 - lr: 0.0100\n",
            "Epoch 54/100\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3221 - accuracy: 0.8833 - val_loss: 0.2706 - val_accuracy: 0.9005 - lr: 0.0100\n",
            "Epoch 55/100\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3238 - accuracy: 0.8839 - val_loss: 0.3889 - val_accuracy: 0.8416 - lr: 0.0100\n",
            "Epoch 56/100\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3200 - accuracy: 0.8846 - val_loss: 0.4114 - val_accuracy: 0.8554 - lr: 0.0100\n",
            "Epoch 57/100\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3205 - accuracy: 0.8812 - val_loss: 0.3279 - val_accuracy: 0.8844 - lr: 0.0100\n",
            "Epoch 58/100\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3204 - accuracy: 0.8852 - val_loss: 0.4177 - val_accuracy: 0.8316 - lr: 0.0100\n",
            "Epoch 59/100\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3201 - accuracy: 0.8838 - val_loss: 0.3389 - val_accuracy: 0.8760 - lr: 0.0100\n",
            "Epoch 60/100\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3196 - accuracy: 0.8843 - val_loss: 0.2984 - val_accuracy: 0.8838 - lr: 0.0100\n",
            "Epoch 61/100\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3154 - accuracy: 0.8863 - val_loss: 0.2851 - val_accuracy: 0.8961 - lr: 0.0100\n",
            "Epoch 62/100\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3163 - accuracy: 0.8850 - val_loss: 0.3661 - val_accuracy: 0.8503 - lr: 0.0100\n",
            "Epoch 63/100\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3170 - accuracy: 0.8851 - val_loss: 0.3478 - val_accuracy: 0.8758 - lr: 0.0100\n",
            "Epoch 1/100\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.8964 - accuracy: 0.6789 - val_loss: 2.6017 - val_accuracy: 0.1861 - lr: 0.0100\n",
            "Epoch 2/100\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.6106 - accuracy: 0.7810 - val_loss: 1.9129 - val_accuracy: 0.2780 - lr: 0.0100\n",
            "Epoch 3/100\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.5402 - accuracy: 0.8060 - val_loss: 1.4389 - val_accuracy: 0.4445 - lr: 0.0100\n",
            "Epoch 4/100\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.5046 - accuracy: 0.8197 - val_loss: 1.4031 - val_accuracy: 0.4207 - lr: 0.0100\n",
            "Epoch 5/100\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4836 - accuracy: 0.8268 - val_loss: 0.7100 - val_accuracy: 0.7171 - lr: 0.0100\n",
            "Epoch 6/100\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4610 - accuracy: 0.8372 - val_loss: 0.5358 - val_accuracy: 0.8069 - lr: 0.0100\n",
            "Epoch 7/100\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4452 - accuracy: 0.8389 - val_loss: 0.5114 - val_accuracy: 0.7981 - lr: 0.0100\n",
            "Epoch 8/100\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4392 - accuracy: 0.8425 - val_loss: 0.4600 - val_accuracy: 0.8114 - lr: 0.0100\n",
            "Epoch 9/100\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4298 - accuracy: 0.8458 - val_loss: 0.4623 - val_accuracy: 0.8041 - lr: 0.0100\n",
            "Epoch 10/100\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4130 - accuracy: 0.8508 - val_loss: 0.4033 - val_accuracy: 0.8499 - lr: 0.0100\n",
            "Epoch 11/100\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4082 - accuracy: 0.8523 - val_loss: 0.3438 - val_accuracy: 0.8686 - lr: 0.0100\n",
            "Epoch 12/100\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4021 - accuracy: 0.8559 - val_loss: 0.3487 - val_accuracy: 0.8702 - lr: 0.0100\n",
            "Epoch 13/100\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3983 - accuracy: 0.8553 - val_loss: 0.3929 - val_accuracy: 0.8485 - lr: 0.0100\n",
            "Epoch 14/100\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4017 - accuracy: 0.8570 - val_loss: 0.4024 - val_accuracy: 0.8454 - lr: 0.0100\n",
            "Epoch 15/100\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3872 - accuracy: 0.8603 - val_loss: 0.3388 - val_accuracy: 0.8694 - lr: 0.0100\n",
            "Epoch 16/100\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3837 - accuracy: 0.8634 - val_loss: 0.3548 - val_accuracy: 0.8648 - lr: 0.0100\n",
            "Epoch 17/100\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3808 - accuracy: 0.8646 - val_loss: 0.3574 - val_accuracy: 0.8625 - lr: 0.0100\n",
            "Epoch 18/100\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3721 - accuracy: 0.8663 - val_loss: 0.4165 - val_accuracy: 0.8421 - lr: 0.0100\n",
            "Epoch 19/100\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3689 - accuracy: 0.8683 - val_loss: 0.3276 - val_accuracy: 0.8783 - lr: 0.0100\n",
            "Epoch 20/100\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3690 - accuracy: 0.8646 - val_loss: 0.3251 - val_accuracy: 0.8742 - lr: 0.0100\n",
            "Epoch 21/100\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3738 - accuracy: 0.8663 - val_loss: 0.3864 - val_accuracy: 0.8461 - lr: 0.0100\n",
            "Epoch 22/100\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3713 - accuracy: 0.8650 - val_loss: 0.3490 - val_accuracy: 0.8621 - lr: 0.0100\n",
            "Epoch 23/100\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3590 - accuracy: 0.8730 - val_loss: 0.3215 - val_accuracy: 0.8791 - lr: 0.0100\n",
            "Epoch 24/100\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3611 - accuracy: 0.8703 - val_loss: 0.3222 - val_accuracy: 0.8808 - lr: 0.0100\n",
            "Epoch 25/100\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3584 - accuracy: 0.8703 - val_loss: 0.2957 - val_accuracy: 0.8874 - lr: 0.0100\n",
            "Epoch 26/100\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3505 - accuracy: 0.8742 - val_loss: 0.3275 - val_accuracy: 0.8770 - lr: 0.0100\n",
            "Epoch 27/100\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3520 - accuracy: 0.8726 - val_loss: 0.3737 - val_accuracy: 0.8569 - lr: 0.0100\n",
            "Epoch 28/100\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3517 - accuracy: 0.8722 - val_loss: 0.3265 - val_accuracy: 0.8774 - lr: 0.0100\n",
            "Epoch 29/100\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3459 - accuracy: 0.8759 - val_loss: 0.3745 - val_accuracy: 0.8540 - lr: 0.0100\n",
            "Epoch 30/100\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3494 - accuracy: 0.8739 - val_loss: 0.3308 - val_accuracy: 0.8766 - lr: 0.0100\n",
            "Epoch 31/100\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3456 - accuracy: 0.8754 - val_loss: 0.4092 - val_accuracy: 0.8282 - lr: 0.0100\n",
            "Epoch 32/100\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3415 - accuracy: 0.8775 - val_loss: 0.3500 - val_accuracy: 0.8686 - lr: 0.0100\n",
            "Epoch 33/100\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3393 - accuracy: 0.8780 - val_loss: 0.2899 - val_accuracy: 0.8903 - lr: 0.0100\n",
            "Epoch 34/100\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3343 - accuracy: 0.8795 - val_loss: 0.3529 - val_accuracy: 0.8630 - lr: 0.0100\n",
            "Epoch 35/100\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3361 - accuracy: 0.8791 - val_loss: 0.3291 - val_accuracy: 0.8770 - lr: 0.0100\n",
            "Epoch 36/100\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3381 - accuracy: 0.8778 - val_loss: 0.3352 - val_accuracy: 0.8706 - lr: 0.0100\n",
            "Epoch 37/100\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3303 - accuracy: 0.8814 - val_loss: 0.3230 - val_accuracy: 0.8745 - lr: 0.0100\n",
            "Epoch 38/100\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3369 - accuracy: 0.8767 - val_loss: 0.3156 - val_accuracy: 0.8795 - lr: 0.0100\n",
            "Epoch 39/100\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3312 - accuracy: 0.8810 - val_loss: 0.3050 - val_accuracy: 0.8835 - lr: 0.0100\n",
            "Epoch 40/100\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3293 - accuracy: 0.8813 - val_loss: 0.3700 - val_accuracy: 0.8571 - lr: 0.0100\n",
            "Epoch 41/100\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3308 - accuracy: 0.8787 - val_loss: 0.3012 - val_accuracy: 0.8873 - lr: 0.0100\n",
            "Epoch 42/100\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3303 - accuracy: 0.8796 - val_loss: 0.2975 - val_accuracy: 0.8904 - lr: 0.0100\n",
            "Epoch 43/100\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3264 - accuracy: 0.8812 - val_loss: 0.2988 - val_accuracy: 0.8894 - lr: 0.0100\n",
            "Epoch 44/100\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3241 - accuracy: 0.8814 - val_loss: 0.2900 - val_accuracy: 0.8905 - lr: 0.0100\n",
            "Epoch 45/100\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3237 - accuracy: 0.8825 - val_loss: 0.2933 - val_accuracy: 0.8875 - lr: 0.0100\n",
            "Epoch 46/100\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3233 - accuracy: 0.8828 - val_loss: 0.3041 - val_accuracy: 0.8869 - lr: 0.0100\n",
            "Epoch 47/100\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3160 - accuracy: 0.8862 - val_loss: 0.3507 - val_accuracy: 0.8680 - lr: 0.0100\n",
            "Epoch 48/100\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3242 - accuracy: 0.8824 - val_loss: 0.2882 - val_accuracy: 0.8942 - lr: 0.0100\n",
            "Epoch 49/100\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3281 - accuracy: 0.8809 - val_loss: 0.2896 - val_accuracy: 0.8932 - lr: 0.0100\n",
            "Epoch 50/100\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3220 - accuracy: 0.8835 - val_loss: 0.3373 - val_accuracy: 0.8727 - lr: 0.0100\n",
            "Epoch 51/100\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3184 - accuracy: 0.8834 - val_loss: 0.2940 - val_accuracy: 0.8901 - lr: 0.0100\n",
            "Epoch 52/100\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3238 - accuracy: 0.8817 - val_loss: 0.2785 - val_accuracy: 0.8965 - lr: 0.0100\n",
            "Epoch 53/100\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3217 - accuracy: 0.8829 - val_loss: 0.2842 - val_accuracy: 0.8939 - lr: 0.0100\n",
            "Epoch 54/100\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3183 - accuracy: 0.8860 - val_loss: 0.2906 - val_accuracy: 0.8925 - lr: 0.0100\n",
            "Epoch 55/100\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3183 - accuracy: 0.8850 - val_loss: 0.2860 - val_accuracy: 0.8905 - lr: 0.0100\n",
            "Epoch 56/100\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3166 - accuracy: 0.8864 - val_loss: 0.2767 - val_accuracy: 0.8946 - lr: 0.0100\n",
            "Epoch 57/100\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3168 - accuracy: 0.8871 - val_loss: 0.2806 - val_accuracy: 0.8959 - lr: 0.0100\n",
            "Epoch 58/100\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3151 - accuracy: 0.8846 - val_loss: 0.2822 - val_accuracy: 0.8936 - lr: 0.0100\n",
            "Epoch 59/100\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3116 - accuracy: 0.8873 - val_loss: 0.3041 - val_accuracy: 0.8895 - lr: 0.0100\n",
            "Epoch 60/100\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3100 - accuracy: 0.8880 - val_loss: 0.3335 - val_accuracy: 0.8758 - lr: 0.0100\n",
            "Epoch 61/100\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3137 - accuracy: 0.8849 - val_loss: 0.3078 - val_accuracy: 0.8854 - lr: 0.0100\n",
            "Epoch 62/100\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3084 - accuracy: 0.8879 - val_loss: 0.2738 - val_accuracy: 0.8982 - lr: 0.0100\n",
            "Epoch 63/100\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3024 - accuracy: 0.8908 - val_loss: 0.3217 - val_accuracy: 0.8850 - lr: 0.0100\n",
            "Epoch 64/100\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3083 - accuracy: 0.8888 - val_loss: 0.2763 - val_accuracy: 0.8957 - lr: 0.0100\n",
            "Epoch 65/100\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3098 - accuracy: 0.8866 - val_loss: 0.3339 - val_accuracy: 0.8751 - lr: 0.0100\n",
            "Epoch 66/100\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3078 - accuracy: 0.8878 - val_loss: 0.2928 - val_accuracy: 0.8906 - lr: 0.0100\n",
            "Epoch 67/100\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3059 - accuracy: 0.8881 - val_loss: 0.2873 - val_accuracy: 0.8923 - lr: 0.0100\n",
            "Epoch 68/100\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3084 - accuracy: 0.8879 - val_loss: 0.2839 - val_accuracy: 0.8956 - lr: 0.0100\n",
            "Epoch 69/100\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3078 - accuracy: 0.8878 - val_loss: 0.2758 - val_accuracy: 0.8941 - lr: 0.0100\n",
            "Epoch 70/100\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3099 - accuracy: 0.8896 - val_loss: 0.3333 - val_accuracy: 0.8754 - lr: 0.0100\n",
            "Epoch 71/100\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3071 - accuracy: 0.8882 - val_loss: 0.2905 - val_accuracy: 0.8931 - lr: 0.0100\n",
            "Epoch 72/100\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3123 - accuracy: 0.8865 - val_loss: 0.2950 - val_accuracy: 0.8910 - lr: 0.0100\n",
            "Epoch 73/100\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3043 - accuracy: 0.8882 - val_loss: 0.2874 - val_accuracy: 0.8915 - lr: 0.0100\n",
            "Epoch 74/100\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3031 - accuracy: 0.8904 - val_loss: 0.3264 - val_accuracy: 0.8830 - lr: 0.0100\n",
            "Epoch 75/100\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3051 - accuracy: 0.8891 - val_loss: 0.2962 - val_accuracy: 0.8899 - lr: 0.0100\n",
            "Epoch 76/100\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2980 - accuracy: 0.8919 - val_loss: 0.3046 - val_accuracy: 0.8886 - lr: 0.0100\n",
            "Epoch 77/100\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3065 - accuracy: 0.8888 - val_loss: 0.3543 - val_accuracy: 0.8676 - lr: 0.0100\n",
            "Epoch 1/100\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.8781 - accuracy: 0.6837 - val_loss: 2.1370 - val_accuracy: 0.1510 - lr: 0.0100\n",
            "Epoch 2/100\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.6090 - accuracy: 0.7794 - val_loss: 2.0998 - val_accuracy: 0.2599 - lr: 0.0100\n",
            "Epoch 3/100\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.5444 - accuracy: 0.8047 - val_loss: 2.0063 - val_accuracy: 0.3079 - lr: 0.0100\n",
            "Epoch 4/100\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.5143 - accuracy: 0.8129 - val_loss: 1.0183 - val_accuracy: 0.5730 - lr: 0.0100\n",
            "Epoch 5/100\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4875 - accuracy: 0.8264 - val_loss: 0.7946 - val_accuracy: 0.6976 - lr: 0.0100\n",
            "Epoch 6/100\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4636 - accuracy: 0.8341 - val_loss: 0.7100 - val_accuracy: 0.7103 - lr: 0.0100\n",
            "Epoch 7/100\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4507 - accuracy: 0.8383 - val_loss: 0.6346 - val_accuracy: 0.7214 - lr: 0.0100\n",
            "Epoch 8/100\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4349 - accuracy: 0.8423 - val_loss: 0.4638 - val_accuracy: 0.8214 - lr: 0.0100\n",
            "Epoch 9/100\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4275 - accuracy: 0.8468 - val_loss: 0.4907 - val_accuracy: 0.7924 - lr: 0.0100\n",
            "Epoch 10/100\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4152 - accuracy: 0.8497 - val_loss: 0.3926 - val_accuracy: 0.8493 - lr: 0.0100\n",
            "Epoch 11/100\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4173 - accuracy: 0.8470 - val_loss: 0.3857 - val_accuracy: 0.8533 - lr: 0.0100\n",
            "Epoch 12/100\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4096 - accuracy: 0.8514 - val_loss: 0.3476 - val_accuracy: 0.8660 - lr: 0.0100\n",
            "Epoch 13/100\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3973 - accuracy: 0.8568 - val_loss: 0.3526 - val_accuracy: 0.8691 - lr: 0.0100\n",
            "Epoch 14/100\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4000 - accuracy: 0.8555 - val_loss: 0.4795 - val_accuracy: 0.8085 - lr: 0.0100\n",
            "Epoch 15/100\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3935 - accuracy: 0.8572 - val_loss: 0.3374 - val_accuracy: 0.8734 - lr: 0.0100\n",
            "Epoch 16/100\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3933 - accuracy: 0.8569 - val_loss: 0.3487 - val_accuracy: 0.8611 - lr: 0.0100\n",
            "Epoch 17/100\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3822 - accuracy: 0.8630 - val_loss: 0.3771 - val_accuracy: 0.8566 - lr: 0.0100\n",
            "Epoch 18/100\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3801 - accuracy: 0.8630 - val_loss: 0.4217 - val_accuracy: 0.8310 - lr: 0.0100\n",
            "Epoch 19/100\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3736 - accuracy: 0.8648 - val_loss: 0.3128 - val_accuracy: 0.8829 - lr: 0.0100\n",
            "Epoch 20/100\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3733 - accuracy: 0.8642 - val_loss: 0.3220 - val_accuracy: 0.8776 - lr: 0.0100\n",
            "Epoch 21/100\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3714 - accuracy: 0.8659 - val_loss: 0.4201 - val_accuracy: 0.8419 - lr: 0.0100\n",
            "Epoch 22/100\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3718 - accuracy: 0.8649 - val_loss: 0.3097 - val_accuracy: 0.8819 - lr: 0.0100\n",
            "Epoch 23/100\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3635 - accuracy: 0.8678 - val_loss: 0.3300 - val_accuracy: 0.8725 - lr: 0.0100\n",
            "Epoch 24/100\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3634 - accuracy: 0.8698 - val_loss: 0.3225 - val_accuracy: 0.8780 - lr: 0.0100\n",
            "Epoch 25/100\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3571 - accuracy: 0.8702 - val_loss: 0.3077 - val_accuracy: 0.8831 - lr: 0.0100\n",
            "Epoch 26/100\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3582 - accuracy: 0.8697 - val_loss: 0.3857 - val_accuracy: 0.8494 - lr: 0.0100\n",
            "Epoch 27/100\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3599 - accuracy: 0.8689 - val_loss: 0.3412 - val_accuracy: 0.8726 - lr: 0.0100\n",
            "Epoch 28/100\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3605 - accuracy: 0.8703 - val_loss: 0.3170 - val_accuracy: 0.8823 - lr: 0.0100\n",
            "Epoch 29/100\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3544 - accuracy: 0.8725 - val_loss: 0.3800 - val_accuracy: 0.8460 - lr: 0.0100\n",
            "Epoch 30/100\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3521 - accuracy: 0.8714 - val_loss: 0.3018 - val_accuracy: 0.8855 - lr: 0.0100\n",
            "Epoch 31/100\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3529 - accuracy: 0.8718 - val_loss: 0.3918 - val_accuracy: 0.8585 - lr: 0.0100\n",
            "Epoch 32/100\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3470 - accuracy: 0.8737 - val_loss: 0.3280 - val_accuracy: 0.8733 - lr: 0.0100\n",
            "Epoch 33/100\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3505 - accuracy: 0.8728 - val_loss: 0.3112 - val_accuracy: 0.8816 - lr: 0.0100\n",
            "Epoch 34/100\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3461 - accuracy: 0.8758 - val_loss: 0.3773 - val_accuracy: 0.8500 - lr: 0.0100\n",
            "Epoch 35/100\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3434 - accuracy: 0.8754 - val_loss: 0.2996 - val_accuracy: 0.8898 - lr: 0.0100\n",
            "Epoch 36/100\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3458 - accuracy: 0.8748 - val_loss: 0.3029 - val_accuracy: 0.8844 - lr: 0.0100\n",
            "Epoch 37/100\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3398 - accuracy: 0.8771 - val_loss: 0.2955 - val_accuracy: 0.8901 - lr: 0.0100\n",
            "Epoch 38/100\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3406 - accuracy: 0.8760 - val_loss: 0.3326 - val_accuracy: 0.8705 - lr: 0.0100\n",
            "Epoch 39/100\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3396 - accuracy: 0.8763 - val_loss: 0.2925 - val_accuracy: 0.8871 - lr: 0.0100\n",
            "Epoch 40/100\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3381 - accuracy: 0.8763 - val_loss: 0.3531 - val_accuracy: 0.8644 - lr: 0.0100\n",
            "Epoch 41/100\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3363 - accuracy: 0.8769 - val_loss: 0.3628 - val_accuracy: 0.8680 - lr: 0.0100\n",
            "Epoch 42/100\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3393 - accuracy: 0.8769 - val_loss: 0.3333 - val_accuracy: 0.8775 - lr: 0.0100\n",
            "Epoch 43/100\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3324 - accuracy: 0.8802 - val_loss: 0.3302 - val_accuracy: 0.8737 - lr: 0.0100\n",
            "Epoch 44/100\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3344 - accuracy: 0.8785 - val_loss: 0.2901 - val_accuracy: 0.8915 - lr: 0.0100\n",
            "Epoch 45/100\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3362 - accuracy: 0.8777 - val_loss: 0.2902 - val_accuracy: 0.8909 - lr: 0.0100\n",
            "Epoch 46/100\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3346 - accuracy: 0.8767 - val_loss: 0.3539 - val_accuracy: 0.8610 - lr: 0.0100\n",
            "Epoch 47/100\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3333 - accuracy: 0.8776 - val_loss: 0.2870 - val_accuracy: 0.8945 - lr: 0.0100\n",
            "Epoch 48/100\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3314 - accuracy: 0.8792 - val_loss: 0.3085 - val_accuracy: 0.8886 - lr: 0.0100\n",
            "Epoch 49/100\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3273 - accuracy: 0.8827 - val_loss: 0.3025 - val_accuracy: 0.8845 - lr: 0.0100\n",
            "Epoch 50/100\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3249 - accuracy: 0.8820 - val_loss: 0.3883 - val_accuracy: 0.8511 - lr: 0.0100\n",
            "Epoch 51/100\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3260 - accuracy: 0.8828 - val_loss: 0.3778 - val_accuracy: 0.8441 - lr: 0.0100\n",
            "Epoch 52/100\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3322 - accuracy: 0.8799 - val_loss: 0.2976 - val_accuracy: 0.8842 - lr: 0.0100\n",
            "Epoch 53/100\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3225 - accuracy: 0.8833 - val_loss: 0.3795 - val_accuracy: 0.8547 - lr: 0.0100\n",
            "Epoch 54/100\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3221 - accuracy: 0.8846 - val_loss: 0.3954 - val_accuracy: 0.8460 - lr: 0.0100\n",
            "Epoch 55/100\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3317 - accuracy: 0.8797 - val_loss: 0.3919 - val_accuracy: 0.8424 - lr: 0.0100\n",
            "Epoch 56/100\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3222 - accuracy: 0.8834 - val_loss: 0.3126 - val_accuracy: 0.8780 - lr: 0.0100\n",
            "Epoch 57/100\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3188 - accuracy: 0.8845 - val_loss: 0.2882 - val_accuracy: 0.8923 - lr: 0.0100\n",
            "Epoch 58/100\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3215 - accuracy: 0.8830 - val_loss: 0.2788 - val_accuracy: 0.8921 - lr: 0.0100\n",
            "Epoch 59/100\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3182 - accuracy: 0.8848 - val_loss: 0.3304 - val_accuracy: 0.8764 - lr: 0.0100\n",
            "Epoch 60/100\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3200 - accuracy: 0.8848 - val_loss: 0.3516 - val_accuracy: 0.8579 - lr: 0.0100\n",
            "Epoch 61/100\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3227 - accuracy: 0.8813 - val_loss: 0.3116 - val_accuracy: 0.8823 - lr: 0.0100\n",
            "Epoch 62/100\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3236 - accuracy: 0.8818 - val_loss: 0.3925 - val_accuracy: 0.8489 - lr: 0.0100\n",
            "Epoch 1/100\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.8987 - accuracy: 0.6732 - val_loss: 1.9670 - val_accuracy: 0.2903 - lr: 0.0100\n",
            "Epoch 2/100\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.6272 - accuracy: 0.7669 - val_loss: 2.9678 - val_accuracy: 0.1399 - lr: 0.0100\n",
            "Epoch 3/100\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.5610 - accuracy: 0.7949 - val_loss: 2.3051 - val_accuracy: 0.2029 - lr: 0.0100\n",
            "Epoch 4/100\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.5233 - accuracy: 0.8078 - val_loss: 2.0819 - val_accuracy: 0.3186 - lr: 0.0100\n",
            "Epoch 5/100\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4890 - accuracy: 0.8226 - val_loss: 0.9500 - val_accuracy: 0.6586 - lr: 0.0100\n",
            "Epoch 6/100\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4721 - accuracy: 0.8277 - val_loss: 0.6307 - val_accuracy: 0.7884 - lr: 0.0100\n",
            "Epoch 7/100\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4567 - accuracy: 0.8333 - val_loss: 0.5836 - val_accuracy: 0.7763 - lr: 0.0100\n",
            "Epoch 8/100\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4489 - accuracy: 0.8375 - val_loss: 0.4796 - val_accuracy: 0.8055 - lr: 0.0100\n",
            "Epoch 9/100\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4343 - accuracy: 0.8419 - val_loss: 0.4441 - val_accuracy: 0.8332 - lr: 0.0100\n",
            "Epoch 10/100\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4306 - accuracy: 0.8431 - val_loss: 0.4127 - val_accuracy: 0.8432 - lr: 0.0100\n",
            "Epoch 11/100\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4226 - accuracy: 0.8473 - val_loss: 0.4186 - val_accuracy: 0.8390 - lr: 0.0100\n",
            "Epoch 12/100\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4098 - accuracy: 0.8522 - val_loss: 0.3233 - val_accuracy: 0.8840 - lr: 0.0100\n",
            "Epoch 13/100\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4037 - accuracy: 0.8539 - val_loss: 0.3193 - val_accuracy: 0.8873 - lr: 0.0100\n",
            "Epoch 14/100\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4022 - accuracy: 0.8544 - val_loss: 0.3167 - val_accuracy: 0.8867 - lr: 0.0100\n",
            "Epoch 15/100\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3916 - accuracy: 0.8564 - val_loss: 0.3116 - val_accuracy: 0.8840 - lr: 0.0100\n",
            "Epoch 16/100\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3880 - accuracy: 0.8596 - val_loss: 0.3067 - val_accuracy: 0.8911 - lr: 0.0100\n",
            "Epoch 17/100\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3811 - accuracy: 0.8619 - val_loss: 0.3551 - val_accuracy: 0.8662 - lr: 0.0100\n",
            "Epoch 18/100\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3800 - accuracy: 0.8622 - val_loss: 0.3307 - val_accuracy: 0.8849 - lr: 0.0100\n",
            "Epoch 19/100\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3829 - accuracy: 0.8619 - val_loss: 0.3085 - val_accuracy: 0.8873 - lr: 0.0100\n",
            "Epoch 20/100\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3756 - accuracy: 0.8637 - val_loss: 0.3803 - val_accuracy: 0.8558 - lr: 0.0100\n",
            "Epoch 21/100\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3780 - accuracy: 0.8623 - val_loss: 0.3172 - val_accuracy: 0.8834 - lr: 0.0100\n",
            "Epoch 22/100\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3727 - accuracy: 0.8635 - val_loss: 0.3097 - val_accuracy: 0.8846 - lr: 0.0100\n",
            "Epoch 23/100\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3729 - accuracy: 0.8643 - val_loss: 0.3167 - val_accuracy: 0.8826 - lr: 0.0100\n",
            "Epoch 24/100\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3658 - accuracy: 0.8684 - val_loss: 0.3076 - val_accuracy: 0.8923 - lr: 0.0100\n",
            "Epoch 25/100\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3629 - accuracy: 0.8689 - val_loss: 0.3469 - val_accuracy: 0.8694 - lr: 0.0100\n",
            "Epoch 26/100\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3561 - accuracy: 0.8706 - val_loss: 0.3060 - val_accuracy: 0.8907 - lr: 0.0100\n",
            "Epoch 27/100\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3644 - accuracy: 0.8673 - val_loss: 0.3156 - val_accuracy: 0.8802 - lr: 0.0100\n",
            "Epoch 28/100\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3624 - accuracy: 0.8706 - val_loss: 0.3048 - val_accuracy: 0.8881 - lr: 0.0100\n",
            "Epoch 29/100\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3529 - accuracy: 0.8744 - val_loss: 0.3143 - val_accuracy: 0.8790 - lr: 0.0100\n",
            "Epoch 30/100\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3557 - accuracy: 0.8714 - val_loss: 0.3123 - val_accuracy: 0.8826 - lr: 0.0100\n",
            "Epoch 31/100\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3541 - accuracy: 0.8701 - val_loss: 0.3064 - val_accuracy: 0.8846 - lr: 0.0100\n",
            "Epoch 32/100\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3525 - accuracy: 0.8723 - val_loss: 0.2892 - val_accuracy: 0.8940 - lr: 0.0100\n",
            "Epoch 33/100\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3496 - accuracy: 0.8734 - val_loss: 0.3025 - val_accuracy: 0.8875 - lr: 0.0100\n",
            "Epoch 34/100\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3485 - accuracy: 0.8725 - val_loss: 0.2920 - val_accuracy: 0.8961 - lr: 0.0100\n",
            "Epoch 35/100\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3461 - accuracy: 0.8744 - val_loss: 0.2858 - val_accuracy: 0.8984 - lr: 0.0100\n",
            "Epoch 36/100\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3429 - accuracy: 0.8761 - val_loss: 0.2973 - val_accuracy: 0.8931 - lr: 0.0100\n",
            "Epoch 37/100\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3431 - accuracy: 0.8755 - val_loss: 0.2856 - val_accuracy: 0.8957 - lr: 0.0100\n",
            "Epoch 38/100\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3414 - accuracy: 0.8757 - val_loss: 0.3989 - val_accuracy: 0.8460 - lr: 0.0100\n",
            "Epoch 39/100\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3362 - accuracy: 0.8795 - val_loss: 0.3047 - val_accuracy: 0.8885 - lr: 0.0100\n",
            "Epoch 40/100\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3399 - accuracy: 0.8791 - val_loss: 0.2913 - val_accuracy: 0.8942 - lr: 0.0100\n",
            "Epoch 41/100\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3392 - accuracy: 0.8750 - val_loss: 0.3379 - val_accuracy: 0.8773 - lr: 0.0100\n",
            "Epoch 42/100\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3368 - accuracy: 0.8760 - val_loss: 0.2836 - val_accuracy: 0.8965 - lr: 0.0100\n",
            "Epoch 43/100\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3319 - accuracy: 0.8805 - val_loss: 0.3614 - val_accuracy: 0.8564 - lr: 0.0100\n",
            "Epoch 44/100\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3418 - accuracy: 0.8766 - val_loss: 0.2800 - val_accuracy: 0.9006 - lr: 0.0100\n",
            "Epoch 45/100\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3341 - accuracy: 0.8797 - val_loss: 0.3179 - val_accuracy: 0.8870 - lr: 0.0100\n",
            "Epoch 46/100\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3301 - accuracy: 0.8793 - val_loss: 0.2836 - val_accuracy: 0.8957 - lr: 0.0100\n",
            "Epoch 47/100\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3346 - accuracy: 0.8787 - val_loss: 0.3098 - val_accuracy: 0.8840 - lr: 0.0100\n",
            "Epoch 48/100\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3317 - accuracy: 0.8789 - val_loss: 0.2870 - val_accuracy: 0.8947 - lr: 0.0100\n",
            "Epoch 49/100\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3337 - accuracy: 0.8799 - val_loss: 0.3052 - val_accuracy: 0.8865 - lr: 0.0100\n",
            "Epoch 50/100\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3302 - accuracy: 0.8799 - val_loss: 0.3166 - val_accuracy: 0.8802 - lr: 0.0100\n",
            "Epoch 51/100\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3298 - accuracy: 0.8804 - val_loss: 0.2863 - val_accuracy: 0.8979 - lr: 0.0100\n",
            "Epoch 52/100\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3293 - accuracy: 0.8823 - val_loss: 0.3056 - val_accuracy: 0.8819 - lr: 0.0100\n",
            "Epoch 53/100\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3225 - accuracy: 0.8826 - val_loss: 0.2745 - val_accuracy: 0.9001 - lr: 0.0100\n",
            "Epoch 54/100\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3187 - accuracy: 0.8841 - val_loss: 0.2777 - val_accuracy: 0.8999 - lr: 0.0100\n",
            "Epoch 55/100\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3258 - accuracy: 0.8817 - val_loss: 0.2744 - val_accuracy: 0.9007 - lr: 0.0100\n",
            "Epoch 56/100\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3265 - accuracy: 0.8797 - val_loss: 0.2907 - val_accuracy: 0.8904 - lr: 0.0100\n",
            "Epoch 57/100\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3223 - accuracy: 0.8832 - val_loss: 0.2796 - val_accuracy: 0.8954 - lr: 0.0100\n",
            "Epoch 58/100\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3207 - accuracy: 0.8834 - val_loss: 0.3351 - val_accuracy: 0.8749 - lr: 0.0100\n",
            "Epoch 59/100\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3164 - accuracy: 0.8847 - val_loss: 0.2953 - val_accuracy: 0.8917 - lr: 0.0100\n",
            "Epoch 60/100\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3214 - accuracy: 0.8811 - val_loss: 0.2934 - val_accuracy: 0.8900 - lr: 0.0100\n",
            "Epoch 61/100\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3192 - accuracy: 0.8840 - val_loss: 0.3003 - val_accuracy: 0.8891 - lr: 0.0100\n",
            "Epoch 62/100\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3201 - accuracy: 0.8835 - val_loss: 0.2748 - val_accuracy: 0.8956 - lr: 0.0100\n",
            "Epoch 63/100\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3122 - accuracy: 0.8860 - val_loss: 0.2915 - val_accuracy: 0.8923 - lr: 0.0100\n",
            "Epoch 64/100\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3145 - accuracy: 0.8857 - val_loss: 0.3610 - val_accuracy: 0.8580 - lr: 0.0100\n",
            "Epoch 65/100\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3167 - accuracy: 0.8847 - val_loss: 0.2723 - val_accuracy: 0.8978 - lr: 0.0100\n",
            "Epoch 66/100\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3164 - accuracy: 0.8855 - val_loss: 0.2895 - val_accuracy: 0.8942 - lr: 0.0100\n",
            "Epoch 67/100\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3171 - accuracy: 0.8853 - val_loss: 0.3455 - val_accuracy: 0.8706 - lr: 0.0100\n",
            "Epoch 68/100\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3165 - accuracy: 0.8848 - val_loss: 0.2907 - val_accuracy: 0.8980 - lr: 0.0100\n",
            "Epoch 69/100\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3106 - accuracy: 0.8862 - val_loss: 0.3352 - val_accuracy: 0.8777 - lr: 0.0100\n",
            "Epoch 70/100\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3119 - accuracy: 0.8865 - val_loss: 0.2919 - val_accuracy: 0.8970 - lr: 0.0100\n",
            "Epoch 1/100\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.9380 - accuracy: 0.6579 - val_loss: 2.3912 - val_accuracy: 0.3066 - lr: 0.0100\n",
            "Epoch 2/100\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.6146 - accuracy: 0.7743 - val_loss: 3.6273 - val_accuracy: 0.1005 - lr: 0.0100\n",
            "Epoch 3/100\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.5469 - accuracy: 0.8047 - val_loss: 3.1499 - val_accuracy: 0.2355 - lr: 0.0100\n",
            "Epoch 4/100\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.5197 - accuracy: 0.8140 - val_loss: 2.2770 - val_accuracy: 0.3254 - lr: 0.0100\n",
            "Epoch 5/100\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4841 - accuracy: 0.8259 - val_loss: 1.4052 - val_accuracy: 0.5552 - lr: 0.0100\n",
            "Epoch 6/100\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4654 - accuracy: 0.8346 - val_loss: 0.8135 - val_accuracy: 0.6835 - lr: 0.0100\n",
            "Epoch 7/100\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4542 - accuracy: 0.8353 - val_loss: 0.5409 - val_accuracy: 0.7860 - lr: 0.0100\n",
            "Epoch 8/100\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4414 - accuracy: 0.8420 - val_loss: 0.5092 - val_accuracy: 0.7990 - lr: 0.0100\n",
            "Epoch 9/100\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4327 - accuracy: 0.8453 - val_loss: 0.3857 - val_accuracy: 0.8545 - lr: 0.0100\n",
            "Epoch 10/100\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4156 - accuracy: 0.8493 - val_loss: 0.3622 - val_accuracy: 0.8686 - lr: 0.0100\n",
            "Epoch 11/100\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4224 - accuracy: 0.8478 - val_loss: 0.3467 - val_accuracy: 0.8660 - lr: 0.0100\n",
            "Epoch 12/100\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4060 - accuracy: 0.8524 - val_loss: 0.3662 - val_accuracy: 0.8589 - lr: 0.0100\n",
            "Epoch 13/100\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4027 - accuracy: 0.8553 - val_loss: 0.3599 - val_accuracy: 0.8631 - lr: 0.0100\n",
            "Epoch 14/100\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3972 - accuracy: 0.8572 - val_loss: 0.3320 - val_accuracy: 0.8756 - lr: 0.0100\n",
            "Epoch 15/100\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3937 - accuracy: 0.8581 - val_loss: 0.4418 - val_accuracy: 0.8146 - lr: 0.0100\n",
            "Epoch 16/100\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3852 - accuracy: 0.8612 - val_loss: 0.3400 - val_accuracy: 0.8741 - lr: 0.0100\n",
            "Epoch 17/100\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3823 - accuracy: 0.8623 - val_loss: 0.3524 - val_accuracy: 0.8675 - lr: 0.0100\n",
            "Epoch 18/100\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3777 - accuracy: 0.8643 - val_loss: 0.3323 - val_accuracy: 0.8761 - lr: 0.0100\n",
            "Epoch 19/100\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3710 - accuracy: 0.8649 - val_loss: 0.3239 - val_accuracy: 0.8780 - lr: 0.0100\n",
            "Epoch 20/100\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3618 - accuracy: 0.8670 - val_loss: 0.3310 - val_accuracy: 0.8756 - lr: 0.0100\n",
            "Epoch 21/100\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3658 - accuracy: 0.8678 - val_loss: 0.3156 - val_accuracy: 0.8799 - lr: 0.0100\n",
            "Epoch 22/100\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3641 - accuracy: 0.8679 - val_loss: 0.3479 - val_accuracy: 0.8717 - lr: 0.0100\n",
            "Epoch 23/100\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3590 - accuracy: 0.8692 - val_loss: 0.3054 - val_accuracy: 0.8860 - lr: 0.0100\n",
            "Epoch 24/100\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3614 - accuracy: 0.8693 - val_loss: 0.3253 - val_accuracy: 0.8784 - lr: 0.0100\n",
            "Epoch 25/100\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3660 - accuracy: 0.8681 - val_loss: 0.3117 - val_accuracy: 0.8838 - lr: 0.0100\n",
            "Epoch 26/100\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3603 - accuracy: 0.8700 - val_loss: 0.3242 - val_accuracy: 0.8755 - lr: 0.0100\n",
            "Epoch 27/100\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3490 - accuracy: 0.8747 - val_loss: 0.3134 - val_accuracy: 0.8804 - lr: 0.0100\n",
            "Epoch 28/100\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3520 - accuracy: 0.8721 - val_loss: 0.3326 - val_accuracy: 0.8701 - lr: 0.0100\n",
            "Epoch 29/100\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3491 - accuracy: 0.8735 - val_loss: 0.3597 - val_accuracy: 0.8661 - lr: 0.0100\n",
            "Epoch 30/100\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3448 - accuracy: 0.8754 - val_loss: 0.3626 - val_accuracy: 0.8656 - lr: 0.0100\n",
            "Epoch 31/100\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3477 - accuracy: 0.8741 - val_loss: 0.3586 - val_accuracy: 0.8679 - lr: 0.0100\n",
            "Epoch 32/100\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3439 - accuracy: 0.8746 - val_loss: 0.3605 - val_accuracy: 0.8609 - lr: 0.0100\n",
            "Epoch 33/100\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3485 - accuracy: 0.8735 - val_loss: 0.3086 - val_accuracy: 0.8841 - lr: 0.0100\n",
            "Epoch 34/100\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3407 - accuracy: 0.8777 - val_loss: 0.3724 - val_accuracy: 0.8506 - lr: 0.0100\n",
            "Epoch 35/100\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3412 - accuracy: 0.8762 - val_loss: 0.3091 - val_accuracy: 0.8842 - lr: 0.0100\n",
            "Epoch 36/100\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3401 - accuracy: 0.8768 - val_loss: 0.3048 - val_accuracy: 0.8832 - lr: 0.0100\n",
            "Epoch 37/100\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3372 - accuracy: 0.8783 - val_loss: 0.3557 - val_accuracy: 0.8616 - lr: 0.0100\n",
            "Epoch 38/100\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3383 - accuracy: 0.8755 - val_loss: 0.3073 - val_accuracy: 0.8875 - lr: 0.0100\n",
            "Epoch 39/100\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3411 - accuracy: 0.8769 - val_loss: 0.3523 - val_accuracy: 0.8624 - lr: 0.0100\n",
            "Epoch 40/100\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3315 - accuracy: 0.8797 - val_loss: 0.3041 - val_accuracy: 0.8884 - lr: 0.0100\n",
            "Epoch 41/100\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3332 - accuracy: 0.8793 - val_loss: 0.3102 - val_accuracy: 0.8848 - lr: 0.0100\n",
            "Epoch 42/100\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3331 - accuracy: 0.8805 - val_loss: 0.2997 - val_accuracy: 0.8907 - lr: 0.0100\n",
            "Epoch 43/100\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3305 - accuracy: 0.8797 - val_loss: 0.3503 - val_accuracy: 0.8708 - lr: 0.0100\n",
            "Epoch 44/100\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3358 - accuracy: 0.8795 - val_loss: 0.3732 - val_accuracy: 0.8654 - lr: 0.0100\n",
            "Epoch 45/100\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3307 - accuracy: 0.8809 - val_loss: 0.3046 - val_accuracy: 0.8855 - lr: 0.0100\n",
            "Epoch 46/100\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3249 - accuracy: 0.8828 - val_loss: 0.3015 - val_accuracy: 0.8892 - lr: 0.0100\n",
            "Epoch 47/100\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3256 - accuracy: 0.8821 - val_loss: 0.3076 - val_accuracy: 0.8880 - lr: 0.0100\n",
            "Epoch 48/100\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3276 - accuracy: 0.8832 - val_loss: 0.2970 - val_accuracy: 0.8891 - lr: 0.0100\n",
            "Epoch 49/100\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3270 - accuracy: 0.8812 - val_loss: 0.2871 - val_accuracy: 0.8946 - lr: 0.0100\n",
            "Epoch 50/100\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3202 - accuracy: 0.8850 - val_loss: 0.2947 - val_accuracy: 0.8906 - lr: 0.0100\n",
            "Epoch 51/100\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3222 - accuracy: 0.8828 - val_loss: 0.3016 - val_accuracy: 0.8869 - lr: 0.0100\n",
            "Epoch 52/100\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3208 - accuracy: 0.8838 - val_loss: 0.2998 - val_accuracy: 0.8895 - lr: 0.0100\n",
            "Epoch 53/100\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3219 - accuracy: 0.8831 - val_loss: 0.3676 - val_accuracy: 0.8586 - lr: 0.0100\n",
            "Epoch 54/100\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3193 - accuracy: 0.8832 - val_loss: 0.3042 - val_accuracy: 0.8825 - lr: 0.0100\n",
            "Epoch 55/100\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3155 - accuracy: 0.8865 - val_loss: 0.3009 - val_accuracy: 0.8901 - lr: 0.0100\n",
            "Epoch 56/100\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3147 - accuracy: 0.8859 - val_loss: 0.3496 - val_accuracy: 0.8690 - lr: 0.0100\n",
            "Epoch 57/100\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3186 - accuracy: 0.8845 - val_loss: 0.3469 - val_accuracy: 0.8706 - lr: 0.0100\n",
            "Epoch 58/100\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3167 - accuracy: 0.8870 - val_loss: 0.3314 - val_accuracy: 0.8808 - lr: 0.0100\n",
            "Epoch 59/100\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3178 - accuracy: 0.8831 - val_loss: 0.2927 - val_accuracy: 0.8939 - lr: 0.0100\n",
            "Epoch 60/100\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3122 - accuracy: 0.8853 - val_loss: 0.2929 - val_accuracy: 0.8913 - lr: 0.0100\n",
            "Epoch 61/100\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3148 - accuracy: 0.8859 - val_loss: 0.2890 - val_accuracy: 0.8985 - lr: 0.0100\n",
            "Epoch 62/100\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3100 - accuracy: 0.8878 - val_loss: 0.3029 - val_accuracy: 0.8896 - lr: 0.0100\n",
            "Epoch 63/100\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3126 - accuracy: 0.8866 - val_loss: 0.3109 - val_accuracy: 0.8850 - lr: 0.0100\n",
            "Epoch 64/100\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3106 - accuracy: 0.8872 - val_loss: 0.2906 - val_accuracy: 0.8951 - lr: 0.0100\n",
            "Epoch 65/100\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3096 - accuracy: 0.8873 - val_loss: 0.3210 - val_accuracy: 0.8800 - lr: 0.0100\n",
            "Epoch 66/100\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3099 - accuracy: 0.8880 - val_loss: 0.3578 - val_accuracy: 0.8646 - lr: 0.0100\n",
            "Epoch 67/100\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3050 - accuracy: 0.8908 - val_loss: 0.2920 - val_accuracy: 0.8932 - lr: 0.0100\n",
            "Epoch 68/100\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3026 - accuracy: 0.8918 - val_loss: 0.2923 - val_accuracy: 0.8928 - lr: 0.0100\n",
            "Epoch 69/100\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3047 - accuracy: 0.8903 - val_loss: 0.2934 - val_accuracy: 0.8932 - lr: 0.0100\n",
            "Epoch 70/100\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3104 - accuracy: 0.8903 - val_loss: 0.3048 - val_accuracy: 0.8886 - lr: 0.0100\n",
            "Epoch 71/100\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3060 - accuracy: 0.8893 - val_loss: 0.2897 - val_accuracy: 0.8955 - lr: 0.0100\n",
            "Epoch 72/100\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3070 - accuracy: 0.8889 - val_loss: 0.2818 - val_accuracy: 0.8965 - lr: 0.0100\n",
            "Epoch 73/100\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3037 - accuracy: 0.8906 - val_loss: 0.3129 - val_accuracy: 0.8834 - lr: 0.0100\n",
            "Epoch 74/100\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3084 - accuracy: 0.8891 - val_loss: 0.3783 - val_accuracy: 0.8650 - lr: 0.0100\n",
            "Epoch 75/100\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3016 - accuracy: 0.8904 - val_loss: 0.2821 - val_accuracy: 0.8988 - lr: 0.0100\n",
            "Epoch 76/100\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3095 - accuracy: 0.8895 - val_loss: 0.2853 - val_accuracy: 0.8980 - lr: 0.0100\n",
            "Epoch 77/100\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3015 - accuracy: 0.8921 - val_loss: 0.3130 - val_accuracy: 0.8825 - lr: 0.0100\n",
            "Epoch 78/100\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3063 - accuracy: 0.8879 - val_loss: 0.2818 - val_accuracy: 0.8979 - lr: 0.0100\n",
            "Epoch 79/100\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3018 - accuracy: 0.8912 - val_loss: 0.2908 - val_accuracy: 0.8915 - lr: 0.0100\n",
            "Epoch 80/100\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2981 - accuracy: 0.8915 - val_loss: 0.2794 - val_accuracy: 0.8971 - lr: 0.0100\n",
            "Epoch 81/100\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3019 - accuracy: 0.8919 - val_loss: 0.3189 - val_accuracy: 0.8852 - lr: 0.0100\n",
            "Epoch 82/100\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3055 - accuracy: 0.8913 - val_loss: 0.2745 - val_accuracy: 0.9014 - lr: 0.0100\n",
            "Epoch 83/100\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2941 - accuracy: 0.8911 - val_loss: 0.2894 - val_accuracy: 0.8960 - lr: 0.0100\n",
            "Epoch 84/100\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3010 - accuracy: 0.8923 - val_loss: 0.2889 - val_accuracy: 0.8898 - lr: 0.0100\n",
            "Epoch 85/100\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2968 - accuracy: 0.8934 - val_loss: 0.3142 - val_accuracy: 0.8785 - lr: 0.0100\n",
            "Epoch 86/100\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2974 - accuracy: 0.8918 - val_loss: 0.3165 - val_accuracy: 0.8815 - lr: 0.0100\n",
            "Epoch 87/100\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3031 - accuracy: 0.8911 - val_loss: 0.3273 - val_accuracy: 0.8823 - lr: 0.0100\n",
            "Epoch 88/100\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2983 - accuracy: 0.8916 - val_loss: 0.3054 - val_accuracy: 0.8873 - lr: 0.0100\n",
            "Epoch 89/100\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2950 - accuracy: 0.8932 - val_loss: 0.3078 - val_accuracy: 0.8852 - lr: 0.0100\n",
            "Epoch 90/100\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2922 - accuracy: 0.8950 - val_loss: 0.2942 - val_accuracy: 0.8901 - lr: 0.0100\n",
            "Epoch 91/100\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2925 - accuracy: 0.8949 - val_loss: 0.2735 - val_accuracy: 0.9024 - lr: 0.0100\n",
            "Epoch 92/100\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2956 - accuracy: 0.8926 - val_loss: 0.2730 - val_accuracy: 0.8989 - lr: 0.0100\n",
            "Epoch 93/100\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2960 - accuracy: 0.8928 - val_loss: 0.2718 - val_accuracy: 0.9014 - lr: 0.0100\n",
            "Epoch 94/100\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2910 - accuracy: 0.8942 - val_loss: 0.2938 - val_accuracy: 0.8947 - lr: 0.0100\n",
            "Epoch 95/100\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2962 - accuracy: 0.8907 - val_loss: 0.2750 - val_accuracy: 0.9010 - lr: 0.0100\n",
            "Epoch 96/100\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2891 - accuracy: 0.8939 - val_loss: 0.2972 - val_accuracy: 0.8894 - lr: 0.0100\n",
            "Epoch 97/100\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2909 - accuracy: 0.8949 - val_loss: 0.2721 - val_accuracy: 0.8999 - lr: 0.0100\n",
            "Epoch 98/100\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2889 - accuracy: 0.8960 - val_loss: 0.3252 - val_accuracy: 0.8825 - lr: 0.0100\n",
            "Epoch 99/100\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2912 - accuracy: 0.8959 - val_loss: 0.2807 - val_accuracy: 0.8955 - lr: 0.0100\n",
            "Epoch 100/100\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2948 - accuracy: 0.8954 - val_loss: 0.2863 - val_accuracy: 0.8992 - lr: 0.0100\n",
            "Epoch 1/100\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.9199 - accuracy: 0.6663 - val_loss: 1.6273 - val_accuracy: 0.4001 - lr: 0.0100\n",
            "Epoch 2/100\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.6174 - accuracy: 0.7720 - val_loss: 2.9740 - val_accuracy: 0.1050 - lr: 0.0100\n",
            "Epoch 3/100\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.5541 - accuracy: 0.7973 - val_loss: 2.6208 - val_accuracy: 0.1807 - lr: 0.0100\n",
            "Epoch 4/100\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.5156 - accuracy: 0.8147 - val_loss: 1.8359 - val_accuracy: 0.3454 - lr: 0.0100\n",
            "Epoch 5/100\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4866 - accuracy: 0.8243 - val_loss: 1.1933 - val_accuracy: 0.5669 - lr: 0.0100\n",
            "Epoch 6/100\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4684 - accuracy: 0.8300 - val_loss: 0.7404 - val_accuracy: 0.7358 - lr: 0.0100\n",
            "Epoch 7/100\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4490 - accuracy: 0.8377 - val_loss: 0.6272 - val_accuracy: 0.7473 - lr: 0.0100\n",
            "Epoch 8/100\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4426 - accuracy: 0.8374 - val_loss: 0.5425 - val_accuracy: 0.7721 - lr: 0.0100\n",
            "Epoch 9/100\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4295 - accuracy: 0.8440 - val_loss: 0.4881 - val_accuracy: 0.7908 - lr: 0.0100\n",
            "Epoch 10/100\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4168 - accuracy: 0.8489 - val_loss: 0.3598 - val_accuracy: 0.8604 - lr: 0.0100\n",
            "Epoch 11/100\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4142 - accuracy: 0.8497 - val_loss: 0.3677 - val_accuracy: 0.8585 - lr: 0.0100\n",
            "Epoch 12/100\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4044 - accuracy: 0.8541 - val_loss: 0.3506 - val_accuracy: 0.8669 - lr: 0.0100\n",
            "Epoch 13/100\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3979 - accuracy: 0.8560 - val_loss: 0.3308 - val_accuracy: 0.8740 - lr: 0.0100\n",
            "Epoch 14/100\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3936 - accuracy: 0.8571 - val_loss: 0.3747 - val_accuracy: 0.8526 - lr: 0.0100\n",
            "Epoch 15/100\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3875 - accuracy: 0.8604 - val_loss: 0.3295 - val_accuracy: 0.8734 - lr: 0.0100\n",
            "Epoch 16/100\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3884 - accuracy: 0.8567 - val_loss: 0.3563 - val_accuracy: 0.8643 - lr: 0.0100\n",
            "Epoch 17/100\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3891 - accuracy: 0.8597 - val_loss: 0.3464 - val_accuracy: 0.8695 - lr: 0.0100\n",
            "Epoch 18/100\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3761 - accuracy: 0.8635 - val_loss: 0.3775 - val_accuracy: 0.8459 - lr: 0.0100\n",
            "Epoch 19/100\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3739 - accuracy: 0.8635 - val_loss: 0.3397 - val_accuracy: 0.8706 - lr: 0.0100\n",
            "Epoch 20/100\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3689 - accuracy: 0.8664 - val_loss: 0.3812 - val_accuracy: 0.8515 - lr: 0.0100\n",
            "Epoch 21/100\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3662 - accuracy: 0.8698 - val_loss: 0.3623 - val_accuracy: 0.8609 - lr: 0.0100\n",
            "Epoch 22/100\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3651 - accuracy: 0.8663 - val_loss: 0.3280 - val_accuracy: 0.8749 - lr: 0.0100\n",
            "Epoch 23/100\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3583 - accuracy: 0.8697 - val_loss: 0.3272 - val_accuracy: 0.8779 - lr: 0.0100\n",
            "Epoch 24/100\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3583 - accuracy: 0.8699 - val_loss: 0.3684 - val_accuracy: 0.8526 - lr: 0.0100\n",
            "Epoch 25/100\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3615 - accuracy: 0.8690 - val_loss: 0.3975 - val_accuracy: 0.8409 - lr: 0.0100\n",
            "Epoch 26/100\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3603 - accuracy: 0.8694 - val_loss: 0.3018 - val_accuracy: 0.8917 - lr: 0.0100\n",
            "Epoch 27/100\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3512 - accuracy: 0.8715 - val_loss: 0.3108 - val_accuracy: 0.8835 - lr: 0.0100\n",
            "Epoch 28/100\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3524 - accuracy: 0.8713 - val_loss: 0.3167 - val_accuracy: 0.8808 - lr: 0.0100\n",
            "Epoch 29/100\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3451 - accuracy: 0.8747 - val_loss: 0.3037 - val_accuracy: 0.8826 - lr: 0.0100\n",
            "Epoch 30/100\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3480 - accuracy: 0.8737 - val_loss: 0.3097 - val_accuracy: 0.8841 - lr: 0.0100\n",
            "Epoch 31/100\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3508 - accuracy: 0.8729 - val_loss: 0.3033 - val_accuracy: 0.8869 - lr: 0.0100\n",
            "Epoch 32/100\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3431 - accuracy: 0.8767 - val_loss: 0.2890 - val_accuracy: 0.8924 - lr: 0.0100\n",
            "Epoch 33/100\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3463 - accuracy: 0.8745 - val_loss: 0.3603 - val_accuracy: 0.8639 - lr: 0.0100\n",
            "Epoch 34/100\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3407 - accuracy: 0.8765 - val_loss: 0.4052 - val_accuracy: 0.8591 - lr: 0.0100\n",
            "Epoch 35/100\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3378 - accuracy: 0.8792 - val_loss: 0.3467 - val_accuracy: 0.8624 - lr: 0.0100\n",
            "Epoch 36/100\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3382 - accuracy: 0.8782 - val_loss: 0.2856 - val_accuracy: 0.8950 - lr: 0.0100\n",
            "Epoch 37/100\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3364 - accuracy: 0.8782 - val_loss: 0.3722 - val_accuracy: 0.8558 - lr: 0.0100\n",
            "Epoch 38/100\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3341 - accuracy: 0.8780 - val_loss: 0.3454 - val_accuracy: 0.8631 - lr: 0.0100\n",
            "Epoch 39/100\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3351 - accuracy: 0.8789 - val_loss: 0.4327 - val_accuracy: 0.8363 - lr: 0.0100\n",
            "Epoch 40/100\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3349 - accuracy: 0.8792 - val_loss: 0.3527 - val_accuracy: 0.8656 - lr: 0.0100\n",
            "Epoch 41/100\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3275 - accuracy: 0.8807 - val_loss: 0.3026 - val_accuracy: 0.8866 - lr: 0.0100\n",
            "Epoch 42/100\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3291 - accuracy: 0.8806 - val_loss: 0.3004 - val_accuracy: 0.8916 - lr: 0.0100\n",
            "Epoch 43/100\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3306 - accuracy: 0.8780 - val_loss: 0.2960 - val_accuracy: 0.8909 - lr: 0.0100\n",
            "Epoch 44/100\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3308 - accuracy: 0.8805 - val_loss: 0.3596 - val_accuracy: 0.8669 - lr: 0.0100\n",
            "Epoch 45/100\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3294 - accuracy: 0.8808 - val_loss: 0.2987 - val_accuracy: 0.8876 - lr: 0.0100\n",
            "Epoch 46/100\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3277 - accuracy: 0.8804 - val_loss: 0.3012 - val_accuracy: 0.8892 - lr: 0.0100\n",
            "Epoch 47/100\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3193 - accuracy: 0.8859 - val_loss: 0.2848 - val_accuracy: 0.8931 - lr: 0.0100\n",
            "Epoch 48/100\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3252 - accuracy: 0.8830 - val_loss: 0.3064 - val_accuracy: 0.8832 - lr: 0.0100\n",
            "Epoch 49/100\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3221 - accuracy: 0.8820 - val_loss: 0.2943 - val_accuracy: 0.8906 - lr: 0.0100\n",
            "Epoch 50/100\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3174 - accuracy: 0.8840 - val_loss: 0.3082 - val_accuracy: 0.8831 - lr: 0.0100\n",
            "Epoch 51/100\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3174 - accuracy: 0.8858 - val_loss: 0.3750 - val_accuracy: 0.8586 - lr: 0.0100\n",
            "Epoch 1/100\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.9488 - accuracy: 0.6558 - val_loss: 2.2714 - val_accuracy: 0.1989 - lr: 0.0100\n",
            "Epoch 2/100\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.6276 - accuracy: 0.7685 - val_loss: 1.7973 - val_accuracy: 0.3103 - lr: 0.0100\n",
            "Epoch 3/100\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.5610 - accuracy: 0.7951 - val_loss: 1.7019 - val_accuracy: 0.3435 - lr: 0.0100\n",
            "Epoch 4/100\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.5211 - accuracy: 0.8112 - val_loss: 1.2943 - val_accuracy: 0.4600 - lr: 0.0100\n",
            "Epoch 5/100\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4937 - accuracy: 0.8212 - val_loss: 0.7590 - val_accuracy: 0.6830 - lr: 0.0100\n",
            "Epoch 6/100\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4688 - accuracy: 0.8330 - val_loss: 0.6355 - val_accuracy: 0.7650 - lr: 0.0100\n",
            "Epoch 7/100\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4592 - accuracy: 0.8336 - val_loss: 0.5121 - val_accuracy: 0.7926 - lr: 0.0100\n",
            "Epoch 8/100\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4398 - accuracy: 0.8416 - val_loss: 0.4981 - val_accuracy: 0.7972 - lr: 0.0100\n",
            "Epoch 9/100\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4377 - accuracy: 0.8428 - val_loss: 0.4317 - val_accuracy: 0.8321 - lr: 0.0100\n",
            "Epoch 10/100\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4361 - accuracy: 0.8422 - val_loss: 0.3518 - val_accuracy: 0.8774 - lr: 0.0100\n",
            "Epoch 11/100\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4167 - accuracy: 0.8501 - val_loss: 0.3421 - val_accuracy: 0.8775 - lr: 0.0100\n",
            "Epoch 12/100\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4103 - accuracy: 0.8520 - val_loss: 0.3530 - val_accuracy: 0.8734 - lr: 0.0100\n",
            "Epoch 13/100\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4093 - accuracy: 0.8506 - val_loss: 0.4031 - val_accuracy: 0.8388 - lr: 0.0100\n",
            "Epoch 14/100\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4004 - accuracy: 0.8558 - val_loss: 0.4434 - val_accuracy: 0.8355 - lr: 0.0100\n",
            "Epoch 15/100\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3960 - accuracy: 0.8582 - val_loss: 0.3816 - val_accuracy: 0.8597 - lr: 0.0100\n",
            "Epoch 16/100\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3901 - accuracy: 0.8587 - val_loss: 0.3270 - val_accuracy: 0.8785 - lr: 0.0100\n",
            "Epoch 17/100\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3878 - accuracy: 0.8600 - val_loss: 0.3507 - val_accuracy: 0.8676 - lr: 0.0100\n",
            "Epoch 18/100\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3787 - accuracy: 0.8644 - val_loss: 0.3508 - val_accuracy: 0.8643 - lr: 0.0100\n",
            "Epoch 19/100\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3736 - accuracy: 0.8657 - val_loss: 0.3268 - val_accuracy: 0.8794 - lr: 0.0100\n",
            "Epoch 20/100\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3778 - accuracy: 0.8648 - val_loss: 0.3006 - val_accuracy: 0.8903 - lr: 0.0100\n",
            "Epoch 21/100\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3743 - accuracy: 0.8658 - val_loss: 0.3147 - val_accuracy: 0.8808 - lr: 0.0100\n",
            "Epoch 22/100\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3662 - accuracy: 0.8678 - val_loss: 0.4042 - val_accuracy: 0.8426 - lr: 0.0100\n",
            "Epoch 23/100\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3703 - accuracy: 0.8672 - val_loss: 0.2969 - val_accuracy: 0.8895 - lr: 0.0100\n",
            "Epoch 24/100\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3603 - accuracy: 0.8707 - val_loss: 0.2923 - val_accuracy: 0.8944 - lr: 0.0100\n",
            "Epoch 25/100\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3606 - accuracy: 0.8699 - val_loss: 0.3234 - val_accuracy: 0.8773 - lr: 0.0100\n",
            "Epoch 26/100\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3602 - accuracy: 0.8698 - val_loss: 0.3261 - val_accuracy: 0.8804 - lr: 0.0100\n",
            "Epoch 27/100\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3595 - accuracy: 0.8688 - val_loss: 0.2953 - val_accuracy: 0.8924 - lr: 0.0100\n",
            "Epoch 28/100\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3521 - accuracy: 0.8727 - val_loss: 0.2994 - val_accuracy: 0.8874 - lr: 0.0100\n",
            "Epoch 29/100\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3510 - accuracy: 0.8724 - val_loss: 0.3016 - val_accuracy: 0.8881 - lr: 0.0100\n",
            "Epoch 30/100\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3506 - accuracy: 0.8728 - val_loss: 0.3390 - val_accuracy: 0.8737 - lr: 0.0100\n",
            "Epoch 31/100\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3465 - accuracy: 0.8738 - val_loss: 0.2836 - val_accuracy: 0.8967 - lr: 0.0100\n",
            "Epoch 32/100\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3468 - accuracy: 0.8720 - val_loss: 0.3123 - val_accuracy: 0.8826 - lr: 0.0100\n",
            "Epoch 33/100\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3413 - accuracy: 0.8776 - val_loss: 0.2993 - val_accuracy: 0.8899 - lr: 0.0100\n",
            "Epoch 34/100\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3475 - accuracy: 0.8751 - val_loss: 0.2973 - val_accuracy: 0.8903 - lr: 0.0100\n",
            "Epoch 35/100\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3406 - accuracy: 0.8746 - val_loss: 0.2836 - val_accuracy: 0.8954 - lr: 0.0100\n",
            "Epoch 36/100\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3421 - accuracy: 0.8770 - val_loss: 0.2980 - val_accuracy: 0.8876 - lr: 0.0100\n",
            "Epoch 37/100\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3376 - accuracy: 0.8784 - val_loss: 0.3277 - val_accuracy: 0.8754 - lr: 0.0100\n",
            "Epoch 38/100\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3346 - accuracy: 0.8783 - val_loss: 0.2958 - val_accuracy: 0.8939 - lr: 0.0100\n",
            "Epoch 39/100\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3354 - accuracy: 0.8798 - val_loss: 0.3913 - val_accuracy: 0.8505 - lr: 0.0100\n",
            "Epoch 40/100\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3371 - accuracy: 0.8788 - val_loss: 0.4245 - val_accuracy: 0.8259 - lr: 0.0100\n",
            "Epoch 41/100\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3337 - accuracy: 0.8798 - val_loss: 0.2821 - val_accuracy: 0.8963 - lr: 0.0100\n",
            "Epoch 42/100\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3293 - accuracy: 0.8808 - val_loss: 0.2966 - val_accuracy: 0.8899 - lr: 0.0100\n",
            "Epoch 43/100\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3324 - accuracy: 0.8809 - val_loss: 0.2937 - val_accuracy: 0.8915 - lr: 0.0100\n",
            "Epoch 44/100\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3267 - accuracy: 0.8808 - val_loss: 0.3344 - val_accuracy: 0.8656 - lr: 0.0100\n",
            "Epoch 45/100\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3275 - accuracy: 0.8811 - val_loss: 0.2993 - val_accuracy: 0.8857 - lr: 0.0100\n",
            "Epoch 46/100\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3276 - accuracy: 0.8804 - val_loss: 0.2792 - val_accuracy: 0.8947 - lr: 0.0100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "TypeError: The added layer must be an instance of class Layer. Found: \n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43m스트리밍 출력 내용이 길어서 마지막 5000줄이 삭제되었습니다.\u001b[0m\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3222 - accuracy: 0.8827 - val_loss: 0.2933 - val_accuracy: 0.8920 - lr: 0.0020\n",
            "Epoch 1/100\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 1.1848 - accuracy: 0.5903 - val_loss: 2.5107 - val_accuracy: 0.0980 - lr: 0.0020\n",
            "Epoch 2/100\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.7348 - accuracy: 0.7366 - val_loss: 2.5552 - val_accuracy: 0.1384 - lr: 0.0020\n",
            "Epoch 3/100\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.6459 - accuracy: 0.7679 - val_loss: 2.2734 - val_accuracy: 0.1608 - lr: 0.0020\n",
            "Epoch 4/100\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.5874 - accuracy: 0.7904 - val_loss: 2.1191 - val_accuracy: 0.3736 - lr: 0.0020\n",
            "Epoch 5/100\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.5530 - accuracy: 0.8057 - val_loss: 1.7482 - val_accuracy: 0.5027 - lr: 0.0020\n",
            "Epoch 6/100\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.5192 - accuracy: 0.8172 - val_loss: 1.3798 - val_accuracy: 0.6049 - lr: 0.0020\n",
            "Epoch 7/100\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4933 - accuracy: 0.8257 - val_loss: 1.1766 - val_accuracy: 0.6459 - lr: 0.0020\n",
            "Epoch 8/100\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4744 - accuracy: 0.8312 - val_loss: 0.7962 - val_accuracy: 0.7330 - lr: 0.0020\n",
            "Epoch 9/100\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4617 - accuracy: 0.8357 - val_loss: 0.5818 - val_accuracy: 0.8048 - lr: 0.0020\n",
            "Epoch 10/100\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4509 - accuracy: 0.8410 - val_loss: 0.5932 - val_accuracy: 0.7695 - lr: 0.0020\n",
            "Epoch 11/100\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4352 - accuracy: 0.8461 - val_loss: 0.5147 - val_accuracy: 0.8102 - lr: 0.0020\n",
            "Epoch 12/100\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4281 - accuracy: 0.8487 - val_loss: 0.5135 - val_accuracy: 0.8061 - lr: 0.0020\n",
            "Epoch 13/100\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4257 - accuracy: 0.8477 - val_loss: 0.3986 - val_accuracy: 0.8481 - lr: 0.0020\n",
            "Epoch 14/100\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4121 - accuracy: 0.8520 - val_loss: 0.4098 - val_accuracy: 0.8465 - lr: 0.0020\n",
            "Epoch 15/100\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4067 - accuracy: 0.8536 - val_loss: 0.4277 - val_accuracy: 0.8404 - lr: 0.0020\n",
            "Epoch 16/100\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4059 - accuracy: 0.8561 - val_loss: 0.3514 - val_accuracy: 0.8694 - lr: 0.0020\n",
            "Epoch 17/100\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3941 - accuracy: 0.8579 - val_loss: 0.3919 - val_accuracy: 0.8493 - lr: 0.0020\n",
            "Epoch 18/100\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3930 - accuracy: 0.8595 - val_loss: 0.3402 - val_accuracy: 0.8716 - lr: 0.0020\n",
            "Epoch 19/100\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3857 - accuracy: 0.8620 - val_loss: 0.3520 - val_accuracy: 0.8676 - lr: 0.0020\n",
            "Epoch 20/100\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3828 - accuracy: 0.8627 - val_loss: 0.3643 - val_accuracy: 0.8624 - lr: 0.0020\n",
            "Epoch 21/100\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3790 - accuracy: 0.8654 - val_loss: 0.3532 - val_accuracy: 0.8694 - lr: 0.0020\n",
            "Epoch 22/100\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3751 - accuracy: 0.8666 - val_loss: 0.3502 - val_accuracy: 0.8660 - lr: 0.0020\n",
            "Epoch 23/100\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3731 - accuracy: 0.8666 - val_loss: 0.3429 - val_accuracy: 0.8712 - lr: 0.0020\n",
            "Epoch 24/100\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3692 - accuracy: 0.8675 - val_loss: 0.3514 - val_accuracy: 0.8686 - lr: 0.0020\n",
            "Epoch 25/100\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3670 - accuracy: 0.8688 - val_loss: 0.3252 - val_accuracy: 0.8764 - lr: 0.0020\n",
            "Epoch 26/100\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3587 - accuracy: 0.8712 - val_loss: 0.3103 - val_accuracy: 0.8844 - lr: 0.0020\n",
            "Epoch 27/100\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3579 - accuracy: 0.8717 - val_loss: 0.3621 - val_accuracy: 0.8641 - lr: 0.0020\n",
            "Epoch 28/100\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3631 - accuracy: 0.8697 - val_loss: 0.3358 - val_accuracy: 0.8755 - lr: 0.0020\n",
            "Epoch 29/100\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3591 - accuracy: 0.8699 - val_loss: 0.3121 - val_accuracy: 0.8855 - lr: 0.0020\n",
            "Epoch 30/100\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3516 - accuracy: 0.8761 - val_loss: 0.2979 - val_accuracy: 0.8914 - lr: 0.0020\n",
            "Epoch 31/100\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3430 - accuracy: 0.8772 - val_loss: 0.3634 - val_accuracy: 0.8644 - lr: 0.0020\n",
            "Epoch 32/100\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3487 - accuracy: 0.8739 - val_loss: 0.3176 - val_accuracy: 0.8839 - lr: 0.0020\n",
            "Epoch 33/100\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3435 - accuracy: 0.8766 - val_loss: 0.4061 - val_accuracy: 0.8504 - lr: 0.0020\n",
            "Epoch 34/100\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3443 - accuracy: 0.8762 - val_loss: 0.3466 - val_accuracy: 0.8746 - lr: 0.0020\n",
            "Epoch 35/100\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3421 - accuracy: 0.8776 - val_loss: 0.3111 - val_accuracy: 0.8854 - lr: 0.0020\n",
            "Epoch 36/100\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3418 - accuracy: 0.8774 - val_loss: 0.3443 - val_accuracy: 0.8717 - lr: 0.0020\n",
            "Epoch 37/100\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3416 - accuracy: 0.8776 - val_loss: 0.3028 - val_accuracy: 0.8874 - lr: 0.0020\n",
            "Epoch 38/100\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3417 - accuracy: 0.8775 - val_loss: 0.3138 - val_accuracy: 0.8844 - lr: 0.0020\n",
            "Epoch 39/100\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3397 - accuracy: 0.8796 - val_loss: 0.4455 - val_accuracy: 0.8320 - lr: 0.0020\n",
            "Epoch 40/100\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3319 - accuracy: 0.8802 - val_loss: 0.3612 - val_accuracy: 0.8629 - lr: 0.0020\n",
            "Epoch 41/100\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3358 - accuracy: 0.8781 - val_loss: 0.3656 - val_accuracy: 0.8668 - lr: 0.0020\n",
            "Epoch 42/100\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3351 - accuracy: 0.8794 - val_loss: 0.3516 - val_accuracy: 0.8694 - lr: 0.0020\n",
            "Epoch 43/100\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3316 - accuracy: 0.8828 - val_loss: 0.3311 - val_accuracy: 0.8788 - lr: 0.0020\n",
            "Epoch 44/100\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3270 - accuracy: 0.8831 - val_loss: 0.4132 - val_accuracy: 0.8418 - lr: 0.0020\n",
            "Epoch 45/100\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3304 - accuracy: 0.8843 - val_loss: 0.3082 - val_accuracy: 0.8839 - lr: 0.0020\n",
            "Epoch 1/100\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 1.1673 - accuracy: 0.5969 - val_loss: 2.3890 - val_accuracy: 0.0980 - lr: 0.0020\n",
            "Epoch 2/100\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.7503 - accuracy: 0.7222 - val_loss: 2.3895 - val_accuracy: 0.1462 - lr: 0.0020\n",
            "Epoch 3/100\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.6616 - accuracy: 0.7602 - val_loss: 2.3155 - val_accuracy: 0.2180 - lr: 0.0020\n",
            "Epoch 4/100\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.5971 - accuracy: 0.7860 - val_loss: 2.0757 - val_accuracy: 0.4074 - lr: 0.0020\n",
            "Epoch 5/100\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.5570 - accuracy: 0.8008 - val_loss: 1.7253 - val_accuracy: 0.5567 - lr: 0.0020\n",
            "Epoch 6/100\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.5260 - accuracy: 0.8127 - val_loss: 1.4567 - val_accuracy: 0.5878 - lr: 0.0020\n",
            "Epoch 7/100\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4993 - accuracy: 0.8233 - val_loss: 1.1919 - val_accuracy: 0.5961 - lr: 0.0020\n",
            "Epoch 8/100\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4791 - accuracy: 0.8272 - val_loss: 0.9362 - val_accuracy: 0.6916 - lr: 0.0020\n",
            "Epoch 9/100\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4689 - accuracy: 0.8314 - val_loss: 0.6254 - val_accuracy: 0.7875 - lr: 0.0020\n",
            "Epoch 10/100\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4559 - accuracy: 0.8359 - val_loss: 0.4995 - val_accuracy: 0.8163 - lr: 0.0020\n",
            "Epoch 11/100\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4388 - accuracy: 0.8413 - val_loss: 0.4529 - val_accuracy: 0.8298 - lr: 0.0020\n",
            "Epoch 12/100\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4356 - accuracy: 0.8411 - val_loss: 0.5376 - val_accuracy: 0.8037 - lr: 0.0020\n",
            "Epoch 13/100\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4195 - accuracy: 0.8508 - val_loss: 0.3923 - val_accuracy: 0.8520 - lr: 0.0020\n",
            "Epoch 14/100\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4145 - accuracy: 0.8515 - val_loss: 0.4251 - val_accuracy: 0.8432 - lr: 0.0020\n",
            "Epoch 15/100\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4095 - accuracy: 0.8509 - val_loss: 0.3977 - val_accuracy: 0.8512 - lr: 0.0020\n",
            "Epoch 16/100\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4008 - accuracy: 0.8566 - val_loss: 0.4497 - val_accuracy: 0.8284 - lr: 0.0020\n",
            "Epoch 17/100\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3998 - accuracy: 0.8560 - val_loss: 0.3603 - val_accuracy: 0.8656 - lr: 0.0020\n",
            "Epoch 18/100\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3944 - accuracy: 0.8572 - val_loss: 0.3931 - val_accuracy: 0.8560 - lr: 0.0020\n",
            "Epoch 19/100\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3832 - accuracy: 0.8592 - val_loss: 0.3774 - val_accuracy: 0.8591 - lr: 0.0020\n",
            "Epoch 20/100\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3821 - accuracy: 0.8609 - val_loss: 0.3360 - val_accuracy: 0.8754 - lr: 0.0020\n",
            "Epoch 21/100\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3814 - accuracy: 0.8625 - val_loss: 0.4526 - val_accuracy: 0.8213 - lr: 0.0020\n",
            "Epoch 22/100\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3780 - accuracy: 0.8664 - val_loss: 0.4052 - val_accuracy: 0.8495 - lr: 0.0020\n",
            "Epoch 23/100\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3790 - accuracy: 0.8621 - val_loss: 0.3520 - val_accuracy: 0.8708 - lr: 0.0020\n",
            "Epoch 24/100\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3707 - accuracy: 0.8666 - val_loss: 0.3797 - val_accuracy: 0.8539 - lr: 0.0020\n",
            "Epoch 25/100\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3606 - accuracy: 0.8691 - val_loss: 0.3873 - val_accuracy: 0.8499 - lr: 0.0020\n",
            "Epoch 26/100\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3636 - accuracy: 0.8711 - val_loss: 0.4056 - val_accuracy: 0.8430 - lr: 0.0020\n",
            "Epoch 27/100\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3621 - accuracy: 0.8709 - val_loss: 0.3485 - val_accuracy: 0.8700 - lr: 0.0020\n",
            "Epoch 28/100\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3557 - accuracy: 0.8720 - val_loss: 0.4531 - val_accuracy: 0.8291 - lr: 0.0020\n",
            "Epoch 29/100\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3566 - accuracy: 0.8724 - val_loss: 0.4064 - val_accuracy: 0.8481 - lr: 0.0020\n",
            "Epoch 30/100\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3503 - accuracy: 0.8742 - val_loss: 0.3312 - val_accuracy: 0.8761 - lr: 0.0020\n",
            "Epoch 31/100\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3488 - accuracy: 0.8735 - val_loss: 0.3815 - val_accuracy: 0.8589 - lr: 0.0020\n",
            "Epoch 32/100\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3475 - accuracy: 0.8739 - val_loss: 0.3579 - val_accuracy: 0.8676 - lr: 0.0020\n",
            "Epoch 33/100\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3438 - accuracy: 0.8770 - val_loss: 0.3970 - val_accuracy: 0.8464 - lr: 0.0020\n",
            "Epoch 34/100\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3515 - accuracy: 0.8733 - val_loss: 0.3500 - val_accuracy: 0.8701 - lr: 0.0020\n",
            "Epoch 35/100\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3403 - accuracy: 0.8783 - val_loss: 0.3957 - val_accuracy: 0.8474 - lr: 0.0020\n",
            "Epoch 36/100\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3373 - accuracy: 0.8794 - val_loss: 0.3779 - val_accuracy: 0.8608 - lr: 0.0020\n",
            "Epoch 37/100\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3435 - accuracy: 0.8767 - val_loss: 0.3252 - val_accuracy: 0.8788 - lr: 0.0020\n",
            "Epoch 38/100\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3351 - accuracy: 0.8800 - val_loss: 0.3436 - val_accuracy: 0.8679 - lr: 0.0020\n",
            "Epoch 39/100\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3349 - accuracy: 0.8793 - val_loss: 0.3535 - val_accuracy: 0.8675 - lr: 0.0020\n",
            "Epoch 40/100\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3351 - accuracy: 0.8779 - val_loss: 0.4266 - val_accuracy: 0.8384 - lr: 0.0020\n",
            "Epoch 41/100\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3383 - accuracy: 0.8769 - val_loss: 0.3007 - val_accuracy: 0.8891 - lr: 0.0020\n",
            "Epoch 42/100\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3292 - accuracy: 0.8816 - val_loss: 0.3728 - val_accuracy: 0.8570 - lr: 0.0020\n",
            "Epoch 43/100\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3297 - accuracy: 0.8801 - val_loss: 0.3815 - val_accuracy: 0.8481 - lr: 0.0020\n",
            "Epoch 44/100\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3287 - accuracy: 0.8805 - val_loss: 0.3609 - val_accuracy: 0.8660 - lr: 0.0020\n",
            "Epoch 45/100\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3270 - accuracy: 0.8820 - val_loss: 0.3394 - val_accuracy: 0.8734 - lr: 0.0020\n",
            "Epoch 46/100\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3298 - accuracy: 0.8802 - val_loss: 0.2973 - val_accuracy: 0.8923 - lr: 0.0020\n",
            "Epoch 47/100\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3266 - accuracy: 0.8818 - val_loss: 0.3003 - val_accuracy: 0.8875 - lr: 0.0020\n",
            "Epoch 48/100\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3250 - accuracy: 0.8823 - val_loss: 0.4211 - val_accuracy: 0.8384 - lr: 0.0020\n",
            "Epoch 49/100\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3258 - accuracy: 0.8822 - val_loss: 0.3140 - val_accuracy: 0.8842 - lr: 0.0020\n",
            "Epoch 50/100\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3208 - accuracy: 0.8840 - val_loss: 0.3024 - val_accuracy: 0.8914 - lr: 0.0020\n",
            "Epoch 51/100\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3232 - accuracy: 0.8822 - val_loss: 0.3726 - val_accuracy: 0.8580 - lr: 0.0020\n",
            "Epoch 52/100\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3204 - accuracy: 0.8846 - val_loss: 0.2910 - val_accuracy: 0.8940 - lr: 0.0020\n",
            "Epoch 53/100\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3185 - accuracy: 0.8845 - val_loss: 0.3520 - val_accuracy: 0.8654 - lr: 0.0020\n",
            "Epoch 54/100\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3207 - accuracy: 0.8847 - val_loss: 0.3007 - val_accuracy: 0.8884 - lr: 0.0020\n",
            "Epoch 55/100\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3131 - accuracy: 0.8864 - val_loss: 0.3040 - val_accuracy: 0.8855 - lr: 0.0020\n",
            "Epoch 56/100\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3143 - accuracy: 0.8872 - val_loss: 0.3713 - val_accuracy: 0.8539 - lr: 0.0020\n",
            "Epoch 57/100\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3177 - accuracy: 0.8840 - val_loss: 0.3135 - val_accuracy: 0.8835 - lr: 0.0020\n",
            "Epoch 58/100\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3117 - accuracy: 0.8868 - val_loss: 0.3106 - val_accuracy: 0.8864 - lr: 0.0020\n",
            "Epoch 59/100\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3169 - accuracy: 0.8845 - val_loss: 0.3108 - val_accuracy: 0.8871 - lr: 0.0020\n",
            "Epoch 60/100\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3136 - accuracy: 0.8856 - val_loss: 0.3722 - val_accuracy: 0.8521 - lr: 0.0020\n",
            "Epoch 61/100\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3112 - accuracy: 0.8873 - val_loss: 0.3721 - val_accuracy: 0.8559 - lr: 0.0020\n",
            "Epoch 62/100\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3136 - accuracy: 0.8857 - val_loss: 0.3538 - val_accuracy: 0.8636 - lr: 0.0020\n",
            "Epoch 63/100\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3104 - accuracy: 0.8877 - val_loss: 0.3001 - val_accuracy: 0.8895 - lr: 0.0020\n",
            "Epoch 64/100\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3113 - accuracy: 0.8863 - val_loss: 0.3403 - val_accuracy: 0.8744 - lr: 0.0020\n",
            "Epoch 65/100\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3104 - accuracy: 0.8873 - val_loss: 0.3319 - val_accuracy: 0.8746 - lr: 0.0020\n",
            "Epoch 66/100\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3083 - accuracy: 0.8877 - val_loss: 0.2978 - val_accuracy: 0.8919 - lr: 0.0020\n",
            "Epoch 67/100\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3091 - accuracy: 0.8902 - val_loss: 0.3626 - val_accuracy: 0.8624 - lr: 0.0020\n",
            "Epoch 1/100\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 1.1725 - accuracy: 0.5928 - val_loss: 2.4977 - val_accuracy: 0.0986 - lr: 0.0020\n",
            "Epoch 2/100\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.7425 - accuracy: 0.7332 - val_loss: 2.3640 - val_accuracy: 0.1076 - lr: 0.0020\n",
            "Epoch 3/100\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.6500 - accuracy: 0.7673 - val_loss: 2.1987 - val_accuracy: 0.3329 - lr: 0.0020\n",
            "Epoch 4/100\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.5904 - accuracy: 0.7886 - val_loss: 2.1330 - val_accuracy: 0.3660 - lr: 0.0020\n",
            "Epoch 5/100\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.5575 - accuracy: 0.8019 - val_loss: 1.7122 - val_accuracy: 0.5330 - lr: 0.0020\n",
            "Epoch 6/100\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.5211 - accuracy: 0.8167 - val_loss: 1.4540 - val_accuracy: 0.5970 - lr: 0.0020\n",
            "Epoch 7/100\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4992 - accuracy: 0.8242 - val_loss: 1.2546 - val_accuracy: 0.6430 - lr: 0.0020\n",
            "Epoch 8/100\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4919 - accuracy: 0.8253 - val_loss: 0.9796 - val_accuracy: 0.6929 - lr: 0.0020\n",
            "Epoch 9/100\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4733 - accuracy: 0.8322 - val_loss: 0.8365 - val_accuracy: 0.7427 - lr: 0.0020\n",
            "Epoch 10/100\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4571 - accuracy: 0.8391 - val_loss: 0.8554 - val_accuracy: 0.7090 - lr: 0.0020\n",
            "Epoch 11/100\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4528 - accuracy: 0.8393 - val_loss: 0.5291 - val_accuracy: 0.8194 - lr: 0.0020\n",
            "Epoch 12/100\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4292 - accuracy: 0.8458 - val_loss: 0.4573 - val_accuracy: 0.8389 - lr: 0.0020\n",
            "Epoch 13/100\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4255 - accuracy: 0.8470 - val_loss: 0.4686 - val_accuracy: 0.8263 - lr: 0.0020\n",
            "Epoch 14/100\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4204 - accuracy: 0.8512 - val_loss: 0.4195 - val_accuracy: 0.8475 - lr: 0.0020\n",
            "Epoch 15/100\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4136 - accuracy: 0.8515 - val_loss: 0.3616 - val_accuracy: 0.8679 - lr: 0.0020\n",
            "Epoch 16/100\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4075 - accuracy: 0.8564 - val_loss: 0.4191 - val_accuracy: 0.8411 - lr: 0.0020\n",
            "Epoch 17/100\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3990 - accuracy: 0.8556 - val_loss: 0.4149 - val_accuracy: 0.8404 - lr: 0.0020\n",
            "Epoch 18/100\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3981 - accuracy: 0.8594 - val_loss: 0.3941 - val_accuracy: 0.8505 - lr: 0.0020\n",
            "Epoch 19/100\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3841 - accuracy: 0.8634 - val_loss: 0.3249 - val_accuracy: 0.8801 - lr: 0.0020\n",
            "Epoch 20/100\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3829 - accuracy: 0.8615 - val_loss: 0.3456 - val_accuracy: 0.8692 - lr: 0.0020\n",
            "Epoch 21/100\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3837 - accuracy: 0.8613 - val_loss: 0.4251 - val_accuracy: 0.8360 - lr: 0.0020\n",
            "Epoch 22/100\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3763 - accuracy: 0.8648 - val_loss: 0.3786 - val_accuracy: 0.8560 - lr: 0.0020\n",
            "Epoch 23/100\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3766 - accuracy: 0.8663 - val_loss: 0.4612 - val_accuracy: 0.8256 - lr: 0.0020\n",
            "Epoch 24/100\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3715 - accuracy: 0.8674 - val_loss: 0.4093 - val_accuracy: 0.8443 - lr: 0.0020\n",
            "Epoch 25/100\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3705 - accuracy: 0.8665 - val_loss: 0.3548 - val_accuracy: 0.8658 - lr: 0.0020\n",
            "Epoch 26/100\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3599 - accuracy: 0.8725 - val_loss: 0.4123 - val_accuracy: 0.8436 - lr: 0.0020\n",
            "Epoch 27/100\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3693 - accuracy: 0.8690 - val_loss: 0.2967 - val_accuracy: 0.8905 - lr: 0.0020\n",
            "Epoch 28/100\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3532 - accuracy: 0.8717 - val_loss: 0.3292 - val_accuracy: 0.8795 - lr: 0.0020\n",
            "Epoch 29/100\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3601 - accuracy: 0.8713 - val_loss: 0.3561 - val_accuracy: 0.8671 - lr: 0.0020\n",
            "Epoch 30/100\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3622 - accuracy: 0.8685 - val_loss: 0.3189 - val_accuracy: 0.8801 - lr: 0.0020\n",
            "Epoch 31/100\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3552 - accuracy: 0.8723 - val_loss: 0.3315 - val_accuracy: 0.8755 - lr: 0.0020\n",
            "Epoch 32/100\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3539 - accuracy: 0.8713 - val_loss: 0.3325 - val_accuracy: 0.8760 - lr: 0.0020\n",
            "Epoch 33/100\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3463 - accuracy: 0.8751 - val_loss: 0.3637 - val_accuracy: 0.8624 - lr: 0.0020\n",
            "Epoch 34/100\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3456 - accuracy: 0.8760 - val_loss: 0.3796 - val_accuracy: 0.8570 - lr: 0.0020\n",
            "Epoch 35/100\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3483 - accuracy: 0.8752 - val_loss: 0.3161 - val_accuracy: 0.8840 - lr: 0.0020\n",
            "Epoch 36/100\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3403 - accuracy: 0.8778 - val_loss: 0.3226 - val_accuracy: 0.8821 - lr: 0.0020\n",
            "Epoch 37/100\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3389 - accuracy: 0.8787 - val_loss: 0.2938 - val_accuracy: 0.8936 - lr: 0.0020\n",
            "Epoch 38/100\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3398 - accuracy: 0.8764 - val_loss: 0.3086 - val_accuracy: 0.8892 - lr: 0.0020\n",
            "Epoch 39/100\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3406 - accuracy: 0.8775 - val_loss: 0.4475 - val_accuracy: 0.8261 - lr: 0.0020\n",
            "Epoch 40/100\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3435 - accuracy: 0.8760 - val_loss: 0.2982 - val_accuracy: 0.8900 - lr: 0.0020\n",
            "Epoch 41/100\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3345 - accuracy: 0.8789 - val_loss: 0.2897 - val_accuracy: 0.8942 - lr: 0.0020\n",
            "Epoch 42/100\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3344 - accuracy: 0.8789 - val_loss: 0.3516 - val_accuracy: 0.8677 - lr: 0.0020\n",
            "Epoch 43/100\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3305 - accuracy: 0.8817 - val_loss: 0.3315 - val_accuracy: 0.8771 - lr: 0.0020\n",
            "Epoch 44/100\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3319 - accuracy: 0.8810 - val_loss: 0.3004 - val_accuracy: 0.8900 - lr: 0.0020\n",
            "Epoch 45/100\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3353 - accuracy: 0.8781 - val_loss: 0.2914 - val_accuracy: 0.8920 - lr: 0.0020\n",
            "Epoch 46/100\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3303 - accuracy: 0.8815 - val_loss: 0.3235 - val_accuracy: 0.8815 - lr: 0.0020\n",
            "Epoch 47/100\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3267 - accuracy: 0.8846 - val_loss: 0.3112 - val_accuracy: 0.8848 - lr: 0.0020\n",
            "Epoch 48/100\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3284 - accuracy: 0.8825 - val_loss: 0.3390 - val_accuracy: 0.8755 - lr: 0.0020\n",
            "Epoch 49/100\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3236 - accuracy: 0.8832 - val_loss: 0.3455 - val_accuracy: 0.8756 - lr: 0.0020\n",
            "Epoch 50/100\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3221 - accuracy: 0.8832 - val_loss: 0.3075 - val_accuracy: 0.8857 - lr: 0.0020\n",
            "Epoch 51/100\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3249 - accuracy: 0.8810 - val_loss: 0.3190 - val_accuracy: 0.8844 - lr: 0.0020\n",
            "Epoch 52/100\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3195 - accuracy: 0.8860 - val_loss: 0.3041 - val_accuracy: 0.8917 - lr: 0.0020\n",
            "Epoch 53/100\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3231 - accuracy: 0.8832 - val_loss: 0.3121 - val_accuracy: 0.8876 - lr: 0.0020\n",
            "Epoch 54/100\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3202 - accuracy: 0.8831 - val_loss: 0.2869 - val_accuracy: 0.8928 - lr: 0.0020\n",
            "Epoch 55/100\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3189 - accuracy: 0.8842 - val_loss: 0.3002 - val_accuracy: 0.8896 - lr: 0.0020\n",
            "Epoch 56/100\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3174 - accuracy: 0.8841 - val_loss: 0.3384 - val_accuracy: 0.8739 - lr: 0.0020\n",
            "Epoch 1/100\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 1.2296 - accuracy: 0.5784 - val_loss: 2.5547 - val_accuracy: 0.1090 - lr: 0.0020\n",
            "Epoch 2/100\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.7467 - accuracy: 0.7302 - val_loss: 2.4954 - val_accuracy: 0.0997 - lr: 0.0020\n",
            "Epoch 3/100\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.6493 - accuracy: 0.7657 - val_loss: 2.4097 - val_accuracy: 0.1392 - lr: 0.0020\n",
            "Epoch 4/100\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.5850 - accuracy: 0.7922 - val_loss: 2.4448 - val_accuracy: 0.1646 - lr: 0.0020\n",
            "Epoch 5/100\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.5480 - accuracy: 0.8095 - val_loss: 1.9226 - val_accuracy: 0.3424 - lr: 0.0020\n",
            "Epoch 6/100\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.5174 - accuracy: 0.8156 - val_loss: 1.3484 - val_accuracy: 0.5689 - lr: 0.0020\n",
            "Epoch 7/100\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4958 - accuracy: 0.8249 - val_loss: 1.0545 - val_accuracy: 0.6357 - lr: 0.0020\n",
            "Epoch 8/100\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4724 - accuracy: 0.8333 - val_loss: 0.7892 - val_accuracy: 0.7340 - lr: 0.0020\n",
            "Epoch 9/100\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4567 - accuracy: 0.8388 - val_loss: 0.6892 - val_accuracy: 0.7408 - lr: 0.0020\n",
            "Epoch 10/100\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4460 - accuracy: 0.8423 - val_loss: 0.6927 - val_accuracy: 0.7451 - lr: 0.0020\n",
            "Epoch 11/100\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4349 - accuracy: 0.8453 - val_loss: 0.5658 - val_accuracy: 0.8000 - lr: 0.0020\n",
            "Epoch 12/100\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4295 - accuracy: 0.8473 - val_loss: 0.5255 - val_accuracy: 0.8044 - lr: 0.0020\n",
            "Epoch 13/100\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4150 - accuracy: 0.8522 - val_loss: 0.4361 - val_accuracy: 0.8374 - lr: 0.0020\n",
            "Epoch 14/100\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4122 - accuracy: 0.8530 - val_loss: 0.4669 - val_accuracy: 0.8256 - lr: 0.0020\n",
            "Epoch 15/100\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4040 - accuracy: 0.8552 - val_loss: 0.4869 - val_accuracy: 0.8184 - lr: 0.0020\n",
            "Epoch 16/100\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3977 - accuracy: 0.8589 - val_loss: 0.4640 - val_accuracy: 0.8366 - lr: 0.0020\n",
            "Epoch 17/100\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3956 - accuracy: 0.8573 - val_loss: 0.3673 - val_accuracy: 0.8625 - lr: 0.0020\n",
            "Epoch 18/100\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3848 - accuracy: 0.8611 - val_loss: 0.3444 - val_accuracy: 0.8725 - lr: 0.0020\n",
            "Epoch 19/100\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3818 - accuracy: 0.8635 - val_loss: 0.3449 - val_accuracy: 0.8749 - lr: 0.0020\n",
            "Epoch 20/100\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3797 - accuracy: 0.8643 - val_loss: 0.3456 - val_accuracy: 0.8740 - lr: 0.0020\n",
            "Epoch 21/100\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3752 - accuracy: 0.8662 - val_loss: 0.3236 - val_accuracy: 0.8845 - lr: 0.0020\n",
            "Epoch 22/100\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3754 - accuracy: 0.8668 - val_loss: 0.3219 - val_accuracy: 0.8806 - lr: 0.0020\n",
            "Epoch 23/100\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3687 - accuracy: 0.8665 - val_loss: 0.4055 - val_accuracy: 0.8500 - lr: 0.0020\n",
            "Epoch 24/100\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3641 - accuracy: 0.8687 - val_loss: 0.3291 - val_accuracy: 0.8806 - lr: 0.0020\n",
            "Epoch 25/100\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3550 - accuracy: 0.8735 - val_loss: 0.4975 - val_accuracy: 0.8094 - lr: 0.0020\n",
            "Epoch 26/100\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3641 - accuracy: 0.8697 - val_loss: 0.3277 - val_accuracy: 0.8776 - lr: 0.0020\n",
            "Epoch 27/100\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3584 - accuracy: 0.8705 - val_loss: 0.3237 - val_accuracy: 0.8819 - lr: 0.0020\n",
            "Epoch 28/100\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3522 - accuracy: 0.8738 - val_loss: 0.3591 - val_accuracy: 0.8669 - lr: 0.0020\n",
            "Epoch 29/100\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3606 - accuracy: 0.8709 - val_loss: 0.3319 - val_accuracy: 0.8786 - lr: 0.0020\n",
            "Epoch 30/100\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3544 - accuracy: 0.8739 - val_loss: 0.3144 - val_accuracy: 0.8850 - lr: 0.0020\n",
            "Epoch 31/100\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3514 - accuracy: 0.8731 - val_loss: 0.3497 - val_accuracy: 0.8717 - lr: 0.0020\n",
            "Epoch 32/100\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3504 - accuracy: 0.8745 - val_loss: 0.3089 - val_accuracy: 0.8864 - lr: 0.0020\n",
            "Epoch 33/100\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3429 - accuracy: 0.8773 - val_loss: 0.3432 - val_accuracy: 0.8695 - lr: 0.0020\n",
            "Epoch 34/100\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3436 - accuracy: 0.8752 - val_loss: 0.3184 - val_accuracy: 0.8815 - lr: 0.0020\n",
            "Epoch 35/100\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3371 - accuracy: 0.8781 - val_loss: 0.3196 - val_accuracy: 0.8821 - lr: 0.0020\n",
            "Epoch 36/100\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3393 - accuracy: 0.8776 - val_loss: 0.3001 - val_accuracy: 0.8915 - lr: 0.0020\n",
            "Epoch 37/100\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3371 - accuracy: 0.8792 - val_loss: 0.3042 - val_accuracy: 0.8875 - lr: 0.0020\n",
            "Epoch 38/100\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3395 - accuracy: 0.8794 - val_loss: 0.2996 - val_accuracy: 0.8890 - lr: 0.0020\n",
            "Epoch 39/100\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3351 - accuracy: 0.8792 - val_loss: 0.2967 - val_accuracy: 0.8909 - lr: 0.0020\n",
            "Epoch 40/100\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3364 - accuracy: 0.8800 - val_loss: 0.4085 - val_accuracy: 0.8451 - lr: 0.0020\n",
            "Epoch 41/100\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3352 - accuracy: 0.8797 - val_loss: 0.3043 - val_accuracy: 0.8881 - lr: 0.0020\n",
            "Epoch 42/100\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3265 - accuracy: 0.8836 - val_loss: 0.3273 - val_accuracy: 0.8783 - lr: 0.0020\n",
            "Epoch 43/100\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3284 - accuracy: 0.8823 - val_loss: 0.3027 - val_accuracy: 0.8910 - lr: 0.0020\n",
            "Epoch 44/100\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3288 - accuracy: 0.8808 - val_loss: 0.3062 - val_accuracy: 0.8874 - lr: 0.0020\n",
            "Epoch 45/100\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3293 - accuracy: 0.8819 - val_loss: 0.3141 - val_accuracy: 0.8813 - lr: 0.0020\n",
            "Epoch 46/100\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3228 - accuracy: 0.8837 - val_loss: 0.2987 - val_accuracy: 0.8917 - lr: 0.0020\n",
            "Epoch 47/100\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3299 - accuracy: 0.8805 - val_loss: 0.3253 - val_accuracy: 0.8829 - lr: 0.0020\n",
            "Epoch 48/100\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3163 - accuracy: 0.8863 - val_loss: 0.3246 - val_accuracy: 0.8799 - lr: 0.0020\n",
            "Epoch 49/100\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3246 - accuracy: 0.8815 - val_loss: 0.3159 - val_accuracy: 0.8816 - lr: 0.0020\n",
            "Epoch 50/100\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3189 - accuracy: 0.8835 - val_loss: 0.2973 - val_accuracy: 0.8911 - lr: 0.0020\n",
            "Epoch 51/100\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3196 - accuracy: 0.8831 - val_loss: 0.3184 - val_accuracy: 0.8821 - lr: 0.0020\n",
            "Epoch 52/100\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3238 - accuracy: 0.8844 - val_loss: 0.2916 - val_accuracy: 0.8961 - lr: 0.0020\n",
            "Epoch 53/100\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3192 - accuracy: 0.8850 - val_loss: 0.3157 - val_accuracy: 0.8842 - lr: 0.0020\n",
            "Epoch 54/100\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3190 - accuracy: 0.8865 - val_loss: 0.3042 - val_accuracy: 0.8906 - lr: 0.0020\n",
            "Epoch 55/100\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3119 - accuracy: 0.8877 - val_loss: 0.2919 - val_accuracy: 0.8903 - lr: 0.0020\n",
            "Epoch 56/100\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3162 - accuracy: 0.8868 - val_loss: 0.2950 - val_accuracy: 0.8945 - lr: 0.0020\n",
            "Epoch 57/100\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3146 - accuracy: 0.8856 - val_loss: 0.3074 - val_accuracy: 0.8885 - lr: 0.0020\n",
            "Epoch 58/100\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3150 - accuracy: 0.8863 - val_loss: 0.3230 - val_accuracy: 0.8804 - lr: 0.0020\n",
            "Epoch 59/100\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3166 - accuracy: 0.8871 - val_loss: 0.2871 - val_accuracy: 0.8946 - lr: 0.0020\n",
            "Epoch 60/100\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3095 - accuracy: 0.8869 - val_loss: 0.2890 - val_accuracy: 0.8947 - lr: 0.0020\n",
            "Epoch 61/100\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3083 - accuracy: 0.8903 - val_loss: 0.2847 - val_accuracy: 0.8982 - lr: 0.0020\n",
            "Epoch 62/100\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3113 - accuracy: 0.8879 - val_loss: 0.3684 - val_accuracy: 0.8643 - lr: 0.0020\n",
            "Epoch 63/100\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3087 - accuracy: 0.8895 - val_loss: 0.3430 - val_accuracy: 0.8760 - lr: 0.0020\n",
            "Epoch 64/100\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3110 - accuracy: 0.8871 - val_loss: 0.2922 - val_accuracy: 0.8930 - lr: 0.0020\n",
            "Epoch 65/100\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3073 - accuracy: 0.8898 - val_loss: 0.3800 - val_accuracy: 0.8562 - lr: 0.0020\n",
            "Epoch 66/100\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3122 - accuracy: 0.8880 - val_loss: 0.3660 - val_accuracy: 0.8625 - lr: 0.0020\n",
            "Epoch 67/100\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3088 - accuracy: 0.8870 - val_loss: 0.3555 - val_accuracy: 0.8670 - lr: 0.0020\n",
            "Epoch 68/100\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3057 - accuracy: 0.8899 - val_loss: 0.3096 - val_accuracy: 0.8875 - lr: 0.0020\n",
            "Epoch 69/100\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3050 - accuracy: 0.8905 - val_loss: 0.3008 - val_accuracy: 0.8901 - lr: 0.0020\n",
            "Epoch 70/100\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2996 - accuracy: 0.8908 - val_loss: 0.3043 - val_accuracy: 0.8894 - lr: 0.0020\n",
            "Epoch 71/100\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3080 - accuracy: 0.8894 - val_loss: 0.3872 - val_accuracy: 0.8539 - lr: 0.0020\n",
            "Epoch 72/100\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3026 - accuracy: 0.8909 - val_loss: 0.4192 - val_accuracy: 0.8459 - lr: 0.0020\n",
            "Epoch 73/100\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3056 - accuracy: 0.8869 - val_loss: 0.3278 - val_accuracy: 0.8816 - lr: 0.0020\n",
            "Epoch 74/100\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3038 - accuracy: 0.8915 - val_loss: 0.3028 - val_accuracy: 0.8885 - lr: 0.0020\n",
            "Epoch 75/100\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3039 - accuracy: 0.8909 - val_loss: 0.2878 - val_accuracy: 0.8969 - lr: 0.0020\n",
            "Epoch 76/100\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2985 - accuracy: 0.8928 - val_loss: 0.3737 - val_accuracy: 0.8577 - lr: 0.0020\n",
            "Epoch 1/100\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 1.1656 - accuracy: 0.5946 - val_loss: 2.3752 - val_accuracy: 0.0980 - lr: 0.0020\n",
            "Epoch 2/100\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.7453 - accuracy: 0.7274 - val_loss: 2.3242 - val_accuracy: 0.1614 - lr: 0.0020\n",
            "Epoch 3/100\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.6514 - accuracy: 0.7594 - val_loss: 2.2663 - val_accuracy: 0.2699 - lr: 0.0020\n",
            "Epoch 4/100\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.5926 - accuracy: 0.7832 - val_loss: 1.9555 - val_accuracy: 0.4604 - lr: 0.0020\n",
            "Epoch 5/100\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.5517 - accuracy: 0.8030 - val_loss: 1.6229 - val_accuracy: 0.5404 - lr: 0.0020\n",
            "Epoch 6/100\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.5209 - accuracy: 0.8132 - val_loss: 1.2908 - val_accuracy: 0.6364 - lr: 0.0020\n",
            "Epoch 7/100\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.5009 - accuracy: 0.8196 - val_loss: 1.0799 - val_accuracy: 0.6595 - lr: 0.0020\n",
            "Epoch 8/100\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4818 - accuracy: 0.8297 - val_loss: 0.8790 - val_accuracy: 0.7028 - lr: 0.0020\n",
            "Epoch 9/100\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4681 - accuracy: 0.8330 - val_loss: 0.5944 - val_accuracy: 0.7981 - lr: 0.0020\n",
            "Epoch 10/100\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4510 - accuracy: 0.8395 - val_loss: 0.5200 - val_accuracy: 0.8150 - lr: 0.0020\n",
            "Epoch 11/100\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4419 - accuracy: 0.8422 - val_loss: 0.4535 - val_accuracy: 0.8328 - lr: 0.0020\n",
            "Epoch 12/100\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4369 - accuracy: 0.8449 - val_loss: 0.4470 - val_accuracy: 0.8357 - lr: 0.0020\n",
            "Epoch 13/100\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4242 - accuracy: 0.8480 - val_loss: 0.3634 - val_accuracy: 0.8683 - lr: 0.0020\n",
            "Epoch 14/100\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4212 - accuracy: 0.8517 - val_loss: 0.3939 - val_accuracy: 0.8528 - lr: 0.0020\n",
            "Epoch 15/100\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4143 - accuracy: 0.8514 - val_loss: 0.3839 - val_accuracy: 0.8559 - lr: 0.0020\n",
            "Epoch 16/100\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4097 - accuracy: 0.8558 - val_loss: 0.3660 - val_accuracy: 0.8616 - lr: 0.0020\n",
            "Epoch 17/100\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4019 - accuracy: 0.8581 - val_loss: 0.4123 - val_accuracy: 0.8524 - lr: 0.0020\n",
            "Epoch 18/100\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3952 - accuracy: 0.8576 - val_loss: 0.3907 - val_accuracy: 0.8526 - lr: 0.0020\n",
            "Epoch 19/100\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3896 - accuracy: 0.8606 - val_loss: 0.3310 - val_accuracy: 0.8767 - lr: 0.0020\n",
            "Epoch 20/100\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3886 - accuracy: 0.8599 - val_loss: 0.3707 - val_accuracy: 0.8621 - lr: 0.0020\n",
            "Epoch 21/100\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3785 - accuracy: 0.8642 - val_loss: 0.4262 - val_accuracy: 0.8334 - lr: 0.0020\n",
            "Epoch 22/100\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3787 - accuracy: 0.8646 - val_loss: 0.3780 - val_accuracy: 0.8536 - lr: 0.0020\n",
            "Epoch 23/100\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3711 - accuracy: 0.8657 - val_loss: 0.4408 - val_accuracy: 0.8226 - lr: 0.0020\n",
            "Epoch 24/100\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3783 - accuracy: 0.8652 - val_loss: 0.3247 - val_accuracy: 0.8773 - lr: 0.0020\n",
            "Epoch 25/100\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3700 - accuracy: 0.8677 - val_loss: 0.3492 - val_accuracy: 0.8698 - lr: 0.0020\n",
            "Epoch 26/100\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3643 - accuracy: 0.8717 - val_loss: 0.3704 - val_accuracy: 0.8627 - lr: 0.0020\n",
            "Epoch 27/100\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3599 - accuracy: 0.8731 - val_loss: 0.3601 - val_accuracy: 0.8645 - lr: 0.0020\n",
            "Epoch 28/100\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3552 - accuracy: 0.8733 - val_loss: 0.3207 - val_accuracy: 0.8813 - lr: 0.0020\n",
            "Epoch 29/100\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3623 - accuracy: 0.8697 - val_loss: 0.3289 - val_accuracy: 0.8770 - lr: 0.0020\n",
            "Epoch 30/100\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3512 - accuracy: 0.8748 - val_loss: 0.3291 - val_accuracy: 0.8744 - lr: 0.0020\n",
            "Epoch 31/100\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3503 - accuracy: 0.8736 - val_loss: 0.3123 - val_accuracy: 0.8832 - lr: 0.0020\n",
            "Epoch 32/100\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3545 - accuracy: 0.8727 - val_loss: 0.3789 - val_accuracy: 0.8569 - lr: 0.0020\n",
            "Epoch 33/100\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3473 - accuracy: 0.8740 - val_loss: 0.3242 - val_accuracy: 0.8785 - lr: 0.0020\n",
            "Epoch 34/100\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3547 - accuracy: 0.8731 - val_loss: 0.3328 - val_accuracy: 0.8754 - lr: 0.0020\n",
            "Epoch 35/100\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3494 - accuracy: 0.8748 - val_loss: 0.3012 - val_accuracy: 0.8875 - lr: 0.0020\n",
            "Epoch 36/100\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3410 - accuracy: 0.8775 - val_loss: 0.3391 - val_accuracy: 0.8709 - lr: 0.0020\n",
            "Epoch 37/100\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3357 - accuracy: 0.8815 - val_loss: 0.3473 - val_accuracy: 0.8698 - lr: 0.0020\n",
            "Epoch 38/100\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3411 - accuracy: 0.8753 - val_loss: 0.3307 - val_accuracy: 0.8755 - lr: 0.0020\n",
            "Epoch 39/100\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3457 - accuracy: 0.8758 - val_loss: 0.2973 - val_accuracy: 0.8899 - lr: 0.0020\n",
            "Epoch 40/100\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3361 - accuracy: 0.8796 - val_loss: 0.3404 - val_accuracy: 0.8679 - lr: 0.0020\n",
            "Epoch 41/100\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3305 - accuracy: 0.8808 - val_loss: 0.3102 - val_accuracy: 0.8848 - lr: 0.0020\n",
            "Epoch 42/100\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3350 - accuracy: 0.8789 - val_loss: 0.3132 - val_accuracy: 0.8809 - lr: 0.0020\n",
            "Epoch 43/100\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3319 - accuracy: 0.8790 - val_loss: 0.2993 - val_accuracy: 0.8910 - lr: 0.0020\n",
            "Epoch 44/100\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3301 - accuracy: 0.8824 - val_loss: 0.2969 - val_accuracy: 0.8891 - lr: 0.0020\n",
            "Epoch 45/100\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3282 - accuracy: 0.8826 - val_loss: 0.3201 - val_accuracy: 0.8834 - lr: 0.0020\n",
            "Epoch 46/100\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3267 - accuracy: 0.8833 - val_loss: 0.2986 - val_accuracy: 0.8899 - lr: 0.0020\n",
            "Epoch 47/100\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3257 - accuracy: 0.8827 - val_loss: 0.3152 - val_accuracy: 0.8805 - lr: 0.0020\n",
            "Epoch 48/100\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3289 - accuracy: 0.8831 - val_loss: 0.3216 - val_accuracy: 0.8824 - lr: 0.0020\n",
            "Epoch 49/100\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3231 - accuracy: 0.8832 - val_loss: 0.2955 - val_accuracy: 0.8915 - lr: 0.0020\n",
            "Epoch 50/100\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3200 - accuracy: 0.8857 - val_loss: 0.3533 - val_accuracy: 0.8700 - lr: 0.0020\n",
            "Epoch 51/100\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3221 - accuracy: 0.8847 - val_loss: 0.2938 - val_accuracy: 0.8915 - lr: 0.0020\n",
            "Epoch 52/100\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3223 - accuracy: 0.8861 - val_loss: 0.3128 - val_accuracy: 0.8845 - lr: 0.0020\n",
            "Epoch 53/100\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3245 - accuracy: 0.8829 - val_loss: 0.3293 - val_accuracy: 0.8739 - lr: 0.0020\n",
            "Epoch 54/100\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3219 - accuracy: 0.8851 - val_loss: 0.3000 - val_accuracy: 0.8891 - lr: 0.0020\n",
            "Epoch 55/100\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3187 - accuracy: 0.8862 - val_loss: 0.2972 - val_accuracy: 0.8892 - lr: 0.0020\n",
            "Epoch 56/100\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3186 - accuracy: 0.8862 - val_loss: 0.3592 - val_accuracy: 0.8609 - lr: 0.0020\n",
            "Epoch 57/100\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3133 - accuracy: 0.8883 - val_loss: 0.3085 - val_accuracy: 0.8884 - lr: 0.0020\n",
            "Epoch 58/100\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3190 - accuracy: 0.8862 - val_loss: 0.2987 - val_accuracy: 0.8899 - lr: 0.0020\n",
            "Epoch 59/100\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3147 - accuracy: 0.8865 - val_loss: 0.2927 - val_accuracy: 0.8949 - lr: 0.0020\n",
            "Epoch 60/100\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3135 - accuracy: 0.8870 - val_loss: 0.3291 - val_accuracy: 0.8771 - lr: 0.0020\n",
            "Epoch 61/100\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3174 - accuracy: 0.8865 - val_loss: 0.3165 - val_accuracy: 0.8829 - lr: 0.0020\n",
            "Epoch 62/100\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3191 - accuracy: 0.8851 - val_loss: 0.2874 - val_accuracy: 0.8919 - lr: 0.0020\n",
            "Epoch 63/100\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3095 - accuracy: 0.8886 - val_loss: 0.3474 - val_accuracy: 0.8719 - lr: 0.0020\n",
            "Epoch 64/100\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3105 - accuracy: 0.8875 - val_loss: 0.3178 - val_accuracy: 0.8815 - lr: 0.0020\n",
            "Epoch 65/100\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3073 - accuracy: 0.8896 - val_loss: 0.3555 - val_accuracy: 0.8630 - lr: 0.0020\n",
            "Epoch 66/100\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3110 - accuracy: 0.8861 - val_loss: 0.3283 - val_accuracy: 0.8752 - lr: 0.0020\n",
            "Epoch 67/100\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3119 - accuracy: 0.8880 - val_loss: 0.3106 - val_accuracy: 0.8831 - lr: 0.0020\n",
            "Epoch 68/100\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3141 - accuracy: 0.8866 - val_loss: 0.2960 - val_accuracy: 0.8940 - lr: 0.0020\n",
            "Epoch 69/100\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3058 - accuracy: 0.8896 - val_loss: 0.3218 - val_accuracy: 0.8783 - lr: 0.0020\n",
            "Epoch 70/100\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3050 - accuracy: 0.8884 - val_loss: 0.3194 - val_accuracy: 0.8806 - lr: 0.0020\n",
            "Epoch 71/100\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3118 - accuracy: 0.8875 - val_loss: 0.2910 - val_accuracy: 0.8924 - lr: 0.0020\n",
            "Epoch 72/100\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3052 - accuracy: 0.8903 - val_loss: 0.3220 - val_accuracy: 0.8786 - lr: 0.0020\n",
            "Epoch 73/100\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3082 - accuracy: 0.8864 - val_loss: 0.2935 - val_accuracy: 0.8928 - lr: 0.0020\n",
            "Epoch 74/100\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3077 - accuracy: 0.8878 - val_loss: 0.3979 - val_accuracy: 0.8514 - lr: 0.0020\n",
            "Epoch 1/100\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 1.2225 - accuracy: 0.5838 - val_loss: 2.5748 - val_accuracy: 0.0986 - lr: 0.0020\n",
            "Epoch 2/100\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.7416 - accuracy: 0.7311 - val_loss: 2.6472 - val_accuracy: 0.1452 - lr: 0.0020\n",
            "Epoch 3/100\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.6508 - accuracy: 0.7645 - val_loss: 2.6848 - val_accuracy: 0.1959 - lr: 0.0020\n",
            "Epoch 4/100\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.5974 - accuracy: 0.7831 - val_loss: 2.6502 - val_accuracy: 0.2271 - lr: 0.0020\n",
            "Epoch 5/100\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.5553 - accuracy: 0.8015 - val_loss: 2.2365 - val_accuracy: 0.3458 - lr: 0.0020\n",
            "Epoch 6/100\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.5269 - accuracy: 0.8125 - val_loss: 1.7026 - val_accuracy: 0.4999 - lr: 0.0020\n",
            "Epoch 7/100\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.5012 - accuracy: 0.8207 - val_loss: 1.2214 - val_accuracy: 0.6409 - lr: 0.0020\n",
            "Epoch 8/100\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4854 - accuracy: 0.8259 - val_loss: 0.8798 - val_accuracy: 0.7211 - lr: 0.0020\n",
            "Epoch 9/100\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4700 - accuracy: 0.8313 - val_loss: 0.6805 - val_accuracy: 0.7620 - lr: 0.0020\n",
            "Epoch 10/100\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4579 - accuracy: 0.8341 - val_loss: 0.5182 - val_accuracy: 0.8285 - lr: 0.0020\n",
            "Epoch 11/100\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4478 - accuracy: 0.8370 - val_loss: 0.4047 - val_accuracy: 0.8581 - lr: 0.0020\n",
            "Epoch 12/100\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4316 - accuracy: 0.8471 - val_loss: 0.5497 - val_accuracy: 0.7847 - lr: 0.0020\n",
            "Epoch 13/100\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4296 - accuracy: 0.8453 - val_loss: 0.4174 - val_accuracy: 0.8453 - lr: 0.0020\n",
            "Epoch 14/100\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4185 - accuracy: 0.8475 - val_loss: 0.5166 - val_accuracy: 0.8010 - lr: 0.0020\n",
            "Epoch 15/100\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4092 - accuracy: 0.8516 - val_loss: 0.4321 - val_accuracy: 0.8399 - lr: 0.0020\n",
            "Epoch 16/100\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4051 - accuracy: 0.8551 - val_loss: 0.3626 - val_accuracy: 0.8634 - lr: 0.0020\n",
            "Epoch 17/100\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3976 - accuracy: 0.8594 - val_loss: 0.5332 - val_accuracy: 0.7914 - lr: 0.0020\n",
            "Epoch 18/100\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3974 - accuracy: 0.8557 - val_loss: 0.4313 - val_accuracy: 0.8372 - lr: 0.0020\n",
            "Epoch 19/100\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3936 - accuracy: 0.8583 - val_loss: 0.4125 - val_accuracy: 0.8440 - lr: 0.0020\n",
            "Epoch 20/100\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3852 - accuracy: 0.8602 - val_loss: 0.3983 - val_accuracy: 0.8489 - lr: 0.0020\n",
            "Epoch 21/100\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3797 - accuracy: 0.8648 - val_loss: 0.4942 - val_accuracy: 0.8034 - lr: 0.0020\n",
            "Epoch 22/100\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3806 - accuracy: 0.8630 - val_loss: 0.3284 - val_accuracy: 0.8800 - lr: 0.0020\n",
            "Epoch 23/100\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3745 - accuracy: 0.8674 - val_loss: 0.3442 - val_accuracy: 0.8706 - lr: 0.0020\n",
            "Epoch 24/100\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3698 - accuracy: 0.8676 - val_loss: 0.3391 - val_accuracy: 0.8737 - lr: 0.0020\n",
            "Epoch 25/100\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3695 - accuracy: 0.8671 - val_loss: 0.3745 - val_accuracy: 0.8654 - lr: 0.0020\n",
            "Epoch 26/100\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3639 - accuracy: 0.8687 - val_loss: 0.3172 - val_accuracy: 0.8846 - lr: 0.0020\n",
            "Epoch 27/100\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3609 - accuracy: 0.8708 - val_loss: 0.3091 - val_accuracy: 0.8865 - lr: 0.0020\n",
            "Epoch 28/100\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3571 - accuracy: 0.8701 - val_loss: 0.3463 - val_accuracy: 0.8729 - lr: 0.0020\n",
            "Epoch 29/100\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3544 - accuracy: 0.8733 - val_loss: 0.3141 - val_accuracy: 0.8834 - lr: 0.0020\n",
            "Epoch 30/100\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3553 - accuracy: 0.8712 - val_loss: 0.3103 - val_accuracy: 0.8829 - lr: 0.0020\n",
            "Epoch 31/100\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3511 - accuracy: 0.8726 - val_loss: 0.3674 - val_accuracy: 0.8633 - lr: 0.0020\n",
            "Epoch 32/100\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3498 - accuracy: 0.8733 - val_loss: 0.3754 - val_accuracy: 0.8600 - lr: 0.0020\n",
            "Epoch 33/100\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3514 - accuracy: 0.8742 - val_loss: 0.3102 - val_accuracy: 0.8854 - lr: 0.0020\n",
            "Epoch 34/100\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3476 - accuracy: 0.8759 - val_loss: 0.3847 - val_accuracy: 0.8524 - lr: 0.0020\n",
            "Epoch 35/100\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3459 - accuracy: 0.8768 - val_loss: 0.3165 - val_accuracy: 0.8798 - lr: 0.0020\n",
            "Epoch 36/100\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3467 - accuracy: 0.8748 - val_loss: 0.3077 - val_accuracy: 0.8845 - lr: 0.0020\n",
            "Epoch 37/100\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3430 - accuracy: 0.8763 - val_loss: 0.2870 - val_accuracy: 0.8949 - lr: 0.0020\n",
            "Epoch 38/100\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3399 - accuracy: 0.8791 - val_loss: 0.3519 - val_accuracy: 0.8696 - lr: 0.0020\n",
            "Epoch 39/100\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3414 - accuracy: 0.8760 - val_loss: 0.2922 - val_accuracy: 0.8920 - lr: 0.0020\n",
            "Epoch 40/100\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3354 - accuracy: 0.8785 - val_loss: 0.2930 - val_accuracy: 0.8942 - lr: 0.0020\n",
            "Epoch 41/100\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3332 - accuracy: 0.8803 - val_loss: 0.3064 - val_accuracy: 0.8860 - lr: 0.0020\n",
            "Epoch 42/100\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3379 - accuracy: 0.8795 - val_loss: 0.2982 - val_accuracy: 0.8884 - lr: 0.0020\n",
            "Epoch 43/100\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3312 - accuracy: 0.8805 - val_loss: 0.2933 - val_accuracy: 0.8930 - lr: 0.0020\n",
            "Epoch 44/100\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3250 - accuracy: 0.8804 - val_loss: 0.3065 - val_accuracy: 0.8864 - lr: 0.0020\n",
            "Epoch 45/100\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3316 - accuracy: 0.8811 - val_loss: 0.3633 - val_accuracy: 0.8631 - lr: 0.0020\n",
            "Epoch 46/100\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3313 - accuracy: 0.8788 - val_loss: 0.2915 - val_accuracy: 0.8926 - lr: 0.0020\n",
            "Epoch 47/100\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3291 - accuracy: 0.8818 - val_loss: 0.2922 - val_accuracy: 0.8929 - lr: 0.0020\n",
            "Epoch 48/100\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3269 - accuracy: 0.8825 - val_loss: 0.3319 - val_accuracy: 0.8745 - lr: 0.0020\n",
            "Epoch 49/100\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3232 - accuracy: 0.8831 - val_loss: 0.3497 - val_accuracy: 0.8681 - lr: 0.0020\n",
            "Epoch 50/100\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3238 - accuracy: 0.8827 - val_loss: 0.3643 - val_accuracy: 0.8639 - lr: 0.0020\n",
            "Epoch 51/100\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3274 - accuracy: 0.8811 - val_loss: 0.3201 - val_accuracy: 0.8831 - lr: 0.0020\n",
            "Epoch 52/100\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3200 - accuracy: 0.8835 - val_loss: 0.3199 - val_accuracy: 0.8824 - lr: 0.0020\n",
            "Epoch 1/100\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.9238 - accuracy: 0.6731 - val_loss: 3.0950 - val_accuracy: 0.1450 - lr: 0.0100\n",
            "Epoch 2/100\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.6128 - accuracy: 0.7787 - val_loss: 2.5642 - val_accuracy: 0.2338 - lr: 0.0100\n",
            "Epoch 3/100\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.5433 - accuracy: 0.8063 - val_loss: 1.7214 - val_accuracy: 0.3728 - lr: 0.0100\n",
            "Epoch 4/100\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.5079 - accuracy: 0.8198 - val_loss: 1.4927 - val_accuracy: 0.4931 - lr: 0.0100\n",
            "Epoch 5/100\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4824 - accuracy: 0.8253 - val_loss: 1.1144 - val_accuracy: 0.6229 - lr: 0.0100\n",
            "Epoch 6/100\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4649 - accuracy: 0.8318 - val_loss: 1.1568 - val_accuracy: 0.5934 - lr: 0.0100\n",
            "Epoch 7/100\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4473 - accuracy: 0.8393 - val_loss: 1.0394 - val_accuracy: 0.6186 - lr: 0.0100\n",
            "Epoch 8/100\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4454 - accuracy: 0.8409 - val_loss: 0.6613 - val_accuracy: 0.7375 - lr: 0.0100\n",
            "Epoch 9/100\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4316 - accuracy: 0.8448 - val_loss: 0.5653 - val_accuracy: 0.7763 - lr: 0.0100\n",
            "Epoch 10/100\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4234 - accuracy: 0.8448 - val_loss: 0.6654 - val_accuracy: 0.7405 - lr: 0.0100\n",
            "Epoch 11/100\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4156 - accuracy: 0.8507 - val_loss: 0.6252 - val_accuracy: 0.7671 - lr: 0.0100\n",
            "Epoch 12/100\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4120 - accuracy: 0.8516 - val_loss: 0.5137 - val_accuracy: 0.7924 - lr: 0.0100\n",
            "Epoch 13/100\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4026 - accuracy: 0.8543 - val_loss: 0.4277 - val_accuracy: 0.8419 - lr: 0.0100\n",
            "Epoch 14/100\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3906 - accuracy: 0.8594 - val_loss: 0.5448 - val_accuracy: 0.7890 - lr: 0.0100\n",
            "Epoch 15/100\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3933 - accuracy: 0.8610 - val_loss: 0.3487 - val_accuracy: 0.8683 - lr: 0.0100\n",
            "Epoch 16/100\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3881 - accuracy: 0.8596 - val_loss: 0.4533 - val_accuracy: 0.8332 - lr: 0.0100\n",
            "Epoch 17/100\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3880 - accuracy: 0.8578 - val_loss: 0.4373 - val_accuracy: 0.8224 - lr: 0.0100\n",
            "Epoch 18/100\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3805 - accuracy: 0.8633 - val_loss: 0.3965 - val_accuracy: 0.8491 - lr: 0.0100\n",
            "Epoch 19/100\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3799 - accuracy: 0.8624 - val_loss: 0.4300 - val_accuracy: 0.8410 - lr: 0.0100\n",
            "Epoch 20/100\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3757 - accuracy: 0.8632 - val_loss: 0.4765 - val_accuracy: 0.8079 - lr: 0.0100\n",
            "Epoch 21/100\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3767 - accuracy: 0.8662 - val_loss: 0.4344 - val_accuracy: 0.8307 - lr: 0.0100\n",
            "Epoch 22/100\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3696 - accuracy: 0.8658 - val_loss: 0.4894 - val_accuracy: 0.8154 - lr: 0.0100\n",
            "Epoch 23/100\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3694 - accuracy: 0.8651 - val_loss: 0.3800 - val_accuracy: 0.8564 - lr: 0.0100\n",
            "Epoch 24/100\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3667 - accuracy: 0.8687 - val_loss: 0.3550 - val_accuracy: 0.8666 - lr: 0.0100\n",
            "Epoch 25/100\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3627 - accuracy: 0.8695 - val_loss: 0.4414 - val_accuracy: 0.8174 - lr: 0.0100\n",
            "Epoch 26/100\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3587 - accuracy: 0.8721 - val_loss: 0.5148 - val_accuracy: 0.8173 - lr: 0.0100\n",
            "Epoch 27/100\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3646 - accuracy: 0.8678 - val_loss: 0.4814 - val_accuracy: 0.8123 - lr: 0.0100\n",
            "Epoch 28/100\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3531 - accuracy: 0.8734 - val_loss: 0.5166 - val_accuracy: 0.8217 - lr: 0.0100\n",
            "Epoch 29/100\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3576 - accuracy: 0.8713 - val_loss: 0.3431 - val_accuracy: 0.8749 - lr: 0.0100\n",
            "Epoch 30/100\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3557 - accuracy: 0.8723 - val_loss: 0.3839 - val_accuracy: 0.8624 - lr: 0.0100\n",
            "Epoch 31/100\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3528 - accuracy: 0.8730 - val_loss: 0.4286 - val_accuracy: 0.8399 - lr: 0.0100\n",
            "Epoch 32/100\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3488 - accuracy: 0.8747 - val_loss: 0.5870 - val_accuracy: 0.7814 - lr: 0.0100\n",
            "Epoch 33/100\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3465 - accuracy: 0.8774 - val_loss: 0.3232 - val_accuracy: 0.8840 - lr: 0.0100\n",
            "Epoch 34/100\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3473 - accuracy: 0.8752 - val_loss: 0.4008 - val_accuracy: 0.8421 - lr: 0.0100\n",
            "Epoch 35/100\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3408 - accuracy: 0.8766 - val_loss: 0.3841 - val_accuracy: 0.8519 - lr: 0.0100\n",
            "Epoch 36/100\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3405 - accuracy: 0.8776 - val_loss: 0.3580 - val_accuracy: 0.8615 - lr: 0.0100\n",
            "Epoch 37/100\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3416 - accuracy: 0.8757 - val_loss: 0.3457 - val_accuracy: 0.8716 - lr: 0.0100\n",
            "Epoch 38/100\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3370 - accuracy: 0.8775 - val_loss: 0.3976 - val_accuracy: 0.8429 - lr: 0.0100\n",
            "Epoch 39/100\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3417 - accuracy: 0.8760 - val_loss: 0.3906 - val_accuracy: 0.8449 - lr: 0.0100\n",
            "Epoch 40/100\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3383 - accuracy: 0.8785 - val_loss: 0.5508 - val_accuracy: 0.7746 - lr: 0.0100\n",
            "Epoch 41/100\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3402 - accuracy: 0.8770 - val_loss: 0.3291 - val_accuracy: 0.8724 - lr: 0.0100\n",
            "Epoch 42/100\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3332 - accuracy: 0.8792 - val_loss: 0.3759 - val_accuracy: 0.8576 - lr: 0.0100\n",
            "Epoch 43/100\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3352 - accuracy: 0.8804 - val_loss: 0.3940 - val_accuracy: 0.8469 - lr: 0.0100\n",
            "Epoch 44/100\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3332 - accuracy: 0.8794 - val_loss: 0.3002 - val_accuracy: 0.8879 - lr: 0.0100\n",
            "Epoch 45/100\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3297 - accuracy: 0.8817 - val_loss: 0.4713 - val_accuracy: 0.8229 - lr: 0.0100\n",
            "Epoch 46/100\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3297 - accuracy: 0.8817 - val_loss: 0.3378 - val_accuracy: 0.8751 - lr: 0.0100\n",
            "Epoch 47/100\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3326 - accuracy: 0.8820 - val_loss: 0.2954 - val_accuracy: 0.8907 - lr: 0.0100\n",
            "Epoch 48/100\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3303 - accuracy: 0.8811 - val_loss: 0.3048 - val_accuracy: 0.8861 - lr: 0.0100\n",
            "Epoch 49/100\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3290 - accuracy: 0.8806 - val_loss: 0.3223 - val_accuracy: 0.8794 - lr: 0.0100\n",
            "Epoch 50/100\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3262 - accuracy: 0.8816 - val_loss: 0.4318 - val_accuracy: 0.8234 - lr: 0.0100\n",
            "Epoch 51/100\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3228 - accuracy: 0.8844 - val_loss: 0.3460 - val_accuracy: 0.8634 - lr: 0.0100\n",
            "Epoch 52/100\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3280 - accuracy: 0.8823 - val_loss: 0.3208 - val_accuracy: 0.8775 - lr: 0.0100\n",
            "Epoch 53/100\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3250 - accuracy: 0.8835 - val_loss: 0.3605 - val_accuracy: 0.8568 - lr: 0.0100\n",
            "Epoch 54/100\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3208 - accuracy: 0.8840 - val_loss: 0.2988 - val_accuracy: 0.8898 - lr: 0.0100\n",
            "Epoch 55/100\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3241 - accuracy: 0.8818 - val_loss: 0.3656 - val_accuracy: 0.8633 - lr: 0.0100\n",
            "Epoch 56/100\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3219 - accuracy: 0.8832 - val_loss: 0.3423 - val_accuracy: 0.8685 - lr: 0.0100\n",
            "Epoch 57/100\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3222 - accuracy: 0.8824 - val_loss: 0.3183 - val_accuracy: 0.8800 - lr: 0.0100\n",
            "Epoch 58/100\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3209 - accuracy: 0.8847 - val_loss: 0.3240 - val_accuracy: 0.8830 - lr: 0.0100\n",
            "Epoch 59/100\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3175 - accuracy: 0.8852 - val_loss: 0.3322 - val_accuracy: 0.8734 - lr: 0.0100\n",
            "Epoch 60/100\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3133 - accuracy: 0.8877 - val_loss: 0.2910 - val_accuracy: 0.8914 - lr: 0.0100\n",
            "Epoch 61/100\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3178 - accuracy: 0.8855 - val_loss: 0.2912 - val_accuracy: 0.8921 - lr: 0.0100\n",
            "Epoch 62/100\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3171 - accuracy: 0.8845 - val_loss: 0.3151 - val_accuracy: 0.8830 - lr: 0.0100\n",
            "Epoch 63/100\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3173 - accuracy: 0.8850 - val_loss: 0.2972 - val_accuracy: 0.8866 - lr: 0.0100\n",
            "Epoch 64/100\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3159 - accuracy: 0.8849 - val_loss: 0.3751 - val_accuracy: 0.8593 - lr: 0.0100\n",
            "Epoch 65/100\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3162 - accuracy: 0.8848 - val_loss: 0.3098 - val_accuracy: 0.8824 - lr: 0.0100\n",
            "Epoch 66/100\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3133 - accuracy: 0.8859 - val_loss: 0.2984 - val_accuracy: 0.8889 - lr: 0.0100\n",
            "Epoch 67/100\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3139 - accuracy: 0.8868 - val_loss: 0.2990 - val_accuracy: 0.8892 - lr: 0.0100\n",
            "Epoch 68/100\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3145 - accuracy: 0.8860 - val_loss: 0.2894 - val_accuracy: 0.8934 - lr: 0.0100\n",
            "Epoch 69/100\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3078 - accuracy: 0.8880 - val_loss: 0.2914 - val_accuracy: 0.8953 - lr: 0.0100\n",
            "Epoch 70/100\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3128 - accuracy: 0.8871 - val_loss: 0.3948 - val_accuracy: 0.8565 - lr: 0.0100\n",
            "Epoch 71/100\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3128 - accuracy: 0.8862 - val_loss: 0.2926 - val_accuracy: 0.8925 - lr: 0.0100\n",
            "Epoch 72/100\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3112 - accuracy: 0.8885 - val_loss: 0.2798 - val_accuracy: 0.8978 - lr: 0.0100\n",
            "Epoch 73/100\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3068 - accuracy: 0.8895 - val_loss: 0.4554 - val_accuracy: 0.8231 - lr: 0.0100\n",
            "Epoch 74/100\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3089 - accuracy: 0.8870 - val_loss: 0.3078 - val_accuracy: 0.8886 - lr: 0.0100\n",
            "Epoch 75/100\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3068 - accuracy: 0.8905 - val_loss: 0.3549 - val_accuracy: 0.8694 - lr: 0.0100\n",
            "Epoch 76/100\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3091 - accuracy: 0.8899 - val_loss: 0.3257 - val_accuracy: 0.8766 - lr: 0.0100\n",
            "Epoch 77/100\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3076 - accuracy: 0.8896 - val_loss: 0.3026 - val_accuracy: 0.8899 - lr: 0.0100\n",
            "Epoch 78/100\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3046 - accuracy: 0.8916 - val_loss: 0.3356 - val_accuracy: 0.8808 - lr: 0.0100\n",
            "Epoch 79/100\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3109 - accuracy: 0.8879 - val_loss: 0.2852 - val_accuracy: 0.8980 - lr: 0.0100\n",
            "Epoch 80/100\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3055 - accuracy: 0.8893 - val_loss: 0.3111 - val_accuracy: 0.8874 - lr: 0.0100\n",
            "Epoch 81/100\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3025 - accuracy: 0.8913 - val_loss: 0.3815 - val_accuracy: 0.8631 - lr: 0.0100\n",
            "Epoch 82/100\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3029 - accuracy: 0.8908 - val_loss: 0.3721 - val_accuracy: 0.8590 - lr: 0.0100\n",
            "Epoch 83/100\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3076 - accuracy: 0.8893 - val_loss: 0.2848 - val_accuracy: 0.8989 - lr: 0.0100\n",
            "Epoch 84/100\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3044 - accuracy: 0.8896 - val_loss: 0.2916 - val_accuracy: 0.8964 - lr: 0.0100\n",
            "Epoch 85/100\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3014 - accuracy: 0.8917 - val_loss: 0.3396 - val_accuracy: 0.8680 - lr: 0.0100\n",
            "Epoch 86/100\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3051 - accuracy: 0.8901 - val_loss: 0.2986 - val_accuracy: 0.8923 - lr: 0.0100\n",
            "Epoch 87/100\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3025 - accuracy: 0.8897 - val_loss: 0.3007 - val_accuracy: 0.8923 - lr: 0.0100\n",
            "Epoch 88/100\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3067 - accuracy: 0.8895 - val_loss: 0.3146 - val_accuracy: 0.8851 - lr: 0.0100\n",
            "Epoch 89/100\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2972 - accuracy: 0.8921 - val_loss: 0.2972 - val_accuracy: 0.8920 - lr: 0.0100\n",
            "Epoch 90/100\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3021 - accuracy: 0.8907 - val_loss: 0.3318 - val_accuracy: 0.8736 - lr: 0.0100\n",
            "Epoch 91/100\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2991 - accuracy: 0.8929 - val_loss: 0.2930 - val_accuracy: 0.8920 - lr: 0.0100\n",
            "Epoch 92/100\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3011 - accuracy: 0.8921 - val_loss: 0.2959 - val_accuracy: 0.8953 - lr: 0.0100\n",
            "Epoch 93/100\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2999 - accuracy: 0.8908 - val_loss: 0.3381 - val_accuracy: 0.8769 - lr: 0.0100\n",
            "Epoch 94/100\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2982 - accuracy: 0.8931 - val_loss: 0.2693 - val_accuracy: 0.8995 - lr: 0.0100\n",
            "Epoch 95/100\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2937 - accuracy: 0.8937 - val_loss: 0.5195 - val_accuracy: 0.8309 - lr: 0.0100\n",
            "Epoch 96/100\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2969 - accuracy: 0.8926 - val_loss: 0.3455 - val_accuracy: 0.8699 - lr: 0.0100\n",
            "Epoch 97/100\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2936 - accuracy: 0.8953 - val_loss: 0.3305 - val_accuracy: 0.8719 - lr: 0.0100\n",
            "Epoch 98/100\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2981 - accuracy: 0.8926 - val_loss: 0.2895 - val_accuracy: 0.8941 - lr: 0.0100\n",
            "Epoch 99/100\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3013 - accuracy: 0.8922 - val_loss: 0.2788 - val_accuracy: 0.8997 - lr: 0.0100\n",
            "Epoch 100/100\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2948 - accuracy: 0.8918 - val_loss: 0.3623 - val_accuracy: 0.8731 - lr: 0.0100\n",
            "Epoch 1/100\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.9309 - accuracy: 0.6657 - val_loss: 3.6627 - val_accuracy: 0.1280 - lr: 0.0100\n",
            "Epoch 2/100\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.6222 - accuracy: 0.7698 - val_loss: 2.8590 - val_accuracy: 0.1261 - lr: 0.0100\n",
            "Epoch 3/100\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.5510 - accuracy: 0.8002 - val_loss: 1.6350 - val_accuracy: 0.5505 - lr: 0.0100\n",
            "Epoch 4/100\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.5160 - accuracy: 0.8124 - val_loss: 1.6169 - val_accuracy: 0.4864 - lr: 0.0100\n",
            "Epoch 5/100\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4910 - accuracy: 0.8215 - val_loss: 1.3517 - val_accuracy: 0.4946 - lr: 0.0100\n",
            "Epoch 6/100\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4699 - accuracy: 0.8309 - val_loss: 1.3584 - val_accuracy: 0.5376 - lr: 0.0100\n",
            "Epoch 7/100\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4601 - accuracy: 0.8329 - val_loss: 0.9351 - val_accuracy: 0.6385 - lr: 0.0100\n",
            "Epoch 8/100\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4488 - accuracy: 0.8397 - val_loss: 0.8372 - val_accuracy: 0.6777 - lr: 0.0100\n",
            "Epoch 9/100\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4350 - accuracy: 0.8429 - val_loss: 0.5461 - val_accuracy: 0.7979 - lr: 0.0100\n",
            "Epoch 10/100\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4272 - accuracy: 0.8460 - val_loss: 0.5414 - val_accuracy: 0.7859 - lr: 0.0100\n",
            "Epoch 11/100\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4232 - accuracy: 0.8470 - val_loss: 0.4633 - val_accuracy: 0.8116 - lr: 0.0100\n",
            "Epoch 12/100\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4147 - accuracy: 0.8515 - val_loss: 0.5973 - val_accuracy: 0.7530 - lr: 0.0100\n",
            "Epoch 13/100\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4116 - accuracy: 0.8499 - val_loss: 0.3829 - val_accuracy: 0.8591 - lr: 0.0100\n",
            "Epoch 14/100\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4022 - accuracy: 0.8547 - val_loss: 0.4556 - val_accuracy: 0.8194 - lr: 0.0100\n",
            "Epoch 15/100\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4018 - accuracy: 0.8569 - val_loss: 0.5755 - val_accuracy: 0.7549 - lr: 0.0100\n",
            "Epoch 16/100\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3940 - accuracy: 0.8572 - val_loss: 0.4633 - val_accuracy: 0.8244 - lr: 0.0100\n",
            "Epoch 17/100\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3931 - accuracy: 0.8595 - val_loss: 0.4489 - val_accuracy: 0.8254 - lr: 0.0100\n",
            "Epoch 18/100\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3873 - accuracy: 0.8599 - val_loss: 0.4069 - val_accuracy: 0.8384 - lr: 0.0100\n",
            "Epoch 19/100\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3836 - accuracy: 0.8610 - val_loss: 0.4826 - val_accuracy: 0.8052 - lr: 0.0100\n",
            "Epoch 20/100\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3842 - accuracy: 0.8619 - val_loss: 0.4581 - val_accuracy: 0.8174 - lr: 0.0100\n",
            "Epoch 21/100\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3748 - accuracy: 0.8634 - val_loss: 0.5322 - val_accuracy: 0.7950 - lr: 0.0100\n",
            "Epoch 22/100\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3708 - accuracy: 0.8652 - val_loss: 0.3509 - val_accuracy: 0.8705 - lr: 0.0100\n",
            "Epoch 23/100\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3758 - accuracy: 0.8626 - val_loss: 0.3248 - val_accuracy: 0.8760 - lr: 0.0100\n",
            "Epoch 24/100\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3633 - accuracy: 0.8692 - val_loss: 0.4620 - val_accuracy: 0.8114 - lr: 0.0100\n",
            "Epoch 25/100\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3632 - accuracy: 0.8703 - val_loss: 0.4443 - val_accuracy: 0.8298 - lr: 0.0100\n",
            "Epoch 26/100\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3582 - accuracy: 0.8713 - val_loss: 0.4026 - val_accuracy: 0.8468 - lr: 0.0100\n",
            "Epoch 27/100\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3653 - accuracy: 0.8686 - val_loss: 0.5683 - val_accuracy: 0.7644 - lr: 0.0100\n",
            "Epoch 28/100\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3613 - accuracy: 0.8694 - val_loss: 0.3950 - val_accuracy: 0.8436 - lr: 0.0100\n",
            "Epoch 29/100\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3550 - accuracy: 0.8727 - val_loss: 0.4223 - val_accuracy: 0.8311 - lr: 0.0100\n",
            "Epoch 30/100\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3568 - accuracy: 0.8703 - val_loss: 0.3170 - val_accuracy: 0.8799 - lr: 0.0100\n",
            "Epoch 31/100\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3605 - accuracy: 0.8698 - val_loss: 0.3300 - val_accuracy: 0.8756 - lr: 0.0100\n",
            "Epoch 32/100\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3511 - accuracy: 0.8723 - val_loss: 0.4518 - val_accuracy: 0.8217 - lr: 0.0100\n",
            "Epoch 33/100\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3476 - accuracy: 0.8733 - val_loss: 0.3038 - val_accuracy: 0.8842 - lr: 0.0100\n",
            "Epoch 34/100\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3502 - accuracy: 0.8716 - val_loss: 0.4095 - val_accuracy: 0.8381 - lr: 0.0100\n",
            "Epoch 35/100\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3464 - accuracy: 0.8742 - val_loss: 0.3471 - val_accuracy: 0.8702 - lr: 0.0100\n",
            "Epoch 36/100\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3402 - accuracy: 0.8759 - val_loss: 0.4794 - val_accuracy: 0.8167 - lr: 0.0100\n",
            "Epoch 37/100\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3420 - accuracy: 0.8762 - val_loss: 0.3945 - val_accuracy: 0.8361 - lr: 0.0100\n",
            "Epoch 38/100\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3440 - accuracy: 0.8753 - val_loss: 0.4911 - val_accuracy: 0.8139 - lr: 0.0100\n",
            "Epoch 39/100\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3427 - accuracy: 0.8767 - val_loss: 0.3143 - val_accuracy: 0.8779 - lr: 0.0100\n",
            "Epoch 40/100\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3387 - accuracy: 0.8762 - val_loss: 0.4728 - val_accuracy: 0.8092 - lr: 0.0100\n",
            "Epoch 41/100\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3375 - accuracy: 0.8765 - val_loss: 0.3411 - val_accuracy: 0.8750 - lr: 0.0100\n",
            "Epoch 42/100\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3383 - accuracy: 0.8762 - val_loss: 0.5794 - val_accuracy: 0.7841 - lr: 0.0100\n",
            "Epoch 43/100\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3367 - accuracy: 0.8795 - val_loss: 0.5339 - val_accuracy: 0.8179 - lr: 0.0100\n",
            "Epoch 44/100\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3364 - accuracy: 0.8778 - val_loss: 0.3299 - val_accuracy: 0.8754 - lr: 0.0100\n",
            "Epoch 45/100\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3343 - accuracy: 0.8802 - val_loss: 0.3507 - val_accuracy: 0.8650 - lr: 0.0100\n",
            "Epoch 46/100\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3361 - accuracy: 0.8769 - val_loss: 0.3724 - val_accuracy: 0.8537 - lr: 0.0100\n",
            "Epoch 47/100\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3323 - accuracy: 0.8793 - val_loss: 0.5167 - val_accuracy: 0.7924 - lr: 0.0100\n",
            "Epoch 48/100\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3320 - accuracy: 0.8794 - val_loss: 0.5110 - val_accuracy: 0.8234 - lr: 0.0100\n",
            "Epoch 1/100\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.9212 - accuracy: 0.6698 - val_loss: 4.2086 - val_accuracy: 0.1035 - lr: 0.0100\n",
            "Epoch 2/100\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.6182 - accuracy: 0.7744 - val_loss: 3.9592 - val_accuracy: 0.1469 - lr: 0.0100\n",
            "Epoch 3/100\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.5504 - accuracy: 0.7994 - val_loss: 2.2927 - val_accuracy: 0.3025 - lr: 0.0100\n",
            "Epoch 4/100\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.5154 - accuracy: 0.8103 - val_loss: 2.1006 - val_accuracy: 0.2566 - lr: 0.0100\n",
            "Epoch 5/100\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4904 - accuracy: 0.8223 - val_loss: 1.6423 - val_accuracy: 0.4804 - lr: 0.0100\n",
            "Epoch 6/100\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4725 - accuracy: 0.8301 - val_loss: 1.4193 - val_accuracy: 0.5426 - lr: 0.0100\n",
            "Epoch 7/100\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4506 - accuracy: 0.8382 - val_loss: 0.7510 - val_accuracy: 0.7044 - lr: 0.0100\n",
            "Epoch 8/100\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4376 - accuracy: 0.8406 - val_loss: 1.0395 - val_accuracy: 0.5936 - lr: 0.0100\n",
            "Epoch 9/100\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4359 - accuracy: 0.8409 - val_loss: 0.5539 - val_accuracy: 0.7731 - lr: 0.0100\n",
            "Epoch 10/100\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4257 - accuracy: 0.8470 - val_loss: 0.4126 - val_accuracy: 0.8489 - lr: 0.0100\n",
            "Epoch 11/100\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4200 - accuracy: 0.8487 - val_loss: 0.7096 - val_accuracy: 0.7185 - lr: 0.0100\n",
            "Epoch 12/100\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4074 - accuracy: 0.8531 - val_loss: 0.6672 - val_accuracy: 0.7349 - lr: 0.0100\n",
            "Epoch 13/100\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4044 - accuracy: 0.8555 - val_loss: 0.5474 - val_accuracy: 0.7845 - lr: 0.0100\n",
            "Epoch 14/100\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3998 - accuracy: 0.8568 - val_loss: 0.7876 - val_accuracy: 0.7028 - lr: 0.0100\n",
            "Epoch 15/100\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3995 - accuracy: 0.8562 - val_loss: 0.4641 - val_accuracy: 0.8210 - lr: 0.0100\n",
            "Epoch 16/100\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3917 - accuracy: 0.8587 - val_loss: 0.4344 - val_accuracy: 0.8328 - lr: 0.0100\n",
            "Epoch 17/100\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3917 - accuracy: 0.8584 - val_loss: 0.6061 - val_accuracy: 0.7558 - lr: 0.0100\n",
            "Epoch 18/100\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3828 - accuracy: 0.8611 - val_loss: 0.4674 - val_accuracy: 0.8110 - lr: 0.0100\n",
            "Epoch 19/100\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3779 - accuracy: 0.8648 - val_loss: 0.3363 - val_accuracy: 0.8814 - lr: 0.0100\n",
            "Epoch 20/100\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3802 - accuracy: 0.8605 - val_loss: 0.5110 - val_accuracy: 0.7835 - lr: 0.0100\n",
            "Epoch 21/100\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3735 - accuracy: 0.8658 - val_loss: 0.4996 - val_accuracy: 0.8292 - lr: 0.0100\n",
            "Epoch 22/100\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3705 - accuracy: 0.8662 - val_loss: 0.4371 - val_accuracy: 0.8321 - lr: 0.0100\n",
            "Epoch 23/100\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3691 - accuracy: 0.8665 - val_loss: 0.4292 - val_accuracy: 0.8229 - lr: 0.0100\n",
            "Epoch 24/100\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3714 - accuracy: 0.8654 - val_loss: 0.3861 - val_accuracy: 0.8559 - lr: 0.0100\n",
            "Epoch 25/100\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3639 - accuracy: 0.8702 - val_loss: 0.5259 - val_accuracy: 0.7784 - lr: 0.0100\n",
            "Epoch 26/100\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3553 - accuracy: 0.8715 - val_loss: 0.4326 - val_accuracy: 0.8257 - lr: 0.0100\n",
            "Epoch 27/100\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3652 - accuracy: 0.8680 - val_loss: 0.4724 - val_accuracy: 0.8149 - lr: 0.0100\n",
            "Epoch 28/100\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3570 - accuracy: 0.8711 - val_loss: 0.4679 - val_accuracy: 0.8155 - lr: 0.0100\n",
            "Epoch 29/100\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3546 - accuracy: 0.8717 - val_loss: 0.3639 - val_accuracy: 0.8720 - lr: 0.0100\n",
            "Epoch 30/100\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3590 - accuracy: 0.8689 - val_loss: 0.3969 - val_accuracy: 0.8494 - lr: 0.0100\n",
            "Epoch 31/100\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3536 - accuracy: 0.8724 - val_loss: 0.3346 - val_accuracy: 0.8733 - lr: 0.0100\n",
            "Epoch 32/100\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3528 - accuracy: 0.8719 - val_loss: 0.3120 - val_accuracy: 0.8831 - lr: 0.0100\n",
            "Epoch 33/100\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3497 - accuracy: 0.8735 - val_loss: 0.4539 - val_accuracy: 0.8231 - lr: 0.0100\n",
            "Epoch 34/100\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3522 - accuracy: 0.8721 - val_loss: 0.3741 - val_accuracy: 0.8580 - lr: 0.0100\n",
            "Epoch 35/100\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3480 - accuracy: 0.8734 - val_loss: 0.3145 - val_accuracy: 0.8825 - lr: 0.0100\n",
            "Epoch 36/100\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3496 - accuracy: 0.8740 - val_loss: 0.3337 - val_accuracy: 0.8775 - lr: 0.0100\n",
            "Epoch 37/100\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3448 - accuracy: 0.8761 - val_loss: 0.4323 - val_accuracy: 0.8340 - lr: 0.0100\n",
            "Epoch 38/100\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3401 - accuracy: 0.8762 - val_loss: 0.3689 - val_accuracy: 0.8512 - lr: 0.0100\n",
            "Epoch 39/100\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3436 - accuracy: 0.8748 - val_loss: 0.3619 - val_accuracy: 0.8610 - lr: 0.0100\n",
            "Epoch 40/100\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3373 - accuracy: 0.8787 - val_loss: 0.3571 - val_accuracy: 0.8634 - lr: 0.0100\n",
            "Epoch 41/100\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3342 - accuracy: 0.8780 - val_loss: 0.5120 - val_accuracy: 0.7912 - lr: 0.0100\n",
            "Epoch 42/100\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3364 - accuracy: 0.8780 - val_loss: 0.3375 - val_accuracy: 0.8800 - lr: 0.0100\n",
            "Epoch 43/100\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3334 - accuracy: 0.8798 - val_loss: 0.3265 - val_accuracy: 0.8804 - lr: 0.0100\n",
            "Epoch 44/100\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3385 - accuracy: 0.8788 - val_loss: 0.3052 - val_accuracy: 0.8857 - lr: 0.0100\n",
            "Epoch 45/100\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3325 - accuracy: 0.8786 - val_loss: 0.3375 - val_accuracy: 0.8701 - lr: 0.0100\n",
            "Epoch 46/100\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3323 - accuracy: 0.8798 - val_loss: 0.4101 - val_accuracy: 0.8451 - lr: 0.0100\n",
            "Epoch 47/100\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3378 - accuracy: 0.8787 - val_loss: 0.3136 - val_accuracy: 0.8848 - lr: 0.0100\n",
            "Epoch 48/100\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3329 - accuracy: 0.8792 - val_loss: 0.3631 - val_accuracy: 0.8633 - lr: 0.0100\n",
            "Epoch 49/100\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3288 - accuracy: 0.8809 - val_loss: 0.3800 - val_accuracy: 0.8489 - lr: 0.0100\n",
            "Epoch 50/100\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3270 - accuracy: 0.8815 - val_loss: 0.3807 - val_accuracy: 0.8546 - lr: 0.0100\n",
            "Epoch 51/100\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3297 - accuracy: 0.8807 - val_loss: 0.3329 - val_accuracy: 0.8719 - lr: 0.0100\n",
            "Epoch 52/100\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3239 - accuracy: 0.8823 - val_loss: 0.3257 - val_accuracy: 0.8785 - lr: 0.0100\n",
            "Epoch 53/100\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3244 - accuracy: 0.8828 - val_loss: 0.3612 - val_accuracy: 0.8622 - lr: 0.0100\n",
            "Epoch 54/100\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3236 - accuracy: 0.8829 - val_loss: 0.4009 - val_accuracy: 0.8345 - lr: 0.0100\n",
            "Epoch 55/100\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3216 - accuracy: 0.8831 - val_loss: 0.2907 - val_accuracy: 0.8926 - lr: 0.0100\n",
            "Epoch 56/100\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3224 - accuracy: 0.8827 - val_loss: 0.2988 - val_accuracy: 0.8896 - lr: 0.0100\n",
            "Epoch 57/100\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3246 - accuracy: 0.8830 - val_loss: 0.2861 - val_accuracy: 0.8942 - lr: 0.0100\n",
            "Epoch 58/100\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3202 - accuracy: 0.8825 - val_loss: 0.2864 - val_accuracy: 0.8963 - lr: 0.0100\n",
            "Epoch 59/100\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3214 - accuracy: 0.8830 - val_loss: 0.2905 - val_accuracy: 0.8935 - lr: 0.0100\n",
            "Epoch 60/100\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3192 - accuracy: 0.8839 - val_loss: 0.3009 - val_accuracy: 0.8911 - lr: 0.0100\n",
            "Epoch 61/100\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3218 - accuracy: 0.8838 - val_loss: 0.2833 - val_accuracy: 0.8969 - lr: 0.0100\n",
            "Epoch 62/100\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3178 - accuracy: 0.8847 - val_loss: 0.3168 - val_accuracy: 0.8836 - lr: 0.0100\n",
            "Epoch 63/100\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3180 - accuracy: 0.8856 - val_loss: 0.2768 - val_accuracy: 0.9003 - lr: 0.0100\n",
            "Epoch 64/100\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3212 - accuracy: 0.8838 - val_loss: 0.3175 - val_accuracy: 0.8820 - lr: 0.0100\n",
            "Epoch 65/100\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3174 - accuracy: 0.8841 - val_loss: 0.3039 - val_accuracy: 0.8896 - lr: 0.0100\n",
            "Epoch 66/100\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3157 - accuracy: 0.8851 - val_loss: 0.2879 - val_accuracy: 0.8978 - lr: 0.0100\n",
            "Epoch 67/100\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3159 - accuracy: 0.8850 - val_loss: 0.2762 - val_accuracy: 0.8997 - lr: 0.0100\n",
            "Epoch 68/100\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3166 - accuracy: 0.8849 - val_loss: 0.3336 - val_accuracy: 0.8761 - lr: 0.0100\n",
            "Epoch 69/100\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3158 - accuracy: 0.8835 - val_loss: 0.3012 - val_accuracy: 0.8905 - lr: 0.0100\n",
            "Epoch 70/100\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3139 - accuracy: 0.8863 - val_loss: 0.3554 - val_accuracy: 0.8624 - lr: 0.0100\n",
            "Epoch 71/100\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3137 - accuracy: 0.8866 - val_loss: 0.3227 - val_accuracy: 0.8845 - lr: 0.0100\n",
            "Epoch 72/100\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3126 - accuracy: 0.8863 - val_loss: 0.3110 - val_accuracy: 0.8795 - lr: 0.0100\n",
            "Epoch 73/100\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3093 - accuracy: 0.8870 - val_loss: 0.2835 - val_accuracy: 0.8929 - lr: 0.0100\n",
            "Epoch 74/100\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3099 - accuracy: 0.8872 - val_loss: 0.2959 - val_accuracy: 0.8895 - lr: 0.0100\n",
            "Epoch 75/100\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3142 - accuracy: 0.8867 - val_loss: 0.2752 - val_accuracy: 0.8992 - lr: 0.0100\n",
            "Epoch 76/100\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3109 - accuracy: 0.8881 - val_loss: 0.2763 - val_accuracy: 0.9007 - lr: 0.0100\n",
            "Epoch 77/100\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3071 - accuracy: 0.8882 - val_loss: 0.2980 - val_accuracy: 0.8884 - lr: 0.0100\n",
            "Epoch 78/100\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3114 - accuracy: 0.8867 - val_loss: 0.2880 - val_accuracy: 0.8979 - lr: 0.0100\n",
            "Epoch 79/100\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3107 - accuracy: 0.8873 - val_loss: 0.3039 - val_accuracy: 0.8939 - lr: 0.0100\n",
            "Epoch 80/100\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3048 - accuracy: 0.8892 - val_loss: 0.2838 - val_accuracy: 0.8949 - lr: 0.0100\n",
            "Epoch 81/100\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3113 - accuracy: 0.8892 - val_loss: 0.3128 - val_accuracy: 0.8873 - lr: 0.0100\n",
            "Epoch 82/100\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3057 - accuracy: 0.8891 - val_loss: 0.4664 - val_accuracy: 0.8399 - lr: 0.0100\n",
            "Epoch 83/100\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3052 - accuracy: 0.8880 - val_loss: 0.2780 - val_accuracy: 0.8982 - lr: 0.0100\n",
            "Epoch 84/100\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3072 - accuracy: 0.8892 - val_loss: 0.2779 - val_accuracy: 0.8967 - lr: 0.0100\n",
            "Epoch 85/100\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3051 - accuracy: 0.8894 - val_loss: 0.2748 - val_accuracy: 0.9003 - lr: 0.0100\n",
            "Epoch 86/100\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3027 - accuracy: 0.8913 - val_loss: 0.3194 - val_accuracy: 0.8866 - lr: 0.0100\n",
            "Epoch 87/100\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3076 - accuracy: 0.8869 - val_loss: 0.3272 - val_accuracy: 0.8785 - lr: 0.0100\n",
            "Epoch 88/100\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3029 - accuracy: 0.8900 - val_loss: 0.3004 - val_accuracy: 0.8934 - lr: 0.0100\n",
            "Epoch 89/100\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3020 - accuracy: 0.8895 - val_loss: 0.2792 - val_accuracy: 0.8963 - lr: 0.0100\n",
            "Epoch 90/100\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3039 - accuracy: 0.8897 - val_loss: 0.2804 - val_accuracy: 0.8946 - lr: 0.0100\n",
            "Epoch 91/100\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3026 - accuracy: 0.8913 - val_loss: 0.3116 - val_accuracy: 0.8811 - lr: 0.0100\n",
            "Epoch 1/100\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.9474 - accuracy: 0.6569 - val_loss: 4.0098 - val_accuracy: 0.1029 - lr: 0.0100\n",
            "Epoch 2/100\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.6216 - accuracy: 0.7718 - val_loss: 3.2257 - val_accuracy: 0.1200 - lr: 0.0100\n",
            "Epoch 3/100\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.5467 - accuracy: 0.8030 - val_loss: 2.0029 - val_accuracy: 0.3212 - lr: 0.0100\n",
            "Epoch 4/100\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.5128 - accuracy: 0.8182 - val_loss: 2.1076 - val_accuracy: 0.3155 - lr: 0.0100\n",
            "Epoch 5/100\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4880 - accuracy: 0.8255 - val_loss: 1.8620 - val_accuracy: 0.4505 - lr: 0.0100\n",
            "Epoch 6/100\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4670 - accuracy: 0.8349 - val_loss: 1.1867 - val_accuracy: 0.6531 - lr: 0.0100\n",
            "Epoch 7/100\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4578 - accuracy: 0.8401 - val_loss: 1.5556 - val_accuracy: 0.4589 - lr: 0.0100\n",
            "Epoch 8/100\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4457 - accuracy: 0.8401 - val_loss: 1.4075 - val_accuracy: 0.5555 - lr: 0.0100\n",
            "Epoch 9/100\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4350 - accuracy: 0.8444 - val_loss: 0.9953 - val_accuracy: 0.6316 - lr: 0.0100\n",
            "Epoch 10/100\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4250 - accuracy: 0.8485 - val_loss: 0.5365 - val_accuracy: 0.7695 - lr: 0.0100\n",
            "Epoch 11/100\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4129 - accuracy: 0.8516 - val_loss: 0.6910 - val_accuracy: 0.7402 - lr: 0.0100\n",
            "Epoch 12/100\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4150 - accuracy: 0.8515 - val_loss: 0.4833 - val_accuracy: 0.8060 - lr: 0.0100\n",
            "Epoch 13/100\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4094 - accuracy: 0.8530 - val_loss: 0.8140 - val_accuracy: 0.6954 - lr: 0.0100\n",
            "Epoch 14/100\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4019 - accuracy: 0.8556 - val_loss: 0.4222 - val_accuracy: 0.8434 - lr: 0.0100\n",
            "Epoch 15/100\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3957 - accuracy: 0.8578 - val_loss: 0.6284 - val_accuracy: 0.7418 - lr: 0.0100\n",
            "Epoch 16/100\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3965 - accuracy: 0.8574 - val_loss: 0.5092 - val_accuracy: 0.7986 - lr: 0.0100\n",
            "Epoch 17/100\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3894 - accuracy: 0.8590 - val_loss: 0.5670 - val_accuracy: 0.7615 - lr: 0.0100\n",
            "Epoch 18/100\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3855 - accuracy: 0.8625 - val_loss: 0.3729 - val_accuracy: 0.8618 - lr: 0.0100\n",
            "Epoch 19/100\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3798 - accuracy: 0.8634 - val_loss: 0.4323 - val_accuracy: 0.8350 - lr: 0.0100\n",
            "Epoch 20/100\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3802 - accuracy: 0.8643 - val_loss: 0.5172 - val_accuracy: 0.7819 - lr: 0.0100\n",
            "Epoch 21/100\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3804 - accuracy: 0.8630 - val_loss: 0.4229 - val_accuracy: 0.8381 - lr: 0.0100\n",
            "Epoch 22/100\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3784 - accuracy: 0.8648 - val_loss: 0.3535 - val_accuracy: 0.8711 - lr: 0.0100\n",
            "Epoch 23/100\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3687 - accuracy: 0.8664 - val_loss: 0.4202 - val_accuracy: 0.8443 - lr: 0.0100\n",
            "Epoch 24/100\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3675 - accuracy: 0.8679 - val_loss: 0.5606 - val_accuracy: 0.7889 - lr: 0.0100\n",
            "Epoch 25/100\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3695 - accuracy: 0.8665 - val_loss: 0.3855 - val_accuracy: 0.8485 - lr: 0.0100\n",
            "Epoch 26/100\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3603 - accuracy: 0.8695 - val_loss: 0.3721 - val_accuracy: 0.8587 - lr: 0.0100\n",
            "Epoch 27/100\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3583 - accuracy: 0.8702 - val_loss: 0.3536 - val_accuracy: 0.8684 - lr: 0.0100\n",
            "Epoch 28/100\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3578 - accuracy: 0.8679 - val_loss: 0.4456 - val_accuracy: 0.8249 - lr: 0.0100\n",
            "Epoch 29/100\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3581 - accuracy: 0.8699 - val_loss: 0.3323 - val_accuracy: 0.8763 - lr: 0.0100\n",
            "Epoch 30/100\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3524 - accuracy: 0.8733 - val_loss: 0.3363 - val_accuracy: 0.8741 - lr: 0.0100\n",
            "Epoch 31/100\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3517 - accuracy: 0.8736 - val_loss: 0.4120 - val_accuracy: 0.8382 - lr: 0.0100\n",
            "Epoch 32/100\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3571 - accuracy: 0.8722 - val_loss: 0.3262 - val_accuracy: 0.8815 - lr: 0.0100\n",
            "Epoch 33/100\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3546 - accuracy: 0.8719 - val_loss: 0.3803 - val_accuracy: 0.8512 - lr: 0.0100\n",
            "Epoch 34/100\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3519 - accuracy: 0.8733 - val_loss: 0.4111 - val_accuracy: 0.8370 - lr: 0.0100\n",
            "Epoch 35/100\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3495 - accuracy: 0.8735 - val_loss: 0.6477 - val_accuracy: 0.7274 - lr: 0.0100\n",
            "Epoch 36/100\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3446 - accuracy: 0.8754 - val_loss: 0.4756 - val_accuracy: 0.8092 - lr: 0.0100\n",
            "Epoch 37/100\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3458 - accuracy: 0.8740 - val_loss: 0.3305 - val_accuracy: 0.8741 - lr: 0.0100\n",
            "Epoch 38/100\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3418 - accuracy: 0.8761 - val_loss: 0.3484 - val_accuracy: 0.8698 - lr: 0.0100\n",
            "Epoch 39/100\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3411 - accuracy: 0.8766 - val_loss: 0.3061 - val_accuracy: 0.8863 - lr: 0.0100\n",
            "Epoch 40/100\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3381 - accuracy: 0.8779 - val_loss: 0.3527 - val_accuracy: 0.8689 - lr: 0.0100\n",
            "Epoch 41/100\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3382 - accuracy: 0.8788 - val_loss: 0.3152 - val_accuracy: 0.8841 - lr: 0.0100\n",
            "Epoch 42/100\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3366 - accuracy: 0.8780 - val_loss: 0.3261 - val_accuracy: 0.8773 - lr: 0.0100\n",
            "Epoch 43/100\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3397 - accuracy: 0.8790 - val_loss: 0.3127 - val_accuracy: 0.8844 - lr: 0.0100\n",
            "Epoch 44/100\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3386 - accuracy: 0.8785 - val_loss: 0.4353 - val_accuracy: 0.8211 - lr: 0.0100\n",
            "Epoch 45/100\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3356 - accuracy: 0.8796 - val_loss: 0.3346 - val_accuracy: 0.8752 - lr: 0.0100\n",
            "Epoch 46/100\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3313 - accuracy: 0.8808 - val_loss: 0.3319 - val_accuracy: 0.8742 - lr: 0.0100\n",
            "Epoch 47/100\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3279 - accuracy: 0.8808 - val_loss: 0.3117 - val_accuracy: 0.8830 - lr: 0.0100\n",
            "Epoch 48/100\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3332 - accuracy: 0.8775 - val_loss: 0.3469 - val_accuracy: 0.8676 - lr: 0.0100\n",
            "Epoch 49/100\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3273 - accuracy: 0.8823 - val_loss: 0.4668 - val_accuracy: 0.8376 - lr: 0.0100\n",
            "Epoch 50/100\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3303 - accuracy: 0.8802 - val_loss: 0.3421 - val_accuracy: 0.8673 - lr: 0.0100\n",
            "Epoch 51/100\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3274 - accuracy: 0.8821 - val_loss: 0.2965 - val_accuracy: 0.8919 - lr: 0.0100\n",
            "Epoch 52/100\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3278 - accuracy: 0.8810 - val_loss: 0.4429 - val_accuracy: 0.8209 - lr: 0.0100\n",
            "Epoch 53/100\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3257 - accuracy: 0.8809 - val_loss: 0.3142 - val_accuracy: 0.8809 - lr: 0.0100\n",
            "Epoch 54/100\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3246 - accuracy: 0.8832 - val_loss: 0.3079 - val_accuracy: 0.8856 - lr: 0.0100\n",
            "Epoch 55/100\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3254 - accuracy: 0.8833 - val_loss: 0.2967 - val_accuracy: 0.8861 - lr: 0.0100\n",
            "Epoch 56/100\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3225 - accuracy: 0.8841 - val_loss: 0.3288 - val_accuracy: 0.8758 - lr: 0.0100\n",
            "Epoch 57/100\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3259 - accuracy: 0.8827 - val_loss: 0.3359 - val_accuracy: 0.8770 - lr: 0.0100\n",
            "Epoch 58/100\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3217 - accuracy: 0.8850 - val_loss: 0.4042 - val_accuracy: 0.8580 - lr: 0.0100\n",
            "Epoch 59/100\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3239 - accuracy: 0.8836 - val_loss: 0.3003 - val_accuracy: 0.8890 - lr: 0.0100\n",
            "Epoch 60/100\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3184 - accuracy: 0.8859 - val_loss: 0.3292 - val_accuracy: 0.8783 - lr: 0.0100\n",
            "Epoch 61/100\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3202 - accuracy: 0.8839 - val_loss: 0.3372 - val_accuracy: 0.8801 - lr: 0.0100\n",
            "Epoch 62/100\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3238 - accuracy: 0.8833 - val_loss: 0.2912 - val_accuracy: 0.8915 - lr: 0.0100\n",
            "Epoch 63/100\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3185 - accuracy: 0.8846 - val_loss: 0.3622 - val_accuracy: 0.8614 - lr: 0.0100\n",
            "Epoch 64/100\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3196 - accuracy: 0.8840 - val_loss: 0.3046 - val_accuracy: 0.8870 - lr: 0.0100\n",
            "Epoch 65/100\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3165 - accuracy: 0.8849 - val_loss: 0.3365 - val_accuracy: 0.8726 - lr: 0.0100\n",
            "Epoch 66/100\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3170 - accuracy: 0.8848 - val_loss: 0.3350 - val_accuracy: 0.8820 - lr: 0.0100\n",
            "Epoch 1/100\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.9185 - accuracy: 0.6707 - val_loss: 2.5199 - val_accuracy: 0.1936 - lr: 0.0100\n",
            "Epoch 2/100\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.6188 - accuracy: 0.7722 - val_loss: 3.2956 - val_accuracy: 0.2024 - lr: 0.0100\n",
            "Epoch 3/100\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.5577 - accuracy: 0.7978 - val_loss: 2.2456 - val_accuracy: 0.2805 - lr: 0.0100\n",
            "Epoch 4/100\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.5146 - accuracy: 0.8131 - val_loss: 1.9409 - val_accuracy: 0.3898 - lr: 0.0100\n",
            "Epoch 5/100\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4933 - accuracy: 0.8197 - val_loss: 1.9470 - val_accuracy: 0.2800 - lr: 0.0100\n",
            "Epoch 6/100\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4788 - accuracy: 0.8254 - val_loss: 1.5831 - val_accuracy: 0.4575 - lr: 0.0100\n",
            "Epoch 7/100\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4613 - accuracy: 0.8356 - val_loss: 0.9109 - val_accuracy: 0.6553 - lr: 0.0100\n",
            "Epoch 8/100\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4417 - accuracy: 0.8378 - val_loss: 0.6540 - val_accuracy: 0.7450 - lr: 0.0100\n",
            "Epoch 9/100\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4397 - accuracy: 0.8393 - val_loss: 0.6171 - val_accuracy: 0.7410 - lr: 0.0100\n",
            "Epoch 10/100\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4302 - accuracy: 0.8419 - val_loss: 0.5687 - val_accuracy: 0.7828 - lr: 0.0100\n",
            "Epoch 11/100\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4233 - accuracy: 0.8460 - val_loss: 0.5910 - val_accuracy: 0.7427 - lr: 0.0100\n",
            "Epoch 12/100\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4142 - accuracy: 0.8500 - val_loss: 0.8435 - val_accuracy: 0.6593 - lr: 0.0100\n",
            "Epoch 13/100\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4154 - accuracy: 0.8476 - val_loss: 0.7734 - val_accuracy: 0.6814 - lr: 0.0100\n",
            "Epoch 14/100\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4048 - accuracy: 0.8518 - val_loss: 0.4799 - val_accuracy: 0.8067 - lr: 0.0100\n",
            "Epoch 15/100\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3962 - accuracy: 0.8577 - val_loss: 0.3634 - val_accuracy: 0.8636 - lr: 0.0100\n",
            "Epoch 16/100\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4008 - accuracy: 0.8579 - val_loss: 0.4196 - val_accuracy: 0.8386 - lr: 0.0100\n",
            "Epoch 17/100\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3916 - accuracy: 0.8609 - val_loss: 0.6439 - val_accuracy: 0.7391 - lr: 0.0100\n",
            "Epoch 18/100\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3902 - accuracy: 0.8577 - val_loss: 0.4025 - val_accuracy: 0.8455 - lr: 0.0100\n",
            "Epoch 19/100\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3837 - accuracy: 0.8624 - val_loss: 0.3957 - val_accuracy: 0.8453 - lr: 0.0100\n",
            "Epoch 20/100\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3808 - accuracy: 0.8618 - val_loss: 0.4915 - val_accuracy: 0.8125 - lr: 0.0100\n",
            "Epoch 21/100\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3787 - accuracy: 0.8618 - val_loss: 0.6111 - val_accuracy: 0.7436 - lr: 0.0100\n",
            "Epoch 22/100\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3778 - accuracy: 0.8628 - val_loss: 0.8658 - val_accuracy: 0.6727 - lr: 0.0100\n",
            "Epoch 23/100\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3769 - accuracy: 0.8639 - val_loss: 0.6922 - val_accuracy: 0.7327 - lr: 0.0100\n",
            "Epoch 24/100\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3669 - accuracy: 0.8677 - val_loss: 0.3623 - val_accuracy: 0.8612 - lr: 0.0100\n",
            "Epoch 25/100\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3636 - accuracy: 0.8687 - val_loss: 0.3327 - val_accuracy: 0.8736 - lr: 0.0100\n",
            "Epoch 26/100\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3611 - accuracy: 0.8693 - val_loss: 0.4215 - val_accuracy: 0.8290 - lr: 0.0100\n",
            "Epoch 27/100\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3658 - accuracy: 0.8675 - val_loss: 0.3401 - val_accuracy: 0.8695 - lr: 0.0100\n",
            "Epoch 28/100\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3592 - accuracy: 0.8671 - val_loss: 0.3534 - val_accuracy: 0.8622 - lr: 0.0100\n",
            "Epoch 29/100\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3597 - accuracy: 0.8697 - val_loss: 0.3560 - val_accuracy: 0.8665 - lr: 0.0100\n",
            "Epoch 30/100\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3547 - accuracy: 0.8712 - val_loss: 0.4254 - val_accuracy: 0.8388 - lr: 0.0100\n",
            "Epoch 31/100\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3544 - accuracy: 0.8707 - val_loss: 0.4595 - val_accuracy: 0.8165 - lr: 0.0100\n",
            "Epoch 32/100\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3576 - accuracy: 0.8705 - val_loss: 0.4604 - val_accuracy: 0.8101 - lr: 0.0100\n",
            "Epoch 33/100\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3502 - accuracy: 0.8740 - val_loss: 0.3492 - val_accuracy: 0.8660 - lr: 0.0100\n",
            "Epoch 34/100\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3515 - accuracy: 0.8737 - val_loss: 0.3933 - val_accuracy: 0.8485 - lr: 0.0100\n",
            "Epoch 35/100\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3484 - accuracy: 0.8731 - val_loss: 0.3798 - val_accuracy: 0.8490 - lr: 0.0100\n",
            "Epoch 36/100\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3457 - accuracy: 0.8734 - val_loss: 0.3414 - val_accuracy: 0.8666 - lr: 0.0100\n",
            "Epoch 37/100\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3422 - accuracy: 0.8786 - val_loss: 0.3408 - val_accuracy: 0.8721 - lr: 0.0100\n",
            "Epoch 38/100\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3479 - accuracy: 0.8744 - val_loss: 0.4776 - val_accuracy: 0.8076 - lr: 0.0100\n",
            "Epoch 39/100\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3432 - accuracy: 0.8758 - val_loss: 0.4280 - val_accuracy: 0.8378 - lr: 0.0100\n",
            "Epoch 40/100\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3427 - accuracy: 0.8752 - val_loss: 0.3931 - val_accuracy: 0.8516 - lr: 0.0100\n",
            "Epoch 1/100\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.9300 - accuracy: 0.6628 - val_loss: 2.6614 - val_accuracy: 0.1273 - lr: 0.0100\n",
            "Epoch 2/100\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.6198 - accuracy: 0.7720 - val_loss: 2.4374 - val_accuracy: 0.2344 - lr: 0.0100\n",
            "Epoch 3/100\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.5486 - accuracy: 0.8025 - val_loss: 1.8132 - val_accuracy: 0.4619 - lr: 0.0100\n",
            "Epoch 4/100\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.5172 - accuracy: 0.8128 - val_loss: 1.8848 - val_accuracy: 0.4000 - lr: 0.0100\n",
            "Epoch 5/100\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4846 - accuracy: 0.8247 - val_loss: 2.1690 - val_accuracy: 0.3709 - lr: 0.0100\n",
            "Epoch 6/100\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4682 - accuracy: 0.8296 - val_loss: 1.5473 - val_accuracy: 0.4626 - lr: 0.0100\n",
            "Epoch 7/100\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4559 - accuracy: 0.8341 - val_loss: 1.0318 - val_accuracy: 0.6120 - lr: 0.0100\n",
            "Epoch 8/100\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4417 - accuracy: 0.8414 - val_loss: 0.7351 - val_accuracy: 0.7498 - lr: 0.0100\n",
            "Epoch 9/100\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4354 - accuracy: 0.8422 - val_loss: 0.8041 - val_accuracy: 0.6783 - lr: 0.0100\n",
            "Epoch 10/100\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4221 - accuracy: 0.8472 - val_loss: 0.5568 - val_accuracy: 0.7753 - lr: 0.0100\n",
            "Epoch 11/100\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4209 - accuracy: 0.8470 - val_loss: 0.5802 - val_accuracy: 0.7776 - lr: 0.0100\n",
            "Epoch 12/100\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4120 - accuracy: 0.8526 - val_loss: 0.6113 - val_accuracy: 0.7531 - lr: 0.0100\n",
            "Epoch 13/100\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4071 - accuracy: 0.8531 - val_loss: 0.4228 - val_accuracy: 0.8444 - lr: 0.0100\n",
            "Epoch 14/100\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4005 - accuracy: 0.8543 - val_loss: 0.5425 - val_accuracy: 0.7850 - lr: 0.0100\n",
            "Epoch 15/100\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3961 - accuracy: 0.8568 - val_loss: 0.5993 - val_accuracy: 0.7434 - lr: 0.0100\n",
            "Epoch 16/100\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3883 - accuracy: 0.8593 - val_loss: 0.4404 - val_accuracy: 0.8225 - lr: 0.0100\n",
            "Epoch 17/100\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3870 - accuracy: 0.8596 - val_loss: 0.4753 - val_accuracy: 0.8073 - lr: 0.0100\n",
            "Epoch 18/100\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3863 - accuracy: 0.8592 - val_loss: 0.4227 - val_accuracy: 0.8372 - lr: 0.0100\n",
            "Epoch 19/100\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3784 - accuracy: 0.8645 - val_loss: 0.4711 - val_accuracy: 0.8180 - lr: 0.0100\n",
            "Epoch 20/100\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3823 - accuracy: 0.8603 - val_loss: 0.4700 - val_accuracy: 0.8099 - lr: 0.0100\n",
            "Epoch 21/100\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3784 - accuracy: 0.8622 - val_loss: 0.4332 - val_accuracy: 0.8186 - lr: 0.0100\n",
            "Epoch 22/100\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3727 - accuracy: 0.8668 - val_loss: 0.3344 - val_accuracy: 0.8737 - lr: 0.0100\n",
            "Epoch 23/100\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3681 - accuracy: 0.8660 - val_loss: 0.4026 - val_accuracy: 0.8464 - lr: 0.0100\n",
            "Epoch 24/100\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3682 - accuracy: 0.8667 - val_loss: 0.3751 - val_accuracy: 0.8556 - lr: 0.0100\n",
            "Epoch 25/100\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3711 - accuracy: 0.8671 - val_loss: 0.3223 - val_accuracy: 0.8838 - lr: 0.0100\n",
            "Epoch 26/100\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3571 - accuracy: 0.8715 - val_loss: 0.3541 - val_accuracy: 0.8727 - lr: 0.0100\n",
            "Epoch 27/100\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3634 - accuracy: 0.8661 - val_loss: 0.3387 - val_accuracy: 0.8687 - lr: 0.0100\n",
            "Epoch 28/100\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3626 - accuracy: 0.8703 - val_loss: 0.3701 - val_accuracy: 0.8558 - lr: 0.0100\n",
            "Epoch 29/100\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3560 - accuracy: 0.8734 - val_loss: 0.4619 - val_accuracy: 0.8040 - lr: 0.0100\n",
            "Epoch 30/100\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3566 - accuracy: 0.8707 - val_loss: 0.3646 - val_accuracy: 0.8556 - lr: 0.0100\n",
            "Epoch 31/100\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3477 - accuracy: 0.8730 - val_loss: 0.3337 - val_accuracy: 0.8736 - lr: 0.0100\n",
            "Epoch 32/100\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3509 - accuracy: 0.8734 - val_loss: 0.5970 - val_accuracy: 0.7529 - lr: 0.0100\n",
            "Epoch 33/100\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3472 - accuracy: 0.8726 - val_loss: 0.3438 - val_accuracy: 0.8746 - lr: 0.0100\n",
            "Epoch 34/100\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3480 - accuracy: 0.8726 - val_loss: 0.4120 - val_accuracy: 0.8382 - lr: 0.0100\n",
            "Epoch 35/100\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3505 - accuracy: 0.8718 - val_loss: 0.4774 - val_accuracy: 0.8158 - lr: 0.0100\n",
            "Epoch 36/100\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3454 - accuracy: 0.8727 - val_loss: 0.3710 - val_accuracy: 0.8595 - lr: 0.0100\n",
            "Epoch 37/100\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3470 - accuracy: 0.8744 - val_loss: 0.3141 - val_accuracy: 0.8786 - lr: 0.0100\n",
            "Epoch 38/100\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3424 - accuracy: 0.8753 - val_loss: 0.3884 - val_accuracy: 0.8534 - lr: 0.0100\n",
            "Epoch 39/100\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3413 - accuracy: 0.8764 - val_loss: 0.3162 - val_accuracy: 0.8829 - lr: 0.0100\n",
            "Epoch 40/100\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3403 - accuracy: 0.8755 - val_loss: 0.3249 - val_accuracy: 0.8795 - lr: 0.0100\n",
            "Epoch 1/100\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.9401 - accuracy: 0.6612 - val_loss: 3.0594 - val_accuracy: 0.1064 - lr: 0.0100\n",
            "Epoch 2/100\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.6562 - accuracy: 0.7558 - val_loss: 3.5627 - val_accuracy: 0.1330 - lr: 0.0100\n",
            "Epoch 3/100\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.5865 - accuracy: 0.7855 - val_loss: 3.1136 - val_accuracy: 0.1001 - lr: 0.0100\n",
            "Epoch 4/100\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.5401 - accuracy: 0.8045 - val_loss: 3.6352 - val_accuracy: 0.1346 - lr: 0.0100\n",
            "Epoch 5/100\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.5081 - accuracy: 0.8191 - val_loss: 2.3725 - val_accuracy: 0.2214 - lr: 0.0100\n",
            "Epoch 6/100\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4857 - accuracy: 0.8264 - val_loss: 2.3818 - val_accuracy: 0.3494 - lr: 0.0100\n",
            "Epoch 7/100\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4681 - accuracy: 0.8324 - val_loss: 2.2845 - val_accuracy: 0.2812 - lr: 0.0100\n",
            "Epoch 8/100\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4543 - accuracy: 0.8361 - val_loss: 1.7698 - val_accuracy: 0.4081 - lr: 0.0100\n",
            "Epoch 9/100\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4418 - accuracy: 0.8418 - val_loss: 1.5238 - val_accuracy: 0.4699 - lr: 0.0100\n",
            "Epoch 10/100\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4323 - accuracy: 0.8447 - val_loss: 1.0680 - val_accuracy: 0.5875 - lr: 0.0100\n",
            "Epoch 11/100\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4289 - accuracy: 0.8474 - val_loss: 1.1852 - val_accuracy: 0.5595 - lr: 0.0100\n",
            "Epoch 12/100\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4166 - accuracy: 0.8518 - val_loss: 1.1659 - val_accuracy: 0.5854 - lr: 0.0100\n",
            "Epoch 13/100\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4139 - accuracy: 0.8524 - val_loss: 1.0198 - val_accuracy: 0.6391 - lr: 0.0100\n",
            "Epoch 14/100\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4045 - accuracy: 0.8562 - val_loss: 0.9031 - val_accuracy: 0.6650 - lr: 0.0100\n",
            "Epoch 15/100\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4038 - accuracy: 0.8534 - val_loss: 0.6726 - val_accuracy: 0.7301 - lr: 0.0100\n",
            "Epoch 16/100\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3952 - accuracy: 0.8579 - val_loss: 0.5524 - val_accuracy: 0.7844 - lr: 0.0100\n",
            "Epoch 17/100\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3924 - accuracy: 0.8595 - val_loss: 0.6912 - val_accuracy: 0.7299 - lr: 0.0100\n",
            "Epoch 18/100\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3864 - accuracy: 0.8593 - val_loss: 0.6149 - val_accuracy: 0.7659 - lr: 0.0100\n",
            "Epoch 19/100\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3823 - accuracy: 0.8619 - val_loss: 0.8649 - val_accuracy: 0.6655 - lr: 0.0100\n",
            "Epoch 20/100\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3812 - accuracy: 0.8626 - val_loss: 0.7302 - val_accuracy: 0.7301 - lr: 0.0100\n",
            "Epoch 21/100\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3797 - accuracy: 0.8619 - val_loss: 0.6059 - val_accuracy: 0.7697 - lr: 0.0100\n",
            "Epoch 22/100\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3721 - accuracy: 0.8660 - val_loss: 0.6098 - val_accuracy: 0.7539 - lr: 0.0100\n",
            "Epoch 23/100\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3753 - accuracy: 0.8654 - val_loss: 0.7694 - val_accuracy: 0.7072 - lr: 0.0100\n",
            "Epoch 24/100\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3697 - accuracy: 0.8666 - val_loss: 0.5694 - val_accuracy: 0.7878 - lr: 0.0100\n",
            "Epoch 25/100\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3628 - accuracy: 0.8679 - val_loss: 0.5073 - val_accuracy: 0.7997 - lr: 0.0100\n",
            "Epoch 26/100\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3623 - accuracy: 0.8695 - val_loss: 0.5964 - val_accuracy: 0.7605 - lr: 0.0100\n",
            "Epoch 27/100\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3610 - accuracy: 0.8718 - val_loss: 0.7058 - val_accuracy: 0.7473 - lr: 0.0100\n",
            "Epoch 28/100\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3596 - accuracy: 0.8678 - val_loss: 0.5116 - val_accuracy: 0.7960 - lr: 0.0100\n",
            "Epoch 29/100\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3608 - accuracy: 0.8681 - val_loss: 0.6317 - val_accuracy: 0.7536 - lr: 0.0100\n",
            "Epoch 30/100\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3534 - accuracy: 0.8731 - val_loss: 0.5440 - val_accuracy: 0.7972 - lr: 0.0100\n",
            "Epoch 31/100\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3523 - accuracy: 0.8734 - val_loss: 0.3598 - val_accuracy: 0.8621 - lr: 0.0100\n",
            "Epoch 32/100\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3530 - accuracy: 0.8741 - val_loss: 0.5003 - val_accuracy: 0.7945 - lr: 0.0100\n",
            "Epoch 33/100\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3525 - accuracy: 0.8734 - val_loss: 0.5734 - val_accuracy: 0.7789 - lr: 0.0100\n",
            "Epoch 34/100\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3476 - accuracy: 0.8730 - val_loss: 0.5749 - val_accuracy: 0.7832 - lr: 0.0100\n",
            "Epoch 35/100\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3517 - accuracy: 0.8723 - val_loss: 0.4651 - val_accuracy: 0.8185 - lr: 0.0100\n",
            "Epoch 36/100\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3491 - accuracy: 0.8739 - val_loss: 0.3690 - val_accuracy: 0.8596 - lr: 0.0100\n",
            "Epoch 37/100\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3403 - accuracy: 0.8772 - val_loss: 0.5033 - val_accuracy: 0.7986 - lr: 0.0100\n",
            "Epoch 38/100\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3493 - accuracy: 0.8723 - val_loss: 0.3521 - val_accuracy: 0.8685 - lr: 0.0100\n",
            "Epoch 39/100\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3413 - accuracy: 0.8773 - val_loss: 0.4605 - val_accuracy: 0.8104 - lr: 0.0100\n",
            "Epoch 40/100\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3399 - accuracy: 0.8796 - val_loss: 0.4413 - val_accuracy: 0.8363 - lr: 0.0100\n",
            "Epoch 41/100\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3420 - accuracy: 0.8769 - val_loss: 0.3973 - val_accuracy: 0.8410 - lr: 0.0100\n",
            "Epoch 42/100\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3343 - accuracy: 0.8788 - val_loss: 0.4530 - val_accuracy: 0.8249 - lr: 0.0100\n",
            "Epoch 43/100\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3394 - accuracy: 0.8788 - val_loss: 0.4454 - val_accuracy: 0.8276 - lr: 0.0100\n",
            "Epoch 44/100\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3304 - accuracy: 0.8808 - val_loss: 0.4186 - val_accuracy: 0.8394 - lr: 0.0100\n",
            "Epoch 45/100\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3340 - accuracy: 0.8797 - val_loss: 0.4023 - val_accuracy: 0.8479 - lr: 0.0100\n",
            "Epoch 46/100\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3302 - accuracy: 0.8801 - val_loss: 0.3867 - val_accuracy: 0.8554 - lr: 0.0100\n",
            "Epoch 47/100\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3327 - accuracy: 0.8813 - val_loss: 0.4062 - val_accuracy: 0.8406 - lr: 0.0100\n",
            "Epoch 48/100\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3363 - accuracy: 0.8788 - val_loss: 0.4259 - val_accuracy: 0.8369 - lr: 0.0100\n",
            "Epoch 49/100\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3306 - accuracy: 0.8796 - val_loss: 0.3490 - val_accuracy: 0.8687 - lr: 0.0100\n",
            "Epoch 50/100\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3357 - accuracy: 0.8775 - val_loss: 0.3853 - val_accuracy: 0.8525 - lr: 0.0100\n",
            "Epoch 51/100\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3249 - accuracy: 0.8830 - val_loss: 0.4508 - val_accuracy: 0.8163 - lr: 0.0100\n",
            "Epoch 52/100\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3287 - accuracy: 0.8803 - val_loss: 0.3914 - val_accuracy: 0.8520 - lr: 0.0100\n",
            "Epoch 53/100\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3265 - accuracy: 0.8821 - val_loss: 0.3929 - val_accuracy: 0.8447 - lr: 0.0100\n",
            "Epoch 54/100\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3255 - accuracy: 0.8815 - val_loss: 0.3445 - val_accuracy: 0.8699 - lr: 0.0100\n",
            "Epoch 55/100\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3250 - accuracy: 0.8831 - val_loss: 0.3241 - val_accuracy: 0.8831 - lr: 0.0100\n",
            "Epoch 56/100\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3207 - accuracy: 0.8822 - val_loss: 0.4119 - val_accuracy: 0.8410 - lr: 0.0100\n",
            "Epoch 57/100\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3181 - accuracy: 0.8845 - val_loss: 0.3523 - val_accuracy: 0.8714 - lr: 0.0100\n",
            "Epoch 58/100\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3254 - accuracy: 0.8828 - val_loss: 0.2904 - val_accuracy: 0.8953 - lr: 0.0100\n",
            "Epoch 59/100\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3215 - accuracy: 0.8838 - val_loss: 0.3518 - val_accuracy: 0.8674 - lr: 0.0100\n",
            "Epoch 60/100\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3206 - accuracy: 0.8846 - val_loss: 0.2819 - val_accuracy: 0.8950 - lr: 0.0100\n",
            "Epoch 61/100\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3195 - accuracy: 0.8839 - val_loss: 0.3193 - val_accuracy: 0.8836 - lr: 0.0100\n",
            "Epoch 62/100\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3206 - accuracy: 0.8847 - val_loss: 0.3572 - val_accuracy: 0.8730 - lr: 0.0100\n",
            "Epoch 63/100\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3172 - accuracy: 0.8852 - val_loss: 0.2806 - val_accuracy: 0.8970 - lr: 0.0100\n",
            "Epoch 64/100\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3172 - accuracy: 0.8857 - val_loss: 0.3704 - val_accuracy: 0.8611 - lr: 0.0100\n",
            "Epoch 65/100\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3180 - accuracy: 0.8864 - val_loss: 0.3229 - val_accuracy: 0.8804 - lr: 0.0100\n",
            "Epoch 66/100\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3142 - accuracy: 0.8876 - val_loss: 0.3158 - val_accuracy: 0.8804 - lr: 0.0100\n",
            "Epoch 67/100\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3165 - accuracy: 0.8853 - val_loss: 0.2935 - val_accuracy: 0.8935 - lr: 0.0100\n",
            "Epoch 68/100\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3122 - accuracy: 0.8865 - val_loss: 0.2971 - val_accuracy: 0.8900 - lr: 0.0100\n",
            "Epoch 69/100\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3087 - accuracy: 0.8893 - val_loss: 0.3402 - val_accuracy: 0.8712 - lr: 0.0100\n",
            "Epoch 70/100\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3151 - accuracy: 0.8858 - val_loss: 0.3073 - val_accuracy: 0.8863 - lr: 0.0100\n",
            "Epoch 71/100\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3149 - accuracy: 0.8860 - val_loss: 0.3120 - val_accuracy: 0.8823 - lr: 0.0100\n",
            "Epoch 72/100\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3115 - accuracy: 0.8880 - val_loss: 0.3584 - val_accuracy: 0.8633 - lr: 0.0100\n",
            "Epoch 73/100\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3127 - accuracy: 0.8870 - val_loss: 0.4401 - val_accuracy: 0.8281 - lr: 0.0100\n",
            "Epoch 74/100\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3037 - accuracy: 0.8894 - val_loss: 0.3450 - val_accuracy: 0.8724 - lr: 0.0100\n",
            "Epoch 75/100\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3123 - accuracy: 0.8867 - val_loss: 0.4049 - val_accuracy: 0.8425 - lr: 0.0100\n",
            "Epoch 76/100\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3088 - accuracy: 0.8891 - val_loss: 0.3000 - val_accuracy: 0.8894 - lr: 0.0100\n",
            "Epoch 77/100\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3135 - accuracy: 0.8857 - val_loss: 0.2907 - val_accuracy: 0.8964 - lr: 0.0100\n",
            "Epoch 78/100\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3068 - accuracy: 0.8898 - val_loss: 0.2999 - val_accuracy: 0.8909 - lr: 0.0100\n",
            "Epoch 1/100\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.9128 - accuracy: 0.6690 - val_loss: 3.1385 - val_accuracy: 0.0980 - lr: 0.0100\n",
            "Epoch 2/100\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.6219 - accuracy: 0.7697 - val_loss: 2.9000 - val_accuracy: 0.0984 - lr: 0.0100\n",
            "Epoch 3/100\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.5611 - accuracy: 0.7978 - val_loss: 2.3471 - val_accuracy: 0.1482 - lr: 0.0100\n",
            "Epoch 4/100\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.5170 - accuracy: 0.8113 - val_loss: 2.1124 - val_accuracy: 0.2294 - lr: 0.0100\n",
            "Epoch 5/100\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4930 - accuracy: 0.8234 - val_loss: 1.5939 - val_accuracy: 0.5415 - lr: 0.0100\n",
            "Epoch 6/100\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4719 - accuracy: 0.8290 - val_loss: 1.5806 - val_accuracy: 0.4409 - lr: 0.0100\n",
            "Epoch 7/100\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4545 - accuracy: 0.8343 - val_loss: 1.0625 - val_accuracy: 0.6152 - lr: 0.0100\n",
            "Epoch 8/100\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4485 - accuracy: 0.8386 - val_loss: 1.0444 - val_accuracy: 0.5957 - lr: 0.0100\n",
            "Epoch 9/100\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4388 - accuracy: 0.8421 - val_loss: 1.0453 - val_accuracy: 0.6183 - lr: 0.0100\n",
            "Epoch 10/100\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4264 - accuracy: 0.8450 - val_loss: 0.5751 - val_accuracy: 0.7699 - lr: 0.0100\n",
            "Epoch 11/100\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4124 - accuracy: 0.8502 - val_loss: 0.6121 - val_accuracy: 0.7625 - lr: 0.0100\n",
            "Epoch 12/100\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4124 - accuracy: 0.8515 - val_loss: 0.7373 - val_accuracy: 0.7090 - lr: 0.0100\n",
            "Epoch 13/100\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4046 - accuracy: 0.8523 - val_loss: 0.6939 - val_accuracy: 0.7311 - lr: 0.0100\n",
            "Epoch 14/100\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4031 - accuracy: 0.8551 - val_loss: 0.5465 - val_accuracy: 0.7768 - lr: 0.0100\n",
            "Epoch 15/100\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3909 - accuracy: 0.8610 - val_loss: 0.6147 - val_accuracy: 0.7484 - lr: 0.0100\n",
            "Epoch 16/100\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3922 - accuracy: 0.8565 - val_loss: 0.5003 - val_accuracy: 0.7974 - lr: 0.0100\n",
            "Epoch 17/100\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3870 - accuracy: 0.8602 - val_loss: 0.6321 - val_accuracy: 0.7474 - lr: 0.0100\n",
            "Epoch 18/100\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3792 - accuracy: 0.8639 - val_loss: 0.6367 - val_accuracy: 0.7523 - lr: 0.0100\n",
            "Epoch 19/100\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3815 - accuracy: 0.8625 - val_loss: 0.6262 - val_accuracy: 0.7370 - lr: 0.0100\n",
            "Epoch 20/100\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3795 - accuracy: 0.8621 - val_loss: 0.5235 - val_accuracy: 0.7890 - lr: 0.0100\n",
            "Epoch 21/100\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3692 - accuracy: 0.8662 - val_loss: 0.6795 - val_accuracy: 0.7426 - lr: 0.0100\n",
            "Epoch 22/100\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3674 - accuracy: 0.8670 - val_loss: 0.6667 - val_accuracy: 0.7431 - lr: 0.0100\n",
            "Epoch 23/100\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3694 - accuracy: 0.8654 - val_loss: 0.7294 - val_accuracy: 0.7255 - lr: 0.0100\n",
            "Epoch 24/100\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3697 - accuracy: 0.8668 - val_loss: 0.6705 - val_accuracy: 0.7400 - lr: 0.0100\n",
            "Epoch 25/100\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3607 - accuracy: 0.8694 - val_loss: 0.5527 - val_accuracy: 0.7780 - lr: 0.0100\n",
            "Epoch 26/100\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3600 - accuracy: 0.8697 - val_loss: 0.6182 - val_accuracy: 0.7550 - lr: 0.0100\n",
            "Epoch 27/100\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3621 - accuracy: 0.8686 - val_loss: 0.4350 - val_accuracy: 0.8210 - lr: 0.0100\n",
            "Epoch 28/100\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3518 - accuracy: 0.8732 - val_loss: 0.6408 - val_accuracy: 0.7632 - lr: 0.0100\n",
            "Epoch 29/100\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3553 - accuracy: 0.8716 - val_loss: 0.4186 - val_accuracy: 0.8314 - lr: 0.0100\n",
            "Epoch 30/100\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3485 - accuracy: 0.8736 - val_loss: 0.4360 - val_accuracy: 0.8285 - lr: 0.0100\n",
            "Epoch 31/100\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3478 - accuracy: 0.8736 - val_loss: 0.3335 - val_accuracy: 0.8692 - lr: 0.0100\n",
            "Epoch 32/100\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3519 - accuracy: 0.8704 - val_loss: 0.5781 - val_accuracy: 0.7830 - lr: 0.0100\n",
            "Epoch 33/100\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3480 - accuracy: 0.8747 - val_loss: 0.5740 - val_accuracy: 0.7724 - lr: 0.0100\n",
            "Epoch 34/100\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3465 - accuracy: 0.8739 - val_loss: 0.5041 - val_accuracy: 0.7936 - lr: 0.0100\n",
            "Epoch 35/100\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3471 - accuracy: 0.8726 - val_loss: 0.5478 - val_accuracy: 0.7843 - lr: 0.0100\n",
            "Epoch 36/100\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3404 - accuracy: 0.8769 - val_loss: 0.5380 - val_accuracy: 0.7845 - lr: 0.0100\n",
            "Epoch 37/100\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3425 - accuracy: 0.8760 - val_loss: 0.4733 - val_accuracy: 0.8030 - lr: 0.0100\n",
            "Epoch 38/100\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3388 - accuracy: 0.8783 - val_loss: 0.4566 - val_accuracy: 0.8191 - lr: 0.0100\n",
            "Epoch 39/100\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3414 - accuracy: 0.8762 - val_loss: 0.4938 - val_accuracy: 0.8015 - lr: 0.0100\n",
            "Epoch 40/100\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3375 - accuracy: 0.8770 - val_loss: 0.4981 - val_accuracy: 0.8070 - lr: 0.0100\n",
            "Epoch 41/100\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3323 - accuracy: 0.8798 - val_loss: 0.3754 - val_accuracy: 0.8530 - lr: 0.0100\n",
            "Epoch 42/100\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3317 - accuracy: 0.8799 - val_loss: 0.3459 - val_accuracy: 0.8661 - lr: 0.0100\n",
            "Epoch 43/100\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3332 - accuracy: 0.8801 - val_loss: 0.4861 - val_accuracy: 0.8055 - lr: 0.0100\n",
            "Epoch 44/100\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3315 - accuracy: 0.8786 - val_loss: 0.4714 - val_accuracy: 0.8161 - lr: 0.0100\n",
            "Epoch 45/100\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3299 - accuracy: 0.8798 - val_loss: 0.4572 - val_accuracy: 0.8159 - lr: 0.0100\n",
            "Epoch 46/100\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3330 - accuracy: 0.8797 - val_loss: 0.4278 - val_accuracy: 0.8305 - lr: 0.0100\n",
            "Epoch 1/100\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.9320 - accuracy: 0.6641 - val_loss: 2.7883 - val_accuracy: 0.1705 - lr: 0.0100\n",
            "Epoch 2/100\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.6331 - accuracy: 0.7656 - val_loss: 3.0349 - val_accuracy: 0.1101 - lr: 0.0100\n",
            "Epoch 3/100\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.5595 - accuracy: 0.7996 - val_loss: 3.0387 - val_accuracy: 0.1279 - lr: 0.0100\n",
            "Epoch 4/100\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.5182 - accuracy: 0.8119 - val_loss: 2.9289 - val_accuracy: 0.1780 - lr: 0.0100\n",
            "Epoch 5/100\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4975 - accuracy: 0.8235 - val_loss: 2.0623 - val_accuracy: 0.3749 - lr: 0.0100\n",
            "Epoch 6/100\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4710 - accuracy: 0.8317 - val_loss: 2.0314 - val_accuracy: 0.3359 - lr: 0.0100\n",
            "Epoch 7/100\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4567 - accuracy: 0.8374 - val_loss: 1.6335 - val_accuracy: 0.5565 - lr: 0.0100\n",
            "Epoch 8/100\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4423 - accuracy: 0.8410 - val_loss: 1.1503 - val_accuracy: 0.6019 - lr: 0.0100\n",
            "Epoch 9/100\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4375 - accuracy: 0.8428 - val_loss: 1.5517 - val_accuracy: 0.4933 - lr: 0.0100\n",
            "Epoch 10/100\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4275 - accuracy: 0.8484 - val_loss: 1.1054 - val_accuracy: 0.6000 - lr: 0.0100\n",
            "Epoch 11/100\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4222 - accuracy: 0.8494 - val_loss: 0.8871 - val_accuracy: 0.6556 - lr: 0.0100\n",
            "Epoch 12/100\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4090 - accuracy: 0.8500 - val_loss: 0.8698 - val_accuracy: 0.6890 - lr: 0.0100\n",
            "Epoch 13/100\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4071 - accuracy: 0.8524 - val_loss: 0.7220 - val_accuracy: 0.7080 - lr: 0.0100\n",
            "Epoch 14/100\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3961 - accuracy: 0.8562 - val_loss: 1.0880 - val_accuracy: 0.5617 - lr: 0.0100\n",
            "Epoch 15/100\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3890 - accuracy: 0.8593 - val_loss: 1.0449 - val_accuracy: 0.6046 - lr: 0.0100\n",
            "Epoch 16/100\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3941 - accuracy: 0.8579 - val_loss: 0.9557 - val_accuracy: 0.6174 - lr: 0.0100\n",
            "Epoch 17/100\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3893 - accuracy: 0.8589 - val_loss: 0.5855 - val_accuracy: 0.7639 - lr: 0.0100\n",
            "Epoch 18/100\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3830 - accuracy: 0.8626 - val_loss: 0.7076 - val_accuracy: 0.7308 - lr: 0.0100\n",
            "Epoch 19/100\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3764 - accuracy: 0.8660 - val_loss: 0.9888 - val_accuracy: 0.6217 - lr: 0.0100\n",
            "Epoch 20/100\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3795 - accuracy: 0.8634 - val_loss: 0.5732 - val_accuracy: 0.7625 - lr: 0.0100\n",
            "Epoch 21/100\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3728 - accuracy: 0.8648 - val_loss: 0.4214 - val_accuracy: 0.8325 - lr: 0.0100\n",
            "Epoch 22/100\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3712 - accuracy: 0.8620 - val_loss: 0.6450 - val_accuracy: 0.7434 - lr: 0.0100\n",
            "Epoch 23/100\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3718 - accuracy: 0.8661 - val_loss: 0.4511 - val_accuracy: 0.8284 - lr: 0.0100\n",
            "Epoch 24/100\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3645 - accuracy: 0.8698 - val_loss: 0.4543 - val_accuracy: 0.8189 - lr: 0.0100\n",
            "Epoch 25/100\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3687 - accuracy: 0.8673 - val_loss: 0.5544 - val_accuracy: 0.7709 - lr: 0.0100\n",
            "Epoch 26/100\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3603 - accuracy: 0.8684 - val_loss: 0.5509 - val_accuracy: 0.7724 - lr: 0.0100\n",
            "Epoch 27/100\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3590 - accuracy: 0.8697 - val_loss: 0.6044 - val_accuracy: 0.7629 - lr: 0.0100\n",
            "Epoch 28/100\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3565 - accuracy: 0.8717 - val_loss: 0.5522 - val_accuracy: 0.7814 - lr: 0.0100\n",
            "Epoch 29/100\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3551 - accuracy: 0.8727 - val_loss: 0.5101 - val_accuracy: 0.8016 - lr: 0.0100\n",
            "Epoch 30/100\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3528 - accuracy: 0.8722 - val_loss: 0.5188 - val_accuracy: 0.8000 - lr: 0.0100\n",
            "Epoch 31/100\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3493 - accuracy: 0.8734 - val_loss: 0.3643 - val_accuracy: 0.8602 - lr: 0.0100\n",
            "Epoch 32/100\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3436 - accuracy: 0.8749 - val_loss: 0.5668 - val_accuracy: 0.7788 - lr: 0.0100\n",
            "Epoch 33/100\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3469 - accuracy: 0.8753 - val_loss: 0.4332 - val_accuracy: 0.8304 - lr: 0.0100\n",
            "Epoch 34/100\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3444 - accuracy: 0.8763 - val_loss: 0.5047 - val_accuracy: 0.7925 - lr: 0.0100\n",
            "Epoch 35/100\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3471 - accuracy: 0.8749 - val_loss: 0.4956 - val_accuracy: 0.7986 - lr: 0.0100\n",
            "Epoch 36/100\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3392 - accuracy: 0.8765 - val_loss: 0.4170 - val_accuracy: 0.8380 - lr: 0.0100\n",
            "Epoch 37/100\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3410 - accuracy: 0.8754 - val_loss: 0.4209 - val_accuracy: 0.8364 - lr: 0.0100\n",
            "Epoch 38/100\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3370 - accuracy: 0.8781 - val_loss: 0.3926 - val_accuracy: 0.8489 - lr: 0.0100\n",
            "Epoch 39/100\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3333 - accuracy: 0.8774 - val_loss: 0.4880 - val_accuracy: 0.8076 - lr: 0.0100\n",
            "Epoch 40/100\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3441 - accuracy: 0.8769 - val_loss: 0.2922 - val_accuracy: 0.8924 - lr: 0.0100\n",
            "Epoch 41/100\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3436 - accuracy: 0.8732 - val_loss: 0.4514 - val_accuracy: 0.8191 - lr: 0.0100\n",
            "Epoch 42/100\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3325 - accuracy: 0.8808 - val_loss: 0.4543 - val_accuracy: 0.8169 - lr: 0.0100\n",
            "Epoch 43/100\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3379 - accuracy: 0.8771 - val_loss: 0.4012 - val_accuracy: 0.8481 - lr: 0.0100\n",
            "Epoch 44/100\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3359 - accuracy: 0.8781 - val_loss: 0.3682 - val_accuracy: 0.8621 - lr: 0.0100\n",
            "Epoch 45/100\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3282 - accuracy: 0.8806 - val_loss: 0.2938 - val_accuracy: 0.8899 - lr: 0.0100\n",
            "Epoch 46/100\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3335 - accuracy: 0.8782 - val_loss: 0.3854 - val_accuracy: 0.8516 - lr: 0.0100\n",
            "Epoch 47/100\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3281 - accuracy: 0.8826 - val_loss: 0.3304 - val_accuracy: 0.8715 - lr: 0.0100\n",
            "Epoch 48/100\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3295 - accuracy: 0.8811 - val_loss: 0.3233 - val_accuracy: 0.8765 - lr: 0.0100\n",
            "Epoch 49/100\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3272 - accuracy: 0.8813 - val_loss: 0.2886 - val_accuracy: 0.8926 - lr: 0.0100\n",
            "Epoch 50/100\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3321 - accuracy: 0.8796 - val_loss: 0.3174 - val_accuracy: 0.8815 - lr: 0.0100\n",
            "Epoch 51/100\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3279 - accuracy: 0.8823 - val_loss: 0.5189 - val_accuracy: 0.8030 - lr: 0.0100\n",
            "Epoch 52/100\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3256 - accuracy: 0.8809 - val_loss: 0.3932 - val_accuracy: 0.8496 - lr: 0.0100\n",
            "Epoch 53/100\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3233 - accuracy: 0.8815 - val_loss: 0.3589 - val_accuracy: 0.8658 - lr: 0.0100\n",
            "Epoch 54/100\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3220 - accuracy: 0.8822 - val_loss: 0.3302 - val_accuracy: 0.8745 - lr: 0.0100\n",
            "Epoch 55/100\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3209 - accuracy: 0.8843 - val_loss: 0.3241 - val_accuracy: 0.8745 - lr: 0.0100\n",
            "Epoch 56/100\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3245 - accuracy: 0.8807 - val_loss: 0.4395 - val_accuracy: 0.8201 - lr: 0.0100\n",
            "Epoch 57/100\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3220 - accuracy: 0.8828 - val_loss: 0.2927 - val_accuracy: 0.8966 - lr: 0.0100\n",
            "Epoch 58/100\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3158 - accuracy: 0.8862 - val_loss: 0.3156 - val_accuracy: 0.8817 - lr: 0.0100\n",
            "Epoch 59/100\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3232 - accuracy: 0.8816 - val_loss: 0.3652 - val_accuracy: 0.8545 - lr: 0.0100\n",
            "Epoch 60/100\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3170 - accuracy: 0.8838 - val_loss: 0.3474 - val_accuracy: 0.8705 - lr: 0.0100\n",
            "Epoch 61/100\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3129 - accuracy: 0.8843 - val_loss: 0.2784 - val_accuracy: 0.9000 - lr: 0.0100\n",
            "Epoch 62/100\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3139 - accuracy: 0.8861 - val_loss: 0.2814 - val_accuracy: 0.8972 - lr: 0.0100\n",
            "Epoch 63/100\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3154 - accuracy: 0.8853 - val_loss: 0.2862 - val_accuracy: 0.8966 - lr: 0.0100\n",
            "Epoch 64/100\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3170 - accuracy: 0.8854 - val_loss: 0.3087 - val_accuracy: 0.8845 - lr: 0.0100\n",
            "Epoch 65/100\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3192 - accuracy: 0.8854 - val_loss: 0.3709 - val_accuracy: 0.8577 - lr: 0.0100\n",
            "Epoch 66/100\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3107 - accuracy: 0.8869 - val_loss: 0.3705 - val_accuracy: 0.8569 - lr: 0.0100\n",
            "Epoch 67/100\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3112 - accuracy: 0.8869 - val_loss: 0.3542 - val_accuracy: 0.8681 - lr: 0.0100\n",
            "Epoch 68/100\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3170 - accuracy: 0.8857 - val_loss: 0.3110 - val_accuracy: 0.8810 - lr: 0.0100\n",
            "Epoch 69/100\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3103 - accuracy: 0.8880 - val_loss: 0.2754 - val_accuracy: 0.9005 - lr: 0.0100\n",
            "Epoch 70/100\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3110 - accuracy: 0.8860 - val_loss: 0.2863 - val_accuracy: 0.8942 - lr: 0.0100\n",
            "Epoch 71/100\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3101 - accuracy: 0.8877 - val_loss: 0.2782 - val_accuracy: 0.9000 - lr: 0.0100\n",
            "Epoch 72/100\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3041 - accuracy: 0.8892 - val_loss: 0.3099 - val_accuracy: 0.8857 - lr: 0.0100\n",
            "Epoch 73/100\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3128 - accuracy: 0.8872 - val_loss: 0.3680 - val_accuracy: 0.8590 - lr: 0.0100\n",
            "Epoch 74/100\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3164 - accuracy: 0.8861 - val_loss: 0.3250 - val_accuracy: 0.8840 - lr: 0.0100\n",
            "Epoch 75/100\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3095 - accuracy: 0.8876 - val_loss: 0.3499 - val_accuracy: 0.8760 - lr: 0.0100\n",
            "Epoch 76/100\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3063 - accuracy: 0.8884 - val_loss: 0.2971 - val_accuracy: 0.8903 - lr: 0.0100\n",
            "Epoch 77/100\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3087 - accuracy: 0.8878 - val_loss: 0.2732 - val_accuracy: 0.9005 - lr: 0.0100\n",
            "Epoch 78/100\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3054 - accuracy: 0.8908 - val_loss: 0.3423 - val_accuracy: 0.8698 - lr: 0.0100\n",
            "Epoch 79/100\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3091 - accuracy: 0.8875 - val_loss: 0.2980 - val_accuracy: 0.8878 - lr: 0.0100\n",
            "Epoch 80/100\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3061 - accuracy: 0.8892 - val_loss: 0.3093 - val_accuracy: 0.8882 - lr: 0.0100\n",
            "Epoch 81/100\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3056 - accuracy: 0.8890 - val_loss: 0.3263 - val_accuracy: 0.8774 - lr: 0.0100\n",
            "Epoch 82/100\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3073 - accuracy: 0.8886 - val_loss: 0.3476 - val_accuracy: 0.8650 - lr: 0.0100\n",
            "Epoch 83/100\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3006 - accuracy: 0.8907 - val_loss: 0.3018 - val_accuracy: 0.8884 - lr: 0.0100\n",
            "Epoch 84/100\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3077 - accuracy: 0.8882 - val_loss: 0.3359 - val_accuracy: 0.8748 - lr: 0.0100\n",
            "Epoch 1/100\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.9636 - accuracy: 0.6527 - val_loss: 3.4711 - val_accuracy: 0.1138 - lr: 0.0100\n",
            "Epoch 2/100\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.6383 - accuracy: 0.7655 - val_loss: 3.8420 - val_accuracy: 0.1177 - lr: 0.0100\n",
            "Epoch 3/100\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.5727 - accuracy: 0.7967 - val_loss: 2.9945 - val_accuracy: 0.1552 - lr: 0.0100\n",
            "Epoch 4/100\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.5266 - accuracy: 0.8144 - val_loss: 2.4181 - val_accuracy: 0.1786 - lr: 0.0100\n",
            "Epoch 5/100\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.5003 - accuracy: 0.8221 - val_loss: 2.1945 - val_accuracy: 0.2438 - lr: 0.0100\n",
            "Epoch 6/100\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4799 - accuracy: 0.8302 - val_loss: 2.1812 - val_accuracy: 0.3273 - lr: 0.0100\n",
            "Epoch 7/100\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4584 - accuracy: 0.8379 - val_loss: 1.6634 - val_accuracy: 0.4206 - lr: 0.0100\n",
            "Epoch 8/100\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4546 - accuracy: 0.8375 - val_loss: 1.3660 - val_accuracy: 0.5188 - lr: 0.0100\n",
            "Epoch 9/100\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4486 - accuracy: 0.8400 - val_loss: 0.4760 - val_accuracy: 0.8215 - lr: 0.0100\n",
            "Epoch 10/100\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4284 - accuracy: 0.8463 - val_loss: 0.9799 - val_accuracy: 0.6194 - lr: 0.0100\n",
            "Epoch 11/100\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4210 - accuracy: 0.8495 - val_loss: 0.7699 - val_accuracy: 0.6914 - lr: 0.0100\n",
            "Epoch 12/100\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4160 - accuracy: 0.8524 - val_loss: 0.7497 - val_accuracy: 0.7051 - lr: 0.0100\n",
            "Epoch 13/100\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4090 - accuracy: 0.8525 - val_loss: 0.6247 - val_accuracy: 0.7440 - lr: 0.0100\n",
            "Epoch 14/100\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4051 - accuracy: 0.8536 - val_loss: 0.5473 - val_accuracy: 0.7703 - lr: 0.0100\n",
            "Epoch 15/100\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3995 - accuracy: 0.8573 - val_loss: 0.5282 - val_accuracy: 0.7836 - lr: 0.0100\n",
            "Epoch 16/100\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3890 - accuracy: 0.8589 - val_loss: 0.5600 - val_accuracy: 0.7732 - lr: 0.0100\n",
            "Epoch 17/100\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3906 - accuracy: 0.8607 - val_loss: 0.4640 - val_accuracy: 0.8090 - lr: 0.0100\n",
            "Epoch 18/100\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3830 - accuracy: 0.8627 - val_loss: 0.5669 - val_accuracy: 0.7682 - lr: 0.0100\n",
            "Epoch 19/100\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3825 - accuracy: 0.8638 - val_loss: 0.6033 - val_accuracy: 0.7697 - lr: 0.0100\n",
            "Epoch 20/100\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3720 - accuracy: 0.8662 - val_loss: 0.4666 - val_accuracy: 0.8198 - lr: 0.0100\n",
            "Epoch 21/100\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3741 - accuracy: 0.8658 - val_loss: 0.5470 - val_accuracy: 0.7741 - lr: 0.0100\n",
            "Epoch 22/100\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3756 - accuracy: 0.8667 - val_loss: 0.4008 - val_accuracy: 0.8441 - lr: 0.0100\n",
            "Epoch 23/100\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3721 - accuracy: 0.8664 - val_loss: 0.3487 - val_accuracy: 0.8704 - lr: 0.0100\n",
            "Epoch 24/100\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3631 - accuracy: 0.8701 - val_loss: 0.3926 - val_accuracy: 0.8524 - lr: 0.0100\n",
            "Epoch 25/100\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3653 - accuracy: 0.8679 - val_loss: 0.4954 - val_accuracy: 0.8030 - lr: 0.0100\n",
            "Epoch 26/100\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3623 - accuracy: 0.8685 - val_loss: 0.4271 - val_accuracy: 0.8390 - lr: 0.0100\n",
            "Epoch 27/100\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3581 - accuracy: 0.8728 - val_loss: 0.4485 - val_accuracy: 0.8240 - lr: 0.0100\n",
            "Epoch 28/100\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3590 - accuracy: 0.8709 - val_loss: 0.4453 - val_accuracy: 0.8311 - lr: 0.0100\n",
            "Epoch 29/100\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3550 - accuracy: 0.8719 - val_loss: 0.4775 - val_accuracy: 0.8071 - lr: 0.0100\n",
            "Epoch 30/100\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3554 - accuracy: 0.8705 - val_loss: 0.3179 - val_accuracy: 0.8800 - lr: 0.0100\n",
            "Epoch 31/100\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3458 - accuracy: 0.8773 - val_loss: 0.4058 - val_accuracy: 0.8451 - lr: 0.0100\n",
            "Epoch 32/100\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3477 - accuracy: 0.8763 - val_loss: 0.3423 - val_accuracy: 0.8709 - lr: 0.0100\n",
            "Epoch 33/100\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3458 - accuracy: 0.8752 - val_loss: 0.4017 - val_accuracy: 0.8446 - lr: 0.0100\n",
            "Epoch 34/100\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3487 - accuracy: 0.8745 - val_loss: 0.4088 - val_accuracy: 0.8394 - lr: 0.0100\n",
            "Epoch 35/100\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3425 - accuracy: 0.8777 - val_loss: 0.5752 - val_accuracy: 0.7688 - lr: 0.0100\n",
            "Epoch 36/100\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3404 - accuracy: 0.8773 - val_loss: 0.4771 - val_accuracy: 0.8100 - lr: 0.0100\n",
            "Epoch 37/100\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3365 - accuracy: 0.8795 - val_loss: 0.3780 - val_accuracy: 0.8520 - lr: 0.0100\n",
            "Epoch 38/100\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3411 - accuracy: 0.8780 - val_loss: 0.3558 - val_accuracy: 0.8602 - lr: 0.0100\n",
            "Epoch 39/100\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3435 - accuracy: 0.8747 - val_loss: 0.3454 - val_accuracy: 0.8733 - lr: 0.0100\n",
            "Epoch 40/100\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3359 - accuracy: 0.8785 - val_loss: 0.3395 - val_accuracy: 0.8766 - lr: 0.0100\n",
            "Epoch 41/100\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3358 - accuracy: 0.8784 - val_loss: 0.3234 - val_accuracy: 0.8777 - lr: 0.0100\n",
            "Epoch 42/100\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3351 - accuracy: 0.8779 - val_loss: 0.4277 - val_accuracy: 0.8382 - lr: 0.0100\n",
            "Epoch 43/100\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3330 - accuracy: 0.8797 - val_loss: 0.4324 - val_accuracy: 0.8364 - lr: 0.0100\n",
            "Epoch 44/100\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3304 - accuracy: 0.8803 - val_loss: 0.3837 - val_accuracy: 0.8576 - lr: 0.0100\n",
            "Epoch 45/100\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3288 - accuracy: 0.8814 - val_loss: 0.4165 - val_accuracy: 0.8390 - lr: 0.0100\n",
            "Epoch 1/100\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.9272 - accuracy: 0.6648 - val_loss: 3.1067 - val_accuracy: 0.1085 - lr: 0.0100\n",
            "Epoch 2/100\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.6400 - accuracy: 0.7658 - val_loss: 3.1287 - val_accuracy: 0.1150 - lr: 0.0100\n",
            "Epoch 3/100\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.5772 - accuracy: 0.7900 - val_loss: 2.7984 - val_accuracy: 0.2138 - lr: 0.0100\n",
            "Epoch 4/100\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.5279 - accuracy: 0.8105 - val_loss: 2.8906 - val_accuracy: 0.1601 - lr: 0.0100\n",
            "Epoch 5/100\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.5026 - accuracy: 0.8194 - val_loss: 2.6337 - val_accuracy: 0.2209 - lr: 0.0100\n",
            "Epoch 6/100\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4841 - accuracy: 0.8251 - val_loss: 1.8151 - val_accuracy: 0.3759 - lr: 0.0100\n",
            "Epoch 7/100\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4564 - accuracy: 0.8365 - val_loss: 2.1997 - val_accuracy: 0.3332 - lr: 0.0100\n",
            "Epoch 8/100\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4476 - accuracy: 0.8394 - val_loss: 0.9886 - val_accuracy: 0.6367 - lr: 0.0100\n",
            "Epoch 9/100\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4383 - accuracy: 0.8426 - val_loss: 0.9188 - val_accuracy: 0.6829 - lr: 0.0100\n",
            "Epoch 10/100\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4289 - accuracy: 0.8455 - val_loss: 0.7962 - val_accuracy: 0.6995 - lr: 0.0100\n",
            "Epoch 11/100\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4206 - accuracy: 0.8485 - val_loss: 0.9031 - val_accuracy: 0.6629 - lr: 0.0100\n",
            "Epoch 12/100\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4087 - accuracy: 0.8511 - val_loss: 0.6285 - val_accuracy: 0.7391 - lr: 0.0100\n",
            "Epoch 13/100\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4136 - accuracy: 0.8513 - val_loss: 0.7941 - val_accuracy: 0.6936 - lr: 0.0100\n",
            "Epoch 14/100\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4043 - accuracy: 0.8539 - val_loss: 0.7905 - val_accuracy: 0.6966 - lr: 0.0100\n",
            "Epoch 15/100\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3970 - accuracy: 0.8564 - val_loss: 0.7002 - val_accuracy: 0.7085 - lr: 0.0100\n",
            "Epoch 16/100\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3955 - accuracy: 0.8564 - val_loss: 1.1847 - val_accuracy: 0.5694 - lr: 0.0100\n",
            "Epoch 17/100\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3913 - accuracy: 0.8583 - val_loss: 0.7309 - val_accuracy: 0.7024 - lr: 0.0100\n",
            "Epoch 18/100\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3849 - accuracy: 0.8604 - val_loss: 0.5718 - val_accuracy: 0.7452 - lr: 0.0100\n",
            "Epoch 19/100\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3840 - accuracy: 0.8609 - val_loss: 0.5810 - val_accuracy: 0.7539 - lr: 0.0100\n",
            "Epoch 20/100\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3785 - accuracy: 0.8623 - val_loss: 0.7642 - val_accuracy: 0.6946 - lr: 0.0100\n",
            "Epoch 21/100\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3773 - accuracy: 0.8631 - val_loss: 0.5814 - val_accuracy: 0.7675 - lr: 0.0100\n",
            "Epoch 22/100\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3667 - accuracy: 0.8672 - val_loss: 0.5396 - val_accuracy: 0.7780 - lr: 0.0100\n",
            "Epoch 23/100\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3722 - accuracy: 0.8645 - val_loss: 0.5855 - val_accuracy: 0.7581 - lr: 0.0100\n",
            "Epoch 24/100\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3663 - accuracy: 0.8691 - val_loss: 0.5641 - val_accuracy: 0.7707 - lr: 0.0100\n",
            "Epoch 25/100\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3660 - accuracy: 0.8688 - val_loss: 0.5682 - val_accuracy: 0.7706 - lr: 0.0100\n",
            "Epoch 26/100\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3594 - accuracy: 0.8698 - val_loss: 0.5950 - val_accuracy: 0.7600 - lr: 0.0100\n",
            "Epoch 27/100\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3612 - accuracy: 0.8690 - val_loss: 0.5013 - val_accuracy: 0.8034 - lr: 0.0100\n",
            "Epoch 28/100\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3562 - accuracy: 0.8711 - val_loss: 0.5674 - val_accuracy: 0.7734 - lr: 0.0100\n",
            "Epoch 29/100\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3599 - accuracy: 0.8689 - val_loss: 0.4873 - val_accuracy: 0.8096 - lr: 0.0100\n",
            "Epoch 30/100\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3448 - accuracy: 0.8741 - val_loss: 0.4467 - val_accuracy: 0.8276 - lr: 0.0100\n",
            "Epoch 31/100\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3539 - accuracy: 0.8729 - val_loss: 0.5835 - val_accuracy: 0.7604 - lr: 0.0100\n",
            "Epoch 32/100\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3547 - accuracy: 0.8710 - val_loss: 0.5648 - val_accuracy: 0.7654 - lr: 0.0100\n",
            "Epoch 33/100\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3499 - accuracy: 0.8743 - val_loss: 0.4772 - val_accuracy: 0.8098 - lr: 0.0100\n",
            "Epoch 34/100\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3463 - accuracy: 0.8717 - val_loss: 0.5671 - val_accuracy: 0.7690 - lr: 0.0100\n",
            "Epoch 35/100\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3456 - accuracy: 0.8727 - val_loss: 0.4351 - val_accuracy: 0.8274 - lr: 0.0100\n",
            "Epoch 36/100\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3432 - accuracy: 0.8752 - val_loss: 0.3408 - val_accuracy: 0.8677 - lr: 0.0100\n",
            "Epoch 37/100\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3379 - accuracy: 0.8745 - val_loss: 0.3654 - val_accuracy: 0.8621 - lr: 0.0100\n",
            "Epoch 38/100\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3344 - accuracy: 0.8776 - val_loss: 0.4882 - val_accuracy: 0.8124 - lr: 0.0100\n",
            "Epoch 39/100\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3430 - accuracy: 0.8762 - val_loss: 0.4505 - val_accuracy: 0.8241 - lr: 0.0100\n",
            "Epoch 40/100\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3367 - accuracy: 0.8779 - val_loss: 0.4127 - val_accuracy: 0.8411 - lr: 0.0100\n",
            "Epoch 41/100\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3376 - accuracy: 0.8764 - val_loss: 0.4044 - val_accuracy: 0.8449 - lr: 0.0100\n",
            "Epoch 42/100\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3358 - accuracy: 0.8776 - val_loss: 0.3341 - val_accuracy: 0.8736 - lr: 0.0100\n",
            "Epoch 43/100\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3309 - accuracy: 0.8816 - val_loss: 0.4996 - val_accuracy: 0.7944 - lr: 0.0100\n",
            "Epoch 44/100\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3333 - accuracy: 0.8784 - val_loss: 0.3972 - val_accuracy: 0.8428 - lr: 0.0100\n",
            "Epoch 45/100\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3279 - accuracy: 0.8812 - val_loss: 0.4175 - val_accuracy: 0.8326 - lr: 0.0100\n",
            "Epoch 46/100\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3319 - accuracy: 0.8803 - val_loss: 0.3098 - val_accuracy: 0.8831 - lr: 0.0100\n",
            "Epoch 47/100\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3330 - accuracy: 0.8799 - val_loss: 0.4330 - val_accuracy: 0.8345 - lr: 0.0100\n",
            "Epoch 48/100\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3253 - accuracy: 0.8820 - val_loss: 0.4436 - val_accuracy: 0.8281 - lr: 0.0100\n",
            "Epoch 49/100\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3299 - accuracy: 0.8805 - val_loss: 0.3436 - val_accuracy: 0.8670 - lr: 0.0100\n",
            "Epoch 50/100\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3265 - accuracy: 0.8816 - val_loss: 0.3101 - val_accuracy: 0.8851 - lr: 0.0100\n",
            "Epoch 51/100\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3248 - accuracy: 0.8806 - val_loss: 0.3782 - val_accuracy: 0.8515 - lr: 0.0100\n",
            "Epoch 52/100\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3217 - accuracy: 0.8839 - val_loss: 0.3466 - val_accuracy: 0.8748 - lr: 0.0100\n",
            "Epoch 53/100\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3222 - accuracy: 0.8824 - val_loss: 0.4271 - val_accuracy: 0.8361 - lr: 0.0100\n",
            "Epoch 54/100\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3213 - accuracy: 0.8832 - val_loss: 0.3989 - val_accuracy: 0.8401 - lr: 0.0100\n",
            "Epoch 55/100\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3199 - accuracy: 0.8836 - val_loss: 0.3641 - val_accuracy: 0.8591 - lr: 0.0100\n",
            "Epoch 56/100\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3231 - accuracy: 0.8833 - val_loss: 0.2962 - val_accuracy: 0.8892 - lr: 0.0100\n",
            "Epoch 57/100\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3224 - accuracy: 0.8853 - val_loss: 0.3056 - val_accuracy: 0.8852 - lr: 0.0100\n",
            "Epoch 58/100\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3215 - accuracy: 0.8841 - val_loss: 0.4517 - val_accuracy: 0.8151 - lr: 0.0100\n",
            "Epoch 59/100\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3238 - accuracy: 0.8841 - val_loss: 0.3957 - val_accuracy: 0.8489 - lr: 0.0100\n",
            "Epoch 60/100\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3186 - accuracy: 0.8852 - val_loss: 0.5043 - val_accuracy: 0.7974 - lr: 0.0100\n",
            "Epoch 61/100\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3145 - accuracy: 0.8854 - val_loss: 0.4284 - val_accuracy: 0.8390 - lr: 0.0100\n",
            "Epoch 62/100\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3211 - accuracy: 0.8829 - val_loss: 0.4014 - val_accuracy: 0.8374 - lr: 0.0100\n",
            "Epoch 63/100\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3126 - accuracy: 0.8847 - val_loss: 0.3903 - val_accuracy: 0.8519 - lr: 0.0100\n",
            "Epoch 64/100\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3146 - accuracy: 0.8858 - val_loss: 0.3563 - val_accuracy: 0.8587 - lr: 0.0100\n",
            "Epoch 65/100\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3128 - accuracy: 0.8861 - val_loss: 0.3593 - val_accuracy: 0.8619 - lr: 0.0100\n",
            "Epoch 66/100\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3168 - accuracy: 0.8832 - val_loss: 0.4151 - val_accuracy: 0.8382 - lr: 0.0100\n",
            "Epoch 67/100\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3168 - accuracy: 0.8862 - val_loss: 0.3193 - val_accuracy: 0.8815 - lr: 0.0100\n",
            "Epoch 68/100\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3117 - accuracy: 0.8872 - val_loss: 0.2814 - val_accuracy: 0.8976 - lr: 0.0100\n",
            "Epoch 69/100\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3112 - accuracy: 0.8876 - val_loss: 0.3996 - val_accuracy: 0.8447 - lr: 0.0100\n",
            "Epoch 70/100\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3088 - accuracy: 0.8892 - val_loss: 0.3771 - val_accuracy: 0.8545 - lr: 0.0100\n",
            "Epoch 71/100\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3098 - accuracy: 0.8873 - val_loss: 0.2960 - val_accuracy: 0.8884 - lr: 0.0100\n",
            "Epoch 72/100\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3117 - accuracy: 0.8871 - val_loss: 0.3137 - val_accuracy: 0.8817 - lr: 0.0100\n",
            "Epoch 73/100\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3035 - accuracy: 0.8894 - val_loss: 0.3785 - val_accuracy: 0.8537 - lr: 0.0100\n",
            "Epoch 74/100\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3134 - accuracy: 0.8882 - val_loss: 0.3547 - val_accuracy: 0.8660 - lr: 0.0100\n",
            "Epoch 75/100\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3067 - accuracy: 0.8903 - val_loss: 0.4275 - val_accuracy: 0.8400 - lr: 0.0100\n",
            "Epoch 76/100\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3096 - accuracy: 0.8865 - val_loss: 0.2917 - val_accuracy: 0.8930 - lr: 0.0100\n",
            "Epoch 77/100\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3082 - accuracy: 0.8870 - val_loss: 0.2865 - val_accuracy: 0.8924 - lr: 0.0100\n",
            "Epoch 78/100\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3057 - accuracy: 0.8892 - val_loss: 0.2811 - val_accuracy: 0.8980 - lr: 0.0100\n",
            "Epoch 79/100\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3014 - accuracy: 0.8890 - val_loss: 0.3521 - val_accuracy: 0.8600 - lr: 0.0100\n",
            "Epoch 80/100\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3096 - accuracy: 0.8869 - val_loss: 0.3241 - val_accuracy: 0.8740 - lr: 0.0100\n",
            "Epoch 81/100\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3044 - accuracy: 0.8903 - val_loss: 0.2853 - val_accuracy: 0.8946 - lr: 0.0100\n",
            "Epoch 82/100\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3013 - accuracy: 0.8883 - val_loss: 0.2838 - val_accuracy: 0.8949 - lr: 0.0100\n",
            "Epoch 83/100\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2974 - accuracy: 0.8914 - val_loss: 0.3583 - val_accuracy: 0.8696 - lr: 0.0100\n",
            "Epoch 84/100\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3045 - accuracy: 0.8882 - val_loss: 0.2865 - val_accuracy: 0.8959 - lr: 0.0100\n",
            "Epoch 85/100\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3074 - accuracy: 0.8882 - val_loss: 0.3105 - val_accuracy: 0.8876 - lr: 0.0100\n",
            "Epoch 86/100\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3032 - accuracy: 0.8896 - val_loss: 0.2909 - val_accuracy: 0.8945 - lr: 0.0100\n",
            "Epoch 87/100\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3022 - accuracy: 0.8910 - val_loss: 0.2839 - val_accuracy: 0.8969 - lr: 0.0100\n",
            "Epoch 88/100\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3021 - accuracy: 0.8889 - val_loss: 0.2856 - val_accuracy: 0.8959 - lr: 0.0100\n",
            "Epoch 89/100\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3032 - accuracy: 0.8882 - val_loss: 0.3436 - val_accuracy: 0.8654 - lr: 0.0100\n",
            "Epoch 90/100\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2987 - accuracy: 0.8927 - val_loss: 0.4446 - val_accuracy: 0.8249 - lr: 0.0100\n",
            "Epoch 91/100\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2985 - accuracy: 0.8917 - val_loss: 0.3750 - val_accuracy: 0.8571 - lr: 0.0100\n",
            "Epoch 92/100\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3032 - accuracy: 0.8913 - val_loss: 0.2828 - val_accuracy: 0.8991 - lr: 0.0100\n",
            "Epoch 93/100\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2986 - accuracy: 0.8923 - val_loss: 0.3408 - val_accuracy: 0.8684 - lr: 0.0100\n",
            "Epoch 94/100\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3078 - accuracy: 0.8892 - val_loss: 0.2888 - val_accuracy: 0.8931 - lr: 0.0100\n",
            "Epoch 95/100\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2963 - accuracy: 0.8933 - val_loss: 0.3199 - val_accuracy: 0.8821 - lr: 0.0100\n",
            "Epoch 96/100\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2946 - accuracy: 0.8925 - val_loss: 0.2711 - val_accuracy: 0.9014 - lr: 0.0100\n",
            "Epoch 97/100\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2999 - accuracy: 0.8922 - val_loss: 0.2942 - val_accuracy: 0.8901 - lr: 0.0100\n",
            "Epoch 98/100\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2987 - accuracy: 0.8907 - val_loss: 0.3193 - val_accuracy: 0.8851 - lr: 0.0100\n",
            "Epoch 99/100\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2949 - accuracy: 0.8927 - val_loss: 0.3728 - val_accuracy: 0.8600 - lr: 0.0100\n",
            "Epoch 100/100\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.2967 - accuracy: 0.8921 - val_loss: 0.2832 - val_accuracy: 0.8971 - lr: 0.0100\n",
            "Epoch 1/100\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.9329 - accuracy: 0.6637 - val_loss: 2.9626 - val_accuracy: 0.1069 - lr: 0.0100\n",
            "Epoch 2/100\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.6431 - accuracy: 0.7631 - val_loss: 2.8625 - val_accuracy: 0.1501 - lr: 0.0100\n",
            "Epoch 3/100\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.5760 - accuracy: 0.7896 - val_loss: 2.6777 - val_accuracy: 0.1035 - lr: 0.0100\n",
            "Epoch 4/100\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.5269 - accuracy: 0.8090 - val_loss: 2.1876 - val_accuracy: 0.2731 - lr: 0.0100\n",
            "Epoch 5/100\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4992 - accuracy: 0.8193 - val_loss: 1.9619 - val_accuracy: 0.3816 - lr: 0.0100\n",
            "Epoch 6/100\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4732 - accuracy: 0.8291 - val_loss: 1.4135 - val_accuracy: 0.5228 - lr: 0.0100\n",
            "Epoch 7/100\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4583 - accuracy: 0.8335 - val_loss: 1.4608 - val_accuracy: 0.5021 - lr: 0.0100\n",
            "Epoch 8/100\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4529 - accuracy: 0.8367 - val_loss: 0.8845 - val_accuracy: 0.6975 - lr: 0.0100\n",
            "Epoch 9/100\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4346 - accuracy: 0.8432 - val_loss: 1.0056 - val_accuracy: 0.6862 - lr: 0.0100\n",
            "Epoch 10/100\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4331 - accuracy: 0.8423 - val_loss: 0.5577 - val_accuracy: 0.7853 - lr: 0.0100\n",
            "Epoch 11/100\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4221 - accuracy: 0.8484 - val_loss: 0.5071 - val_accuracy: 0.7962 - lr: 0.0100\n",
            "Epoch 12/100\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4113 - accuracy: 0.8512 - val_loss: 0.7237 - val_accuracy: 0.7050 - lr: 0.0100\n",
            "Epoch 13/100\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4077 - accuracy: 0.8514 - val_loss: 0.6031 - val_accuracy: 0.7486 - lr: 0.0100\n",
            "Epoch 14/100\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.4113 - accuracy: 0.8498 - val_loss: 0.4955 - val_accuracy: 0.7993 - lr: 0.0100\n",
            "Epoch 15/100\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3992 - accuracy: 0.8558 - val_loss: 0.5331 - val_accuracy: 0.7904 - lr: 0.0100\n",
            "Epoch 16/100\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3906 - accuracy: 0.8602 - val_loss: 0.4655 - val_accuracy: 0.8116 - lr: 0.0100\n",
            "Epoch 17/100\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3798 - accuracy: 0.8630 - val_loss: 0.4913 - val_accuracy: 0.8049 - lr: 0.0100\n",
            "Epoch 18/100\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3766 - accuracy: 0.8632 - val_loss: 0.4954 - val_accuracy: 0.8061 - lr: 0.0100\n",
            "Epoch 19/100\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3821 - accuracy: 0.8615 - val_loss: 0.4719 - val_accuracy: 0.8173 - lr: 0.0100\n",
            "Epoch 20/100\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3723 - accuracy: 0.8641 - val_loss: 0.4274 - val_accuracy: 0.8265 - lr: 0.0100\n",
            "Epoch 21/100\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3760 - accuracy: 0.8648 - val_loss: 0.5131 - val_accuracy: 0.7993 - lr: 0.0100\n",
            "Epoch 22/100\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3724 - accuracy: 0.8637 - val_loss: 0.5188 - val_accuracy: 0.7876 - lr: 0.0100\n",
            "Epoch 23/100\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3716 - accuracy: 0.8658 - val_loss: 0.4793 - val_accuracy: 0.8015 - lr: 0.0100\n",
            "Epoch 24/100\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3645 - accuracy: 0.8673 - val_loss: 0.4952 - val_accuracy: 0.7890 - lr: 0.0100\n",
            "Epoch 25/100\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3576 - accuracy: 0.8711 - val_loss: 0.4680 - val_accuracy: 0.8052 - lr: 0.0100\n",
            "Epoch 26/100\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3570 - accuracy: 0.8701 - val_loss: 0.5576 - val_accuracy: 0.7700 - lr: 0.0100\n",
            "Epoch 27/100\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3596 - accuracy: 0.8686 - val_loss: 0.4338 - val_accuracy: 0.8317 - lr: 0.0100\n",
            "Epoch 28/100\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3569 - accuracy: 0.8712 - val_loss: 0.5149 - val_accuracy: 0.7986 - lr: 0.0100\n",
            "Epoch 29/100\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3529 - accuracy: 0.8734 - val_loss: 0.3858 - val_accuracy: 0.8535 - lr: 0.0100\n",
            "Epoch 30/100\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3528 - accuracy: 0.8724 - val_loss: 0.4006 - val_accuracy: 0.8471 - lr: 0.0100\n",
            "Epoch 31/100\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3571 - accuracy: 0.8703 - val_loss: 0.4193 - val_accuracy: 0.8263 - lr: 0.0100\n",
            "Epoch 32/100\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3439 - accuracy: 0.8747 - val_loss: 0.5152 - val_accuracy: 0.7899 - lr: 0.0100\n",
            "Epoch 33/100\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3525 - accuracy: 0.8706 - val_loss: 0.4160 - val_accuracy: 0.8426 - lr: 0.0100\n",
            "Epoch 34/100\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3411 - accuracy: 0.8758 - val_loss: 0.5272 - val_accuracy: 0.7972 - lr: 0.0100\n",
            "Epoch 35/100\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3478 - accuracy: 0.8744 - val_loss: 0.4301 - val_accuracy: 0.8303 - lr: 0.0100\n",
            "Epoch 36/100\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3420 - accuracy: 0.8772 - val_loss: 0.4028 - val_accuracy: 0.8382 - lr: 0.0100\n",
            "Epoch 37/100\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3397 - accuracy: 0.8765 - val_loss: 0.4041 - val_accuracy: 0.8426 - lr: 0.0100\n",
            "Epoch 38/100\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3381 - accuracy: 0.8777 - val_loss: 0.4239 - val_accuracy: 0.8345 - lr: 0.0100\n",
            "Epoch 39/100\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3361 - accuracy: 0.8785 - val_loss: 0.3568 - val_accuracy: 0.8630 - lr: 0.0100\n",
            "Epoch 40/100\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3365 - accuracy: 0.8793 - val_loss: 0.3279 - val_accuracy: 0.8761 - lr: 0.0100\n",
            "Epoch 41/100\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3354 - accuracy: 0.8799 - val_loss: 0.3423 - val_accuracy: 0.8696 - lr: 0.0100\n",
            "Epoch 42/100\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3326 - accuracy: 0.8806 - val_loss: 0.3221 - val_accuracy: 0.8777 - lr: 0.0100\n",
            "Epoch 43/100\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3360 - accuracy: 0.8775 - val_loss: 0.3212 - val_accuracy: 0.8775 - lr: 0.0100\n",
            "Epoch 44/100\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3296 - accuracy: 0.8791 - val_loss: 0.4322 - val_accuracy: 0.8246 - lr: 0.0100\n",
            "Epoch 45/100\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3321 - accuracy: 0.8782 - val_loss: 0.4291 - val_accuracy: 0.8335 - lr: 0.0100\n",
            "Epoch 46/100\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3241 - accuracy: 0.8827 - val_loss: 0.3979 - val_accuracy: 0.8510 - lr: 0.0100\n",
            "Epoch 47/100\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3274 - accuracy: 0.8802 - val_loss: 0.3190 - val_accuracy: 0.8823 - lr: 0.0100\n",
            "Epoch 48/100\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3289 - accuracy: 0.8792 - val_loss: 0.2958 - val_accuracy: 0.8938 - lr: 0.0100\n",
            "Epoch 49/100\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3263 - accuracy: 0.8804 - val_loss: 0.3412 - val_accuracy: 0.8702 - lr: 0.0100\n",
            "Epoch 50/100\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3216 - accuracy: 0.8848 - val_loss: 0.4618 - val_accuracy: 0.8175 - lr: 0.0100\n",
            "Epoch 51/100\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3284 - accuracy: 0.8810 - val_loss: 0.2960 - val_accuracy: 0.8901 - lr: 0.0100\n",
            "Epoch 52/100\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3250 - accuracy: 0.8830 - val_loss: 0.4569 - val_accuracy: 0.8239 - lr: 0.0100\n",
            "Epoch 53/100\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3221 - accuracy: 0.8832 - val_loss: 0.3114 - val_accuracy: 0.8821 - lr: 0.0100\n",
            "Epoch 54/100\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3225 - accuracy: 0.8825 - val_loss: 0.4029 - val_accuracy: 0.8429 - lr: 0.0100\n",
            "Epoch 55/100\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3233 - accuracy: 0.8818 - val_loss: 0.3387 - val_accuracy: 0.8709 - lr: 0.0100\n",
            "Epoch 56/100\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3195 - accuracy: 0.8838 - val_loss: 0.2866 - val_accuracy: 0.8966 - lr: 0.0100\n",
            "Epoch 57/100\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3232 - accuracy: 0.8835 - val_loss: 0.4153 - val_accuracy: 0.8395 - lr: 0.0100\n",
            "Epoch 58/100\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3146 - accuracy: 0.8863 - val_loss: 0.2991 - val_accuracy: 0.8913 - lr: 0.0100\n",
            "Epoch 59/100\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3162 - accuracy: 0.8858 - val_loss: 0.3377 - val_accuracy: 0.8755 - lr: 0.0100\n",
            "Epoch 60/100\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3137 - accuracy: 0.8850 - val_loss: 0.3771 - val_accuracy: 0.8568 - lr: 0.0100\n",
            "Epoch 61/100\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3177 - accuracy: 0.8847 - val_loss: 0.3107 - val_accuracy: 0.8857 - lr: 0.0100\n",
            "Epoch 62/100\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3158 - accuracy: 0.8873 - val_loss: 0.3495 - val_accuracy: 0.8712 - lr: 0.0100\n",
            "Epoch 63/100\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3144 - accuracy: 0.8889 - val_loss: 0.3467 - val_accuracy: 0.8673 - lr: 0.0100\n",
            "Epoch 64/100\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3121 - accuracy: 0.8855 - val_loss: 0.3168 - val_accuracy: 0.8792 - lr: 0.0100\n",
            "Epoch 65/100\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3106 - accuracy: 0.8884 - val_loss: 0.3682 - val_accuracy: 0.8583 - lr: 0.0100\n",
            "Epoch 66/100\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3099 - accuracy: 0.8868 - val_loss: 0.3584 - val_accuracy: 0.8677 - lr: 0.0100\n",
            "Epoch 67/100\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3145 - accuracy: 0.8867 - val_loss: 0.3076 - val_accuracy: 0.8894 - lr: 0.0100\n",
            "Epoch 68/100\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3104 - accuracy: 0.8873 - val_loss: 0.4105 - val_accuracy: 0.8395 - lr: 0.0100\n",
            "Epoch 69/100\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3143 - accuracy: 0.8845 - val_loss: 0.3094 - val_accuracy: 0.8873 - lr: 0.0100\n",
            "Epoch 70/100\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3161 - accuracy: 0.8864 - val_loss: 0.2708 - val_accuracy: 0.9014 - lr: 0.0100\n",
            "Epoch 71/100\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3125 - accuracy: 0.8840 - val_loss: 0.2974 - val_accuracy: 0.8944 - lr: 0.0100\n",
            "Epoch 72/100\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3123 - accuracy: 0.8868 - val_loss: 0.2784 - val_accuracy: 0.8994 - lr: 0.0100\n",
            "Epoch 73/100\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3110 - accuracy: 0.8878 - val_loss: 0.2936 - val_accuracy: 0.8926 - lr: 0.0100\n",
            "Epoch 74/100\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3070 - accuracy: 0.8887 - val_loss: 0.3327 - val_accuracy: 0.8816 - lr: 0.0100\n",
            "Epoch 75/100\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3094 - accuracy: 0.8892 - val_loss: 0.3270 - val_accuracy: 0.8779 - lr: 0.0100\n",
            "Epoch 76/100\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3104 - accuracy: 0.8866 - val_loss: 0.3044 - val_accuracy: 0.8880 - lr: 0.0100\n",
            "Epoch 77/100\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3083 - accuracy: 0.8875 - val_loss: 0.4094 - val_accuracy: 0.8410 - lr: 0.0100\n",
            "Epoch 78/100\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3042 - accuracy: 0.8873 - val_loss: 0.2784 - val_accuracy: 0.8994 - lr: 0.0100\n",
            "Epoch 79/100\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3017 - accuracy: 0.8906 - val_loss: 0.3617 - val_accuracy: 0.8681 - lr: 0.0100\n",
            "Epoch 80/100\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3074 - accuracy: 0.8887 - val_loss: 0.2692 - val_accuracy: 0.8989 - lr: 0.0100\n",
            "Epoch 81/100\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3048 - accuracy: 0.8916 - val_loss: 0.3235 - val_accuracy: 0.8775 - lr: 0.0100\n",
            "Epoch 82/100\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3020 - accuracy: 0.8904 - val_loss: 0.2853 - val_accuracy: 0.8940 - lr: 0.0100\n",
            "Epoch 83/100\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3020 - accuracy: 0.8914 - val_loss: 0.3219 - val_accuracy: 0.8798 - lr: 0.0100\n",
            "Epoch 84/100\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3017 - accuracy: 0.8908 - val_loss: 0.2736 - val_accuracy: 0.8971 - lr: 0.0100\n",
            "Epoch 85/100\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.91088\n",
            "63/63 - 1s - loss: 0.3036 - accuracy: 0.8881 - val_loss: 0.3145 - val_accuracy: 0.8854 - lr: 0.0100\n",
            "Epoch 1/100\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.91088\n",
            "94/94 - 1s - loss: 0.8861 - accuracy: 0.6865 - val_loss: 2.5211 - val_accuracy: 0.0959 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.91088\n",
            "94/94 - 1s - loss: 0.5542 - accuracy: 0.8005 - val_loss: 2.3172 - val_accuracy: 0.0972 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.91088\n",
            "94/94 - 1s - loss: 0.4792 - accuracy: 0.8293 - val_loss: 1.8236 - val_accuracy: 0.2738 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.91088\n",
            "94/94 - 1s - loss: 0.4377 - accuracy: 0.8429 - val_loss: 1.1216 - val_accuracy: 0.5551 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.91088\n",
            "94/94 - 1s - loss: 0.4080 - accuracy: 0.8550 - val_loss: 0.7151 - val_accuracy: 0.7168 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.91088\n",
            "94/94 - 1s - loss: 0.3806 - accuracy: 0.8636 - val_loss: 0.4721 - val_accuracy: 0.8155 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.91088\n",
            "94/94 - 1s - loss: 0.3681 - accuracy: 0.8690 - val_loss: 0.3789 - val_accuracy: 0.8555 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.91088\n",
            "94/94 - 1s - loss: 0.3539 - accuracy: 0.8707 - val_loss: 0.3363 - val_accuracy: 0.8723 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.91088\n",
            "94/94 - 1s - loss: 0.3419 - accuracy: 0.8756 - val_loss: 0.3323 - val_accuracy: 0.8765 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.91088\n",
            "94/94 - 1s - loss: 0.3282 - accuracy: 0.8804 - val_loss: 0.3635 - val_accuracy: 0.8625 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.91088\n",
            "94/94 - 1s - loss: 0.3183 - accuracy: 0.8848 - val_loss: 0.2975 - val_accuracy: 0.8889 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.91088\n",
            "94/94 - 1s - loss: 0.3125 - accuracy: 0.8863 - val_loss: 0.2914 - val_accuracy: 0.8929 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.91088\n",
            "94/94 - 1s - loss: 0.3007 - accuracy: 0.8889 - val_loss: 0.2997 - val_accuracy: 0.8889 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.91088\n",
            "94/94 - 1s - loss: 0.2999 - accuracy: 0.8909 - val_loss: 0.3048 - val_accuracy: 0.8878 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.91088\n",
            "94/94 - 1s - loss: 0.2882 - accuracy: 0.8963 - val_loss: 0.2871 - val_accuracy: 0.8922 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.91088\n",
            "94/94 - 1s - loss: 0.2818 - accuracy: 0.8970 - val_loss: 0.2820 - val_accuracy: 0.8981 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.91088\n",
            "94/94 - 1s - loss: 0.2759 - accuracy: 0.8996 - val_loss: 0.2929 - val_accuracy: 0.8941 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.91088\n",
            "94/94 - 1s - loss: 0.2721 - accuracy: 0.9008 - val_loss: 0.2871 - val_accuracy: 0.8960 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.91088\n",
            "94/94 - 1s - loss: 0.2677 - accuracy: 0.9013 - val_loss: 0.2842 - val_accuracy: 0.8963 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.91088\n",
            "94/94 - 1s - loss: 0.2597 - accuracy: 0.9043 - val_loss: 0.2825 - val_accuracy: 0.8974 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.91088\n",
            "94/94 - 1s - loss: 0.2563 - accuracy: 0.9063 - val_loss: 0.3119 - val_accuracy: 0.8832 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.91088\n",
            "94/94 - 1s - loss: 0.2567 - accuracy: 0.9065 - val_loss: 0.2726 - val_accuracy: 0.9001 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.91088\n",
            "94/94 - 1s - loss: 0.2492 - accuracy: 0.9078 - val_loss: 0.2804 - val_accuracy: 0.8991 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.91088\n",
            "94/94 - 1s - loss: 0.2431 - accuracy: 0.9108 - val_loss: 0.2735 - val_accuracy: 0.8988 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.91088\n",
            "94/94 - 1s - loss: 0.2384 - accuracy: 0.9124 - val_loss: 0.2656 - val_accuracy: 0.9038 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.91088\n",
            "94/94 - 1s - loss: 0.2381 - accuracy: 0.9138 - val_loss: 0.3083 - val_accuracy: 0.8864 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.91088\n",
            "94/94 - 1s - loss: 0.2330 - accuracy: 0.9128 - val_loss: 0.2648 - val_accuracy: 0.9034 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.91088\n",
            "94/94 - 1s - loss: 0.2329 - accuracy: 0.9127 - val_loss: 0.3052 - val_accuracy: 0.8941 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.91088\n",
            "94/94 - 1s - loss: 0.2267 - accuracy: 0.9154 - val_loss: 0.2779 - val_accuracy: 0.9009 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.91088\n",
            "94/94 - 1s - loss: 0.2250 - accuracy: 0.9172 - val_loss: 0.2780 - val_accuracy: 0.8990 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.91088\n",
            "94/94 - 1s - loss: 0.2244 - accuracy: 0.9182 - val_loss: 0.2714 - val_accuracy: 0.9024 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.91088\n",
            "94/94 - 1s - loss: 0.2251 - accuracy: 0.9168 - val_loss: 0.2750 - val_accuracy: 0.9032 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.91088\n",
            "94/94 - 1s - loss: 0.2201 - accuracy: 0.9197 - val_loss: 0.2619 - val_accuracy: 0.9069 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.91088\n",
            "94/94 - 1s - loss: 0.2192 - accuracy: 0.9191 - val_loss: 0.2629 - val_accuracy: 0.9045 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.91088\n",
            "94/94 - 1s - loss: 0.2134 - accuracy: 0.9211 - val_loss: 0.2624 - val_accuracy: 0.9056 - lr: 0.0010\n",
            "Epoch 36/100\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.91088\n",
            "94/94 - 1s - loss: 0.2100 - accuracy: 0.9230 - val_loss: 0.2946 - val_accuracy: 0.8944 - lr: 0.0010\n",
            "Epoch 37/100\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.91088\n",
            "94/94 - 1s - loss: 0.2088 - accuracy: 0.9225 - val_loss: 0.2538 - val_accuracy: 0.9083 - lr: 0.0010\n",
            "Epoch 38/100\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.91088\n",
            "94/94 - 1s - loss: 0.2041 - accuracy: 0.9253 - val_loss: 0.2671 - val_accuracy: 0.9077 - lr: 0.0010\n",
            "Epoch 39/100\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.91088\n",
            "94/94 - 1s - loss: 0.2058 - accuracy: 0.9235 - val_loss: 0.2774 - val_accuracy: 0.9034 - lr: 0.0010\n",
            "Epoch 40/100\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.91088\n",
            "94/94 - 1s - loss: 0.2003 - accuracy: 0.9258 - val_loss: 0.2766 - val_accuracy: 0.9044 - lr: 0.0010\n",
            "Epoch 41/100\n",
            "\n",
            "Epoch 00041: val_accuracy improved from 0.91088 to 0.91142, saving model to ./mymodel.h5\n",
            "94/94 - 1s - loss: 0.2028 - accuracy: 0.9249 - val_loss: 0.2543 - val_accuracy: 0.9114 - lr: 0.0010\n",
            "Epoch 42/100\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.91142\n",
            "94/94 - 1s - loss: 0.2017 - accuracy: 0.9264 - val_loss: 0.2595 - val_accuracy: 0.9093 - lr: 0.0010\n",
            "Epoch 43/100\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.91142\n",
            "94/94 - 1s - loss: 0.1981 - accuracy: 0.9268 - val_loss: 0.2853 - val_accuracy: 0.8997 - lr: 0.0010\n",
            "Epoch 44/100\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.91142\n",
            "94/94 - 1s - loss: 0.1989 - accuracy: 0.9264 - val_loss: 0.2758 - val_accuracy: 0.9035 - lr: 0.0010\n",
            "Epoch 45/100\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.91142\n",
            "94/94 - 1s - loss: 0.1931 - accuracy: 0.9285 - val_loss: 0.2872 - val_accuracy: 0.8998 - lr: 0.0010\n",
            "Epoch 46/100\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.91142\n",
            "94/94 - 1s - loss: 0.1959 - accuracy: 0.9269 - val_loss: 0.2826 - val_accuracy: 0.9003 - lr: 0.0010\n",
            "Epoch 47/100\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.91142\n",
            "94/94 - 1s - loss: 0.1928 - accuracy: 0.9279 - val_loss: 0.2732 - val_accuracy: 0.9053 - lr: 0.0010\n",
            "Epoch 48/100\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.91142\n",
            "94/94 - 1s - loss: 0.1927 - accuracy: 0.9287 - val_loss: 0.2836 - val_accuracy: 0.9043 - lr: 0.0010\n",
            "Epoch 49/100\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.91142\n",
            "94/94 - 1s - loss: 0.1865 - accuracy: 0.9302 - val_loss: 0.2762 - val_accuracy: 0.9030 - lr: 0.0010\n",
            "Epoch 50/100\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.91142\n",
            "94/94 - 1s - loss: 0.1907 - accuracy: 0.9298 - val_loss: 0.2667 - val_accuracy: 0.9100 - lr: 0.0010\n",
            "Epoch 51/100\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.91142\n",
            "94/94 - 1s - loss: 0.1857 - accuracy: 0.9312 - val_loss: 0.3031 - val_accuracy: 0.8942 - lr: 0.0010\n",
            "Epoch 52/100\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.91142\n",
            "94/94 - 1s - loss: 0.1872 - accuracy: 0.9290 - val_loss: 0.2560 - val_accuracy: 0.9111 - lr: 0.0010\n",
            "Epoch 53/100\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.91142\n",
            "94/94 - 1s - loss: 0.1866 - accuracy: 0.9310 - val_loss: 0.2724 - val_accuracy: 0.9045 - lr: 0.0010\n",
            "Epoch 54/100\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.91142\n",
            "94/94 - 1s - loss: 0.1819 - accuracy: 0.9329 - val_loss: 0.2609 - val_accuracy: 0.9095 - lr: 0.0010\n",
            "Epoch 55/100\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.91142\n",
            "94/94 - 1s - loss: 0.1828 - accuracy: 0.9315 - val_loss: 0.2671 - val_accuracy: 0.9093 - lr: 0.0010\n",
            "Epoch 56/100\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.91142\n",
            "94/94 - 1s - loss: 0.1775 - accuracy: 0.9344 - val_loss: 0.2838 - val_accuracy: 0.9033 - lr: 0.0010\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYryGsFGM6Hn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "outputId": "68833360-d6e7-4d44-b695-b18528741eb5"
      },
      "source": [
        "grid_result.best_params_"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'_activation': 'relu',\n",
              " '_batch_norm': 1,\n",
              " '_dropout': 0.2,\n",
              " '_lr': 0.001,\n",
              " '_optimizer': 'Adam',\n",
              " 'batch_size': 512,\n",
              " 'epochs': 100}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFwcrccOOua2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c9c3717d-b6d9-4dfb-cd0d-82aef5472a71"
      },
      "source": [
        "grid_result.best_score_"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9038333296775818"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5Y0ZzRW7_t6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}